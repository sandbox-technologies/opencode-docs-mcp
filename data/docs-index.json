{
  "pages": [
    {
      "path": "/docs/",
      "title": "Intro",
      "url": "https://opencode.ai/docs/",
      "content": "# Intro\n\nGet started with OpenCode.\n\nOpenCode is an open source AI coding agent. It’s available as a terminal-based interface, desktop app, or IDE extension.\n\nLet’s get started.\n\n#### Prerequisites\n\nTo use OpenCode in your terminal, you’ll need:\n\n- A modern terminal emulator like:\n\nWezTerm, cross-platform\nAlacritty, cross-platform\nGhostty, Linux and macOS\nKitty, Linux and macOS\nA modern terminal emulator like:\n\n- WezTerm, cross-platform\n- Alacritty, cross-platform\n- Ghostty, Linux and macOS\n- Kitty, Linux and macOS\n- API keys for the LLM providers you want to use.\nAPI keys for the LLM providers you want to use.\n\n## Install\n\nThe easiest way to install OpenCode is through the install script.\n\n```\ncurl -fsSL https://opencode.ai/install | bash\n```\n\nYou can also install it with the following commands:\n\n- Using Node.js\n      npm     Bun     pnpm     Yarn      Terminal windownpm install -g opencode-ai  Terminal windowbun install -g opencode-ai  Terminal windowpnpm install -g opencode-ai  Terminal windowyarn global add opencode-ai\nUsing Node.js\n\n- npm\n- Bun\n- pnpm\n- Yarn\n\n```\nnpm install -g opencode-ai\n```\n\n```\nbun install -g opencode-ai\n```\n\n```\npnpm install -g opencode-ai\n```\n\n```\nyarn global add opencode-ai\n```\n\n- Using Homebrew on macOS and Linux\nTerminal windowbrew install anomalyco/tap/opencode\n\nWe recommend using the OpenCode tap for the most up to date releases. The official brew install opencode formula is maintained by the Homebrew team and is updated less frequently.\nUsing Homebrew on macOS and Linux\n\n```\nbrew install anomalyco/tap/opencode\n```\n\nWe recommend using the OpenCode tap for the most up to date releases. The official brew install opencode formula is maintained by the Homebrew team and is updated less frequently.\n\n- Using Paru on Arch Linux\nTerminal windowparu -S opencode-bin\nUsing Paru on Arch Linux\n\n```\nparu -S opencode-bin\n```\n\n#### Windows\n\n- Using Chocolatey\nTerminal windowchoco install opencode\nUsing Chocolatey\n\n```\nchoco install opencode\n```\n\n- Using Scoop\nTerminal windowscoop bucket add extrasscoop install extras/opencode\nUsing Scoop\n\n```\nscoop bucket add extrasscoop install extras/opencode\n```\n\n- Using NPM\nTerminal windownpm install -g opencode-ai\nUsing NPM\n\n```\nnpm install -g opencode-ai\n```\n\n- Using Mise\nTerminal windowmise use -g github:anomalyco/opencode\nUsing Mise\n\n```\nmise use -g github:anomalyco/opencode\n```\n\n- Using Docker\nTerminal windowdocker run -it --rm ghcr.io/anomalyco/opencode\nUsing Docker\n\n```\ndocker run -it --rm ghcr.io/anomalyco/opencode\n```\n\nSupport for installing OpenCode on Windows using Bun is currently in progress.\n\nYou can also grab the binary from the Releases.\n\n## Configure\n\nWith OpenCode you can use any LLM provider by configuring their API keys.\n\nIf you are new to using LLM providers, we recommend using OpenCode Zen.\nIt’s a curated list of models that have been tested and verified by the OpenCode\nteam.\n\n- Run the /connect command in the TUI, select opencode, and head to opencode.ai/auth.\n/connect\nRun the /connect command in the TUI, select opencode, and head to opencode.ai/auth.\n\n```\n/connect\n```\n\n- Sign in, add your billing details, and copy your API key.\nSign in, add your billing details, and copy your API key.\n\n- Paste your API key.\n┌ API key││└ enter\nPaste your API key.\n\n```\n┌ API key││└ enter\n```\n\nAlternatively, you can select one of the other providers. Learn more.\n\n## Initialize\n\nNow that you’ve configured a provider, you can navigate to a project that\nyou want to work on.\n\n```\ncd /path/to/project\n```\n\nAnd run OpenCode.\n\n```\nopencode\n```\n\nNext, initialize OpenCode for the project by running the following command.\n\n```\n/init\n```\n\nThis will get OpenCode to analyze your project and create an AGENTS.md file in\nthe project root.\n\nTip\n\nYou should commit your project’s AGENTS.md file to Git.\n\nThis helps OpenCode understand the project structure and the coding patterns\nused.\n\n## Usage\n\nYou are now ready to use OpenCode to work on your project. Feel free to ask it\nanything!\n\nIf you are new to using an AI coding agent, here are some examples that might\nhelp.\n\n### Ask questions\n\nYou can ask OpenCode to explain the codebase to you.\n\nTip\n\nUse the @ key to fuzzy search for files in the project.\n\n```\nHow is authentication handled in @packages/functions/src/api/index.ts\n```\n\nThis is helpful if there’s a part of the codebase that you didn’t work on.\n\n### Add features\n\nYou can ask OpenCode to add new features to your project. Though we first recommend asking it to create a plan.\n\n- Create a plan\nOpenCode has a Plan mode that disables its ability to make changes and\ninstead suggest how it’ll implement the feature.\nSwitch to it using the Tab key. You’ll see an indicator for this in the lower right corner.\n<TAB>\nNow let’s describe what we want it to do.\nWhen a user deletes a note, we'd like to flag it as deleted in the database.Then create a screen that shows all the recently deleted notes.From this screen, the user can undelete a note or permanently delete it.\nYou want to give OpenCode enough details to understand what you want. It helps\nto talk to it like you are talking to a junior developer on your team.\nTipGive OpenCode plenty of context and examples to help it understand what you\nwant.\nCreate a plan\n\nOpenCode has a Plan mode that disables its ability to make changes and\ninstead suggest how it’ll implement the feature.\n\nSwitch to it using the Tab key. You’ll see an indicator for this in the lower right corner.\n\n```\n<TAB>\n```\n\nNow let’s describe what we want it to do.\n\n```\nWhen a user deletes a note, we'd like to flag it as deleted in the database.Then create a screen that shows all the recently deleted notes.From this screen, the user can undelete a note or permanently delete it.\n```\n\nYou want to give OpenCode enough details to understand what you want. It helps\nto talk to it like you are talking to a junior developer on your team.\n\nTip\n\nGive OpenCode plenty of context and examples to help it understand what you\nwant.\n\n- Iterate on the plan\nOnce it gives you a plan, you can give it feedback or add more details.\nWe'd like to design this new screen using a design I've used before.[Image #1] Take a look at this image and use it as a reference.\nTipDrag and drop images into the terminal to add them to the prompt.\nOpenCode can scan any images you give it and add them to the prompt. You can\ndo this by dragging and dropping an image into the terminal.\nIterate on the plan\n\nOnce it gives you a plan, you can give it feedback or add more details.\n\n```\nWe'd like to design this new screen using a design I've used before.[Image #1] Take a look at this image and use it as a reference.\n```\n\nTip\n\nDrag and drop images into the terminal to add them to the prompt.\n\nOpenCode can scan any images you give it and add them to the prompt. You can\ndo this by dragging and dropping an image into the terminal.\n\n- Build the feature\nOnce you feel comfortable with the plan, switch back to Build mode by\nhitting the Tab key again.\n<TAB>\nAnd asking it to make the changes.\nSounds good! Go ahead and make the changes.\nBuild the feature\n\nOnce you feel comfortable with the plan, switch back to Build mode by\nhitting the Tab key again.\n\n```\n<TAB>\n```\n\nAnd asking it to make the changes.\n\n```\nSounds good! Go ahead and make the changes.\n```\n\n### Make changes\n\nFor more straightforward changes, you can ask OpenCode to directly build it\nwithout having to review the plan first.\n\n```\nWe need to add authentication to the /settings route. Take a look at how this ishandled in the /notes route in @packages/functions/src/notes.ts and implementthe same logic in @packages/functions/src/settings.ts\n```\n\nYou want to make sure you provide a good amount of detail so OpenCode makes the right\nchanges.\n\n### Undo changes\n\nLet’s say you ask OpenCode to make some changes.\n\n```\nCan you refactor the function in @packages/functions/src/api/index.ts?\n```\n\nBut you realize that it is not what you wanted. You can undo the changes\nusing the /undo command.\n\n```\n/undo\n```\n\nOpenCode will now revert the changes you made and show your original message\nagain.\n\n```\nCan you refactor the function in @packages/functions/src/api/index.ts?\n```\n\nFrom here you can tweak the prompt and ask OpenCode to try again.\n\nTip\n\nYou can run /undo multiple times to undo multiple changes.\n\nOr you can redo the changes using the /redo command.\n\n```\n/redo\n```\n\n## Share\n\nThe conversations that you have with OpenCode can be shared with your\nteam.\n\n```\n/share\n```\n\nThis will create a link to the current conversation and copy it to your clipboard.\n\nNote\n\nConversations are not shared by default.\n\nHere’s an example conversation with OpenCode.\n\n## Customize\n\nAnd that’s it! You are now a pro at using OpenCode.\n\nTo make it your own, we recommend picking a theme, customizing the keybinds, configuring code formatters, creating custom commands, or playing around with the OpenCode config.\n\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/index.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "Intro",
          "id": "_top"
        },
        {
          "level": 4,
          "text": "Prerequisites",
          "id": "prerequisites"
        },
        {
          "level": 2,
          "text": "Install",
          "id": "install"
        },
        {
          "level": 4,
          "text": "Windows",
          "id": "windows"
        },
        {
          "level": 2,
          "text": "Configure",
          "id": "configure"
        },
        {
          "level": 2,
          "text": "Initialize",
          "id": "initialize"
        },
        {
          "level": 2,
          "text": "Usage",
          "id": "usage"
        },
        {
          "level": 3,
          "text": "Ask questions",
          "id": "ask-questions"
        },
        {
          "level": 3,
          "text": "Add features",
          "id": "add-features"
        },
        {
          "level": 3,
          "text": "Make changes",
          "id": "make-changes"
        },
        {
          "level": 3,
          "text": "Undo changes",
          "id": "undo-changes"
        },
        {
          "level": 2,
          "text": "Share",
          "id": "share"
        },
        {
          "level": 2,
          "text": "Customize",
          "id": "customize"
        }
      ],
      "category": "Getting Started",
      "scrapedAt": 1768685266538
    },
    {
      "path": "/docs/config/",
      "title": "Config",
      "url": "https://opencode.ai/docs/config/",
      "content": "# Config\n\nUsing the OpenCode JSON config.\n\nYou can configure OpenCode using a JSON config file.\n\n## Format\n\nOpenCode supports both JSON and JSONC (JSON with Comments) formats.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  // Theme configuration  \"theme\": \"opencode\",  \"model\": \"anthropic/claude-sonnet-4-5\",  \"autoupdate\": true,}\n```\n\n## Locations\n\nYou can place your config in a couple of different locations and they have a\ndifferent order of precedence.\n\nNote\n\nConfiguration files are merged together, not replaced.\n\nConfiguration files are merged together, not replaced. Settings from the following config locations are combined. Later configs override earlier ones only for conflicting keys. Non-conflicting settings from all configs are preserved.\n\nFor example, if your global config sets theme: \"opencode\" and autoupdate: true, and your project config sets model: \"anthropic/claude-sonnet-4-5\", the final configuration will include all three settings.\n\n### Precedence order\n\nConfig sources are loaded in this order (later sources override earlier ones):\n\n- Remote config (from .well-known/opencode) - organizational defaults\n- Global config (~/.config/opencode/opencode.json) - user preferences\n- Custom config (OPENCODE_CONFIG env var) - custom overrides\n- Project config (opencode.json in project) - project-specific settings\n- .opencode directories - agents, commands, plugins\n- Inline config (OPENCODE_CONFIG_CONTENT env var) - runtime overrides\nThis means project configs can override global defaults, and global configs can override remote organizational defaults.\n\n### Remote\n\nOrganizations can provide default configuration via the .well-known/opencode endpoint. This is fetched automatically when you authenticate with a provider that supports it.\n\nRemote config is loaded first, serving as the base layer. All other config sources (global, project) can override these defaults.\n\nFor example, if your organization provides MCP servers that are disabled by default:\n\n```\n{  \"mcp\": {    \"jira\": {      \"type\": \"remote\",      \"url\": \"https://jira.example.com/mcp\",      \"enabled\": false    }  }}\n```\n\nYou can enable specific servers in your local config:\n\n```\n{  \"mcp\": {    \"jira\": {      \"type\": \"remote\",      \"url\": \"https://jira.example.com/mcp\",      \"enabled\": true    }  }}\n```\n\n### Global\n\nPlace your global OpenCode config in ~/.config/opencode/opencode.json. Use global config for user-wide preferences like themes, providers, or keybinds.\n\nGlobal config overrides remote organizational defaults.\n\n### Per project\n\nAdd opencode.json in your project root. Project config has the highest precedence among standard config files - it overrides both global and remote configs.\n\nTip\n\nPlace project specific config in the root of your project.\n\nWhen OpenCode starts up, it looks for a config file in the current directory or traverse up to the nearest Git directory.\n\nThis is also safe to be checked into Git and uses the same schema as the global one.\n\n### Custom path\n\nSpecify a custom config file path using the OPENCODE_CONFIG environment variable.\n\n```\nexport OPENCODE_CONFIG=/path/to/my/custom-config.jsonopencode run \"Hello world\"\n```\n\nCustom config is loaded between global and project configs in the precedence order.\n\n### Custom directory\n\nSpecify a custom config directory using the OPENCODE_CONFIG_DIR\nenvironment variable. This directory will be searched for agents, commands,\nmodes, and plugins just like the standard .opencode directory, and should\nfollow the same structure.\n\n```\nexport OPENCODE_CONFIG_DIR=/path/to/my/config-directoryopencode run \"Hello world\"\n```\n\nThe custom directory is loaded after the global config and .opencode directories, so it can override their settings.\n\n## Schema\n\nThe config file has a schema that’s defined in opencode.ai/config.json.\n\nYour editor should be able to validate and autocomplete based on the schema.\n\n### TUI\n\nYou can configure TUI-specific settings through the tui option.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"tui\": {    \"scroll_speed\": 3,    \"scroll_acceleration\": {      \"enabled\": true    },    \"diff_style\": \"auto\"  }}\n```\n\nAvailable options:\n\n- scroll_acceleration.enabled - Enable macOS-style scroll acceleration. Takes precedence over scroll_speed.\n- scroll_speed - Custom scroll speed multiplier (default: 3, minimum: 1). Ignored if scroll_acceleration.enabled is true.\n- diff_style - Control diff rendering. \"auto\" adapts to terminal width, \"stacked\" always shows single column.\nLearn more about using the TUI here.\n\n### Server\n\nYou can configure server settings for the opencode serve and opencode web commands through the server option.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"server\": {    \"port\": 4096,    \"hostname\": \"0.0.0.0\",    \"mdns\": true,    \"cors\": [\"http://localhost:5173\"]  }}\n```\n\nAvailable options:\n\n- port - Port to listen on.\n- hostname - Hostname to listen on. When mdns is enabled and no hostname is set, defaults to 0.0.0.0.\n- mdns - Enable mDNS service discovery. This allows other devices on the network to discover your OpenCode server.\n- cors - Additional origins to allow for CORS when using the HTTP server from a browser-based client. Values must be full origins (scheme + host + optional port), eg https://app.example.com.\nLearn more about the server here.\n\n### Tools\n\nYou can manage the tools an LLM can use through the tools option.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"tools\": {    \"write\": false,    \"bash\": false  }}\n```\n\nLearn more about tools here.\n\n### Models\n\nYou can configure the providers and models you want to use in your OpenCode config through the provider, model and small_model options.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {},  \"model\": \"anthropic/claude-sonnet-4-5\",  \"small_model\": \"anthropic/claude-haiku-4-5\"}\n```\n\nThe small_model option configures a separate model for lightweight tasks like title generation. By default, OpenCode tries to use a cheaper model if one is available from your provider, otherwise it falls back to your main model.\n\nProvider options can include timeout and setCacheKey:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"anthropic\": {      \"options\": {        \"timeout\": 600000,        \"setCacheKey\": true      }    }  }}\n```\n\n- timeout - Request timeout in milliseconds (default: 300000). Set to false to disable.\n- setCacheKey - Ensure a cache key is always set for designated provider.\nYou can also configure local models. Learn more.\n\n#### Provider-Specific Options\n\nSome providers support additional configuration options beyond the generic timeout and apiKey settings.\n\n[Amazon Bedrock](#amazon-bedrock) Amazon Bedrock supports AWS-specific configuration:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"amazon-bedrock\": {      \"options\": {        \"region\": \"us-east-1\",        \"profile\": \"my-aws-profile\",        \"endpoint\": \"https://bedrock-runtime.us-east-1.vpce-xxxxx.amazonaws.com\"      }    }  }}\n```\n\n- region - AWS region for Bedrock (defaults to AWS_REGION env var or us-east-1)\n- profile - AWS named profile from ~/.aws/credentials (defaults to AWS_PROFILE env var)\n- endpoint - Custom endpoint URL for VPC endpoints. This is an alias for the generic baseURL option using AWS-specific terminology. If both are specified, endpoint takes precedence.\nNote\n\nBearer tokens (AWS_BEARER_TOKEN_BEDROCK or /connect) take precedence over profile-based authentication. See authentication precedence for details.\n\nLearn more about Amazon Bedrock configuration.\n\n### Themes\n\nYou can configure the theme you want to use in your OpenCode config through the theme option.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"theme\": \"\"}\n```\n\nLearn more here.\n\n### Agents\n\nYou can configure specialized agents for specific tasks through the agent option.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"agent\": {    \"code-reviewer\": {      \"description\": \"Reviews code for best practices and potential issues\",      \"model\": \"anthropic/claude-sonnet-4-5\",      \"prompt\": \"You are a code reviewer. Focus on security, performance, and maintainability.\",      \"tools\": {        // Disable file modification tools for review-only agent        \"write\": false,        \"edit\": false,      },    },  },}\n```\n\nYou can also define agents using markdown files in ~/.config/opencode/agent/ or .opencode/agent/. Learn more here.\n\n### Default agent\n\nYou can set the default agent using the default_agent option. This determines which agent is used when none is explicitly specified.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"default_agent\": \"plan\"}\n```\n\nThe default agent must be a primary agent (not a subagent). This can be a built-in agent like \"build\" or \"plan\", or a custom agent you’ve defined. If the specified agent doesn’t exist or is a subagent, OpenCode will fall back to \"build\" with a warning.\n\nThis setting applies across all interfaces: TUI, CLI (opencode run), desktop app, and GitHub Action.\n\n### Sharing\n\nYou can configure the share feature through the share option.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"share\": \"manual\"}\n```\n\nThis takes:\n\n- \"manual\" - Allow manual sharing via commands (default)\n- \"auto\" - Automatically share new conversations\n- \"disabled\" - Disable sharing entirely\nBy default, sharing is set to manual mode where you need to explicitly share conversations using the /share command.\n\n### Commands\n\nYou can configure custom commands for repetitive tasks through the command option.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"command\": {    \"test\": {      \"template\": \"Run the full test suite with coverage report and show any failures.\\nFocus on the failing tests and suggest fixes.\",      \"description\": \"Run tests with coverage\",      \"agent\": \"build\",      \"model\": \"anthropic/claude-haiku-4-5\",    },    \"component\": {      \"template\": \"Create a new React component named $ARGUMENTS with TypeScript support.\\nInclude proper typing and basic structure.\",      \"description\": \"Create a new component\",    },  },}\n```\n\nYou can also define commands using markdown files in ~/.config/opencode/command/ or .opencode/command/. Learn more here.\n\n### Keybinds\n\nYou can customize your keybinds through the keybinds option.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"keybinds\": {}}\n```\n\nLearn more here.\n\n### Autoupdate\n\nOpenCode will automatically download any new updates when it starts up. You can disable this with the autoupdate option.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"autoupdate\": false}\n```\n\nIf you don’t want updates but want to be notified when a new version is available, set autoupdate to \"notify\".\n\n### Formatters\n\nYou can configure code formatters through the formatter option.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"formatter\": {    \"prettier\": {      \"disabled\": true    },    \"custom-prettier\": {      \"command\": [\"npx\", \"prettier\", \"--write\", \"$FILE\"],      \"environment\": {        \"NODE_ENV\": \"development\"      },      \"extensions\": [\".js\", \".ts\", \".jsx\", \".tsx\"]    }  }}\n```\n\nLearn more about formatters here.\n\n### Permissions\n\nBy default, opencode allows all operations without requiring explicit approval. You can change this using the permission option.\n\nFor example, to ensure that the edit and bash tools require user approval:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"permission\": {    \"edit\": \"ask\",    \"bash\": \"ask\"  }}\n```\n\nLearn more about permissions here.\n\n### Compaction\n\nYou can control context compaction behavior through the compaction option.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"compaction\": {    \"auto\": true,    \"prune\": true  }}\n```\n\n- auto - Automatically compact the session when context is full (default: true).\n- prune - Remove old tool outputs to save tokens (default: true).\n\n### Watcher\n\nYou can configure file watcher ignore patterns through the watcher option.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"watcher\": {    \"ignore\": [\"node_modules/**\", \"dist/**\", \".git/**\"]  }}\n```\n\nPatterns follow glob syntax. Use this to exclude noisy directories from file watching.\n\n### MCP servers\n\nYou can configure MCP servers you want to use through the mcp option.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"mcp\": {}}\n```\n\nLearn more here.\n\n### Plugins\n\nPlugins extend OpenCode with custom tools, hooks, and integrations.\n\nPlace plugin files in .opencode/plugin/ or ~/.config/opencode/plugin/. You can also load plugins from npm through the plugin option.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"plugin\": [\"opencode-helicone-session\", \"@my-org/custom-plugin\"]}\n```\n\nLearn more here.\n\n### Instructions\n\nYou can configure the instructions for the model you’re using through the instructions option.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"instructions\": [\"CONTRIBUTING.md\", \"docs/guidelines.md\", \".cursor/rules/*.md\"]}\n```\n\nThis takes an array of paths and glob patterns to instruction files. Learn more\nabout rules here.\n\n### Disabled providers\n\nYou can disable providers that are loaded automatically through the disabled_providers option. This is useful when you want to prevent certain providers from being loaded even if their credentials are available.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"disabled_providers\": [\"openai\", \"gemini\"]}\n```\n\nNote\n\nThe disabled_providers takes priority over enabled_providers.\n\nThe disabled_providers option accepts an array of provider IDs. When a provider is disabled:\n\n- It won’t be loaded even if environment variables are set.\n- It won’t be loaded even if API keys are configured through the /connect command.\n- The provider’s models won’t appear in the model selection list.\n\n### Enabled providers\n\nYou can specify an allowlist of providers through the enabled_providers option. When set, only the specified providers will be enabled and all others will be ignored.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"enabled_providers\": [\"anthropic\", \"openai\"]}\n```\n\nThis is useful when you want to restrict OpenCode to only use specific providers rather than disabling them one by one.\n\nNote\n\nThe disabled_providers takes priority over enabled_providers.\n\nIf a provider appears in both enabled_providers and disabled_providers, the disabled_providers takes priority for backwards compatibility.\n\n### Experimental\n\nThe experimental key contains options that are under active development.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"experimental\": {}}\n```\n\nCaution\n\nExperimental options are not stable. They may change or be removed without notice.\n\n## Variables\n\nYou can use variable substitution in your config files to reference environment variables and file contents.\n\n### Env vars\n\nUse {env:VARIABLE_NAME} to substitute environment variables:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"model\": \"{env:OPENCODE_MODEL}\",  \"provider\": {    \"anthropic\": {      \"models\": {},      \"options\": {        \"apiKey\": \"{env:ANTHROPIC_API_KEY}\"      }    }  }}\n```\n\nIf the environment variable is not set, it will be replaced with an empty string.\n\n### Files\n\nUse {file:path/to/file} to substitute the contents of a file:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"instructions\": [\"./custom-instructions.md\"],  \"provider\": {    \"openai\": {      \"options\": {        \"apiKey\": \"{file:~/.secrets/openai-key}\"      }    }  }}\n```\n\nFile paths can be:\n\n- Relative to the config file directory\n- Or absolute paths starting with / or ~\nThese are useful for:\n\n- Keeping sensitive data like API keys in separate files.\n- Including large instruction files without cluttering your config.\n- Sharing common configuration snippets across multiple config files.\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/config.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "Config",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "Format",
          "id": "format"
        },
        {
          "level": 2,
          "text": "Locations",
          "id": "locations"
        },
        {
          "level": 3,
          "text": "Precedence order",
          "id": "precedence-order"
        },
        {
          "level": 3,
          "text": "Remote",
          "id": "remote"
        },
        {
          "level": 3,
          "text": "Global",
          "id": "global"
        },
        {
          "level": 3,
          "text": "Per project",
          "id": "per-project"
        },
        {
          "level": 3,
          "text": "Custom path",
          "id": "custom-path"
        },
        {
          "level": 3,
          "text": "Custom directory",
          "id": "custom-directory"
        },
        {
          "level": 2,
          "text": "Schema",
          "id": "schema"
        },
        {
          "level": 3,
          "text": "TUI",
          "id": "tui"
        },
        {
          "level": 3,
          "text": "Server",
          "id": "server"
        },
        {
          "level": 3,
          "text": "Tools",
          "id": "tools"
        },
        {
          "level": 3,
          "text": "Models",
          "id": "models"
        },
        {
          "level": 4,
          "text": "Provider-Specific Options",
          "id": "provider-specific-options"
        },
        {
          "level": 5,
          "text": "Amazon Bedrock",
          "id": "amazon-bedrock"
        },
        {
          "level": 3,
          "text": "Themes",
          "id": "themes"
        },
        {
          "level": 3,
          "text": "Agents",
          "id": "agents"
        },
        {
          "level": 3,
          "text": "Default agent",
          "id": "default-agent"
        },
        {
          "level": 3,
          "text": "Sharing",
          "id": "sharing"
        },
        {
          "level": 3,
          "text": "Commands",
          "id": "commands"
        },
        {
          "level": 3,
          "text": "Keybinds",
          "id": "keybinds"
        },
        {
          "level": 3,
          "text": "Autoupdate",
          "id": "autoupdate"
        },
        {
          "level": 3,
          "text": "Formatters",
          "id": "formatters"
        },
        {
          "level": 3,
          "text": "Permissions",
          "id": "permissions"
        },
        {
          "level": 3,
          "text": "Compaction",
          "id": "compaction"
        },
        {
          "level": 3,
          "text": "Watcher",
          "id": "watcher"
        },
        {
          "level": 3,
          "text": "MCP servers",
          "id": "mcp-servers"
        },
        {
          "level": 3,
          "text": "Plugins",
          "id": "plugins"
        },
        {
          "level": 3,
          "text": "Instructions",
          "id": "instructions"
        },
        {
          "level": 3,
          "text": "Disabled providers",
          "id": "disabled-providers"
        },
        {
          "level": 3,
          "text": "Enabled providers",
          "id": "enabled-providers"
        },
        {
          "level": 3,
          "text": "Experimental",
          "id": "experimental"
        },
        {
          "level": 2,
          "text": "Variables",
          "id": "variables"
        },
        {
          "level": 3,
          "text": "Env vars",
          "id": "env-vars"
        },
        {
          "level": 3,
          "text": "Files",
          "id": "files"
        }
      ],
      "category": "Getting Started",
      "scrapedAt": 1768685266906
    },
    {
      "path": "/docs/providers/",
      "title": "Providers",
      "url": "https://opencode.ai/docs/providers/",
      "content": "# Providers\n\nUsing any LLM provider in OpenCode.\n\nOpenCode uses the AI SDK and Models.dev to support 75+ LLM providers and it supports running local models.\n\nTo add a provider you need to:\n\n- Add the API keys for the provider using the /connect command.\n- Configure the provider in your OpenCode config.\n\n### Credentials\n\nWhen you add a provider’s API keys with the /connect command, they are stored\nin ~/.local/share/opencode/auth.json.\n\n### Config\n\nYou can customize the providers through the provider section in your OpenCode\nconfig.\n\n#### Base URL\n\nYou can customize the base URL for any provider by setting the baseURL option. This is useful when using proxy services or custom endpoints.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"anthropic\": {      \"options\": {        \"baseURL\": \"https://api.anthropic.com/v1\"      }    }  }}\n```\n\n## OpenCode Zen\n\nOpenCode Zen is a list of models provided by the OpenCode team that have been\ntested and verified to work well with OpenCode. Learn more.\n\nTip\n\nIf you are new, we recommend starting with OpenCode Zen.\n\n- Run the /connect command in the TUI, select opencode, and head to opencode.ai/auth.\n/connect\nRun the /connect command in the TUI, select opencode, and head to opencode.ai/auth.\n\n```\n/connect\n```\n\n- Sign in, add your billing details, and copy your API key.\nSign in, add your billing details, and copy your API key.\n\n- Paste your API key.\n┌ API key││└ enter\nPaste your API key.\n\n```\n┌ API key││└ enter\n```\n\n- Run /models in the TUI to see the list of models we recommend.\n/models\nRun /models in the TUI to see the list of models we recommend.\n\n```\n/models\n```\n\nIt works like any other provider in OpenCode and is completely optional to use.\n\n## Directory\n\nLet’s look at some of the providers in detail. If you’d like to add a provider to the\nlist, feel free to open a PR.\n\nNote\n\nDon’t see a provider here? Submit a PR.\n\n### 302.AI\n\n- Head over to the 302.AI console, create an account, and generate an API key.\nHead over to the 302.AI console, create an account, and generate an API key.\n\n- Run the /connect command and search for 302.AI.\n/connect\nRun the /connect command and search for 302.AI.\n\n```\n/connect\n```\n\n- Enter your 302.AI API key.\n┌ API key││└ enter\nEnter your 302.AI API key.\n\n```\n┌ API key││└ enter\n```\n\n- Run the /models command to select a model.\n/models\nRun the /models command to select a model.\n\n```\n/models\n```\n\n### Amazon Bedrock\n\nTo use Amazon Bedrock with OpenCode:\n\n- Head over to the Model catalog in the Amazon Bedrock console and request\naccess to the models you want.\nTipYou need to have access to the model you want in Amazon Bedrock.\nHead over to the Model catalog in the Amazon Bedrock console and request\naccess to the models you want.\n\nTip\n\nYou need to have access to the model you want in Amazon Bedrock.\n\n- Configure authentication using one of the following methods:\nEnvironment Variables (Quick Start)\nSet one of these environment variables while running opencode:\nTerminal window# Option 1: Using AWS access keysAWS_ACCESS_KEY_ID=XXX AWS_SECRET_ACCESS_KEY=YYY opencode\n# Option 2: Using named AWS profileAWS_PROFILE=my-profile opencode\n# Option 3: Using Bedrock bearer tokenAWS_BEARER_TOKEN_BEDROCK=XXX opencode\nOr add them to your bash profile:\n~/.bash_profileexport AWS_PROFILE=my-dev-profileexport AWS_REGION=us-east-1\nConfiguration File (Recommended)\nFor project-specific or persistent configuration, use opencode.json:\nopencode.json{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"amazon-bedrock\": {      \"options\": {        \"region\": \"us-east-1\",        \"profile\": \"my-aws-profile\"      }    }  }}\nAvailable options:\n\nregion - AWS region (e.g., us-east-1, eu-west-1)\nprofile - AWS named profile from ~/.aws/credentials\nendpoint - Custom endpoint URL for VPC endpoints (alias for generic baseURL option)\n\nTipConfiguration file options take precedence over environment variables.\nAdvanced: VPC Endpoints\nIf you’re using VPC endpoints for Bedrock:\nopencode.json{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"amazon-bedrock\": {      \"options\": {        \"region\": \"us-east-1\",        \"profile\": \"production\",        \"endpoint\": \"https://bedrock-runtime.us-east-1.vpce-xxxxx.amazonaws.com\"      }    }  }}\nNoteThe endpoint option is an alias for the generic baseURL option, using AWS-specific terminology. If both endpoint and baseURL are specified, endpoint takes precedence.\nAuthentication Methods\n\nAWS_ACCESS_KEY_ID / AWS_SECRET_ACCESS_KEY: Create an IAM user and generate access keys in the AWS Console\nAWS_PROFILE: Use named profiles from ~/.aws/credentials. First configure with aws configure --profile my-profile or aws sso login\nAWS_BEARER_TOKEN_BEDROCK: Generate long-term API keys from the Amazon Bedrock console\nAWS_WEB_IDENTITY_TOKEN_FILE / AWS_ROLE_ARN: For EKS IRSA (IAM Roles for Service Accounts) or other Kubernetes environments with OIDC federation. These environment variables are automatically injected by Kubernetes when using service account annotations.\n\nAuthentication Precedence\nAmazon Bedrock uses the following authentication priority:\n\nBearer Token - AWS_BEARER_TOKEN_BEDROCK environment variable or token from /connect command\nAWS Credential Chain - Profile, access keys, shared credentials, IAM roles, Web Identity Tokens (EKS IRSA), instance metadata\n\nNoteWhen a bearer token is set (via /connect or AWS_BEARER_TOKEN_BEDROCK), it takes precedence over all AWS credential methods including configured profiles.\nConfigure authentication using one of the following methods:\n\n#### Environment Variables (Quick Start)\n\nSet one of these environment variables while running opencode:\n\n```\n# Option 1: Using AWS access keysAWS_ACCESS_KEY_ID=XXX AWS_SECRET_ACCESS_KEY=YYY opencode\n# Option 2: Using named AWS profileAWS_PROFILE=my-profile opencode\n# Option 3: Using Bedrock bearer tokenAWS_BEARER_TOKEN_BEDROCK=XXX opencode\n```\n\nOr add them to your bash profile:\n\n```\nexport AWS_PROFILE=my-dev-profileexport AWS_REGION=us-east-1\n```\n\n#### Configuration File (Recommended)\n\nFor project-specific or persistent configuration, use opencode.json:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"amazon-bedrock\": {      \"options\": {        \"region\": \"us-east-1\",        \"profile\": \"my-aws-profile\"      }    }  }}\n```\n\nAvailable options:\n\n- region - AWS region (e.g., us-east-1, eu-west-1)\n- profile - AWS named profile from ~/.aws/credentials\n- endpoint - Custom endpoint URL for VPC endpoints (alias for generic baseURL option)\nTip\n\nConfiguration file options take precedence over environment variables.\n\n#### Advanced: VPC Endpoints\n\nIf you’re using VPC endpoints for Bedrock:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"amazon-bedrock\": {      \"options\": {        \"region\": \"us-east-1\",        \"profile\": \"production\",        \"endpoint\": \"https://bedrock-runtime.us-east-1.vpce-xxxxx.amazonaws.com\"      }    }  }}\n```\n\nNote\n\nThe endpoint option is an alias for the generic baseURL option, using AWS-specific terminology. If both endpoint and baseURL are specified, endpoint takes precedence.\n\n#### Authentication Methods\n\n- AWS_ACCESS_KEY_ID / AWS_SECRET_ACCESS_KEY: Create an IAM user and generate access keys in the AWS Console\n- AWS_PROFILE: Use named profiles from ~/.aws/credentials. First configure with aws configure --profile my-profile or aws sso login\n- AWS_BEARER_TOKEN_BEDROCK: Generate long-term API keys from the Amazon Bedrock console\n- AWS_WEB_IDENTITY_TOKEN_FILE / AWS_ROLE_ARN: For EKS IRSA (IAM Roles for Service Accounts) or other Kubernetes environments with OIDC federation. These environment variables are automatically injected by Kubernetes when using service account annotations.\n\n#### Authentication Precedence\n\nAmazon Bedrock uses the following authentication priority:\n\n- Bearer Token - AWS_BEARER_TOKEN_BEDROCK environment variable or token from /connect command\n- AWS Credential Chain - Profile, access keys, shared credentials, IAM roles, Web Identity Tokens (EKS IRSA), instance metadata\nNote\n\nWhen a bearer token is set (via /connect or AWS_BEARER_TOKEN_BEDROCK), it takes precedence over all AWS credential methods including configured profiles.\n\n- Run the /models command to select the model you want.\n/models\nRun the /models command to select the model you want.\n\n```\n/models\n```\n\n### Anthropic\n\nWe recommend signing up for Claude Pro or Max.\n\n- Once you’ve signed up, run the /connect command and select Anthropic.\n/connect\nOnce you’ve signed up, run the /connect command and select Anthropic.\n\n```\n/connect\n```\n\n- Here you can select the Claude Pro/Max option and it’ll open your browser\nand ask you to authenticate.\n┌ Select auth method││ Claude Pro/Max│ Create an API Key│ Manually enter API Key└\nHere you can select the Claude Pro/Max option and it’ll open your browser\nand ask you to authenticate.\n\n```\n┌ Select auth method││ Claude Pro/Max│ Create an API Key│ Manually enter API Key└\n```\n\n- Now all the Anthropic models should be available when you use the /models command.\n/models\nNow all the Anthropic models should be available when you use the /models command.\n\n```\n/models\n```\n\n[Using API keys](#using-api-keys) You can also select Create an API Key if you don’t have a Pro/Max subscription. It’ll also open your browser and ask you to login to Anthropic and give you a code you can paste in your terminal.\n\nOr if you already have an API key, you can select Manually enter API Key and paste it in your terminal.\n\n### Azure OpenAI\n\nNote\n\nIf you encounter “I’m sorry, but I cannot assist with that request” errors, try changing the content filter from DefaultV2 to Default in your Azure resource.\n\n- Head over to the Azure portal and create an Azure OpenAI resource. You’ll need:\n\nResource name: This becomes part of your API endpoint (https://RESOURCE_NAME.openai.azure.com/)\nAPI key: Either KEY 1 or KEY 2 from your resource\nHead over to the Azure portal and create an Azure OpenAI resource. You’ll need:\n\n- Resource name: This becomes part of your API endpoint (https://RESOURCE_NAME.openai.azure.com/)\n- API key: Either KEY 1 or KEY 2 from your resource\n- Go to Azure AI Foundry and deploy a model.\nNoteThe deployment name must match the model name for opencode to work properly.\nGo to Azure AI Foundry and deploy a model.\n\nNote\n\nThe deployment name must match the model name for opencode to work properly.\n\n- Run the /connect command and search for Azure.\n/connect\nRun the /connect command and search for Azure.\n\n```\n/connect\n```\n\n- Enter your API key.\n┌ API key││└ enter\nEnter your API key.\n\n```\n┌ API key││└ enter\n```\n\n- Set your resource name as an environment variable:\nTerminal windowAZURE_RESOURCE_NAME=XXX opencode\nOr add it to your bash profile:\n~/.bash_profileexport AZURE_RESOURCE_NAME=XXX\nSet your resource name as an environment variable:\n\n```\nAZURE_RESOURCE_NAME=XXX opencode\n```\n\nOr add it to your bash profile:\n\n```\nexport AZURE_RESOURCE_NAME=XXX\n```\n\n- Run the /models command to select your deployed model.\n/models\nRun the /models command to select your deployed model.\n\n```\n/models\n```\n\n### Azure Cognitive Services\n\n- Head over to the Azure portal and create an Azure OpenAI resource. You’ll need:\n\nResource name: This becomes part of your API endpoint (https://AZURE_COGNITIVE_SERVICES_RESOURCE_NAME.cognitiveservices.azure.com/)\nAPI key: Either KEY 1 or KEY 2 from your resource\nHead over to the Azure portal and create an Azure OpenAI resource. You’ll need:\n\n- Resource name: This becomes part of your API endpoint (https://AZURE_COGNITIVE_SERVICES_RESOURCE_NAME.cognitiveservices.azure.com/)\n- API key: Either KEY 1 or KEY 2 from your resource\n- Go to Azure AI Foundry and deploy a model.\nNoteThe deployment name must match the model name for opencode to work properly.\nGo to Azure AI Foundry and deploy a model.\n\nNote\n\nThe deployment name must match the model name for opencode to work properly.\n\n- Run the /connect command and search for Azure Cognitive Services.\n/connect\nRun the /connect command and search for Azure Cognitive Services.\n\n```\n/connect\n```\n\n- Enter your API key.\n┌ API key││└ enter\nEnter your API key.\n\n```\n┌ API key││└ enter\n```\n\n- Set your resource name as an environment variable:\nTerminal windowAZURE_COGNITIVE_SERVICES_RESOURCE_NAME=XXX opencode\nOr add it to your bash profile:\n~/.bash_profileexport AZURE_COGNITIVE_SERVICES_RESOURCE_NAME=XXX\nSet your resource name as an environment variable:\n\n```\nAZURE_COGNITIVE_SERVICES_RESOURCE_NAME=XXX opencode\n```\n\nOr add it to your bash profile:\n\n```\nexport AZURE_COGNITIVE_SERVICES_RESOURCE_NAME=XXX\n```\n\n- Run the /models command to select your deployed model.\n/models\nRun the /models command to select your deployed model.\n\n```\n/models\n```\n\n### Baseten\n\n- Head over to the Baseten, create an account, and generate an API key.\nHead over to the Baseten, create an account, and generate an API key.\n\n- Run the /connect command and search for Baseten.\n/connect\nRun the /connect command and search for Baseten.\n\n```\n/connect\n```\n\n- Enter your Baseten API key.\n┌ API key││└ enter\nEnter your Baseten API key.\n\n```\n┌ API key││└ enter\n```\n\n- Run the /models command to select a model.\n/models\nRun the /models command to select a model.\n\n```\n/models\n```\n\n### Cerebras\n\n- Head over to the Cerebras console, create an account, and generate an API key.\nHead over to the Cerebras console, create an account, and generate an API key.\n\n- Run the /connect command and search for Cerebras.\n/connect\nRun the /connect command and search for Cerebras.\n\n```\n/connect\n```\n\n- Enter your Cerebras API key.\n┌ API key││└ enter\nEnter your Cerebras API key.\n\n```\n┌ API key││└ enter\n```\n\n- Run the /models command to select a model like Qwen 3 Coder 480B.\n/models\nRun the /models command to select a model like Qwen 3 Coder 480B.\n\n```\n/models\n```\n\n### Cloudflare AI Gateway\n\nCloudflare AI Gateway lets you access models from OpenAI, Anthropic, Workers AI, and more through a unified endpoint. With Unified Billing you don’t need separate API keys for each provider.\n\n- Head over to the Cloudflare dashboard, navigate to AI > AI Gateway, and create a new gateway.\nHead over to the Cloudflare dashboard, navigate to AI > AI Gateway, and create a new gateway.\n\n- Set your Account ID and Gateway ID as environment variables.\n~/.bash_profileexport CLOUDFLARE_ACCOUNT_ID=your-32-character-account-idexport CLOUDFLARE_GATEWAY_ID=your-gateway-id\nSet your Account ID and Gateway ID as environment variables.\n\n```\nexport CLOUDFLARE_ACCOUNT_ID=your-32-character-account-idexport CLOUDFLARE_GATEWAY_ID=your-gateway-id\n```\n\n- Run the /connect command and search for Cloudflare AI Gateway.\n/connect\nRun the /connect command and search for Cloudflare AI Gateway.\n\n```\n/connect\n```\n\n- Enter your Cloudflare API token.\n┌ API key││└ enter\nOr set it as an environment variable.\n~/.bash_profileexport CLOUDFLARE_API_TOKEN=your-api-token\nEnter your Cloudflare API token.\n\n```\n┌ API key││└ enter\n```\n\nOr set it as an environment variable.\n\n```\nexport CLOUDFLARE_API_TOKEN=your-api-token\n```\n\n- Run the /models command to select a model.\n/models\nYou can also add models through your opencode config.\nopencode.json{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"cloudflare-ai-gateway\": {      \"models\": {        \"openai/gpt-4o\": {},        \"anthropic/claude-sonnet-4\": {}      }    }  }}\nRun the /models command to select a model.\n\n```\n/models\n```\n\nYou can also add models through your opencode config.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"cloudflare-ai-gateway\": {      \"models\": {        \"openai/gpt-4o\": {},        \"anthropic/claude-sonnet-4\": {}      }    }  }}\n```\n\n### Cortecs\n\n- Head over to the Cortecs console, create an account, and generate an API key.\nHead over to the Cortecs console, create an account, and generate an API key.\n\n- Run the /connect command and search for Cortecs.\n/connect\nRun the /connect command and search for Cortecs.\n\n```\n/connect\n```\n\n- Enter your Cortecs API key.\n┌ API key││└ enter\nEnter your Cortecs API key.\n\n```\n┌ API key││└ enter\n```\n\n- Run the /models command to select a model like Kimi K2 Instruct.\n/models\nRun the /models command to select a model like Kimi K2 Instruct.\n\n```\n/models\n```\n\n### DeepSeek\n\n- Head over to the DeepSeek console, create an account, and click Create new API key.\nHead over to the DeepSeek console, create an account, and click Create new API key.\n\n- Run the /connect command and search for DeepSeek.\n/connect\nRun the /connect command and search for DeepSeek.\n\n```\n/connect\n```\n\n- Enter your DeepSeek API key.\n┌ API key││└ enter\nEnter your DeepSeek API key.\n\n```\n┌ API key││└ enter\n```\n\n- Run the /models command to select a DeepSeek model like DeepSeek Reasoner.\n/models\nRun the /models command to select a DeepSeek model like DeepSeek Reasoner.\n\n```\n/models\n```\n\n### Deep Infra\n\n- Head over to the Deep Infra dashboard, create an account, and generate an API key.\nHead over to the Deep Infra dashboard, create an account, and generate an API key.\n\n- Run the /connect command and search for Deep Infra.\n/connect\nRun the /connect command and search for Deep Infra.\n\n```\n/connect\n```\n\n- Enter your Deep Infra API key.\n┌ API key││└ enter\nEnter your Deep Infra API key.\n\n```\n┌ API key││└ enter\n```\n\n- Run the /models command to select a model.\n/models\nRun the /models command to select a model.\n\n```\n/models\n```\n\n### Fireworks AI\n\n- Head over to the Fireworks AI console, create an account, and click Create API Key.\nHead over to the Fireworks AI console, create an account, and click Create API Key.\n\n- Run the /connect command and search for Fireworks AI.\n/connect\nRun the /connect command and search for Fireworks AI.\n\n```\n/connect\n```\n\n- Enter your Fireworks AI API key.\n┌ API key││└ enter\nEnter your Fireworks AI API key.\n\n```\n┌ API key││└ enter\n```\n\n- Run the /models command to select a model like Kimi K2 Instruct.\n/models\nRun the /models command to select a model like Kimi K2 Instruct.\n\n```\n/models\n```\n\n### GitLab Duo\n\nGitLab Duo provides AI-powered agentic chat with native tool calling capabilities through GitLab’s Anthropic proxy.\n\n- Run the /connect command and select GitLab.\n/connect\nRun the /connect command and select GitLab.\n\n```\n/connect\n```\n\n- Choose your authentication method:\n┌ Select auth method││ OAuth (Recommended)│ Personal Access Token└\nUsing OAuth (Recommended)\nSelect OAuth and your browser will open for authorization.\nUsing Personal Access Token\n\nGo to GitLab User Settings > Access Tokens\nClick Add new token\nName: OpenCode, Scopes: api\nCopy the token (starts with glpat-)\nEnter it in the terminal\nChoose your authentication method:\n\n```\n┌ Select auth method││ OAuth (Recommended)│ Personal Access Token└\n```\n\n#### Using OAuth (Recommended)\n\nSelect OAuth and your browser will open for authorization.\n\n#### Using Personal Access Token\n\n- Go to GitLab User Settings > Access Tokens\n- Click Add new token\n- Name: OpenCode, Scopes: api\n- Copy the token (starts with glpat-)\n- Enter it in the terminal\n- Run the /models command to see available models.\n/models\nThree Claude-based models are available:\n\nduo-chat-haiku-4-5 (Default) - Fast responses for quick tasks\nduo-chat-sonnet-4-5 - Balanced performance for most workflows\nduo-chat-opus-4-5 - Most capable for complex analysis\nRun the /models command to see available models.\n\n```\n/models\n```\n\nThree Claude-based models are available:\n\n- duo-chat-haiku-4-5 (Default) - Fast responses for quick tasks\n- duo-chat-sonnet-4-5 - Balanced performance for most workflows\n- duo-chat-opus-4-5 - Most capable for complex analysis\n[Self-Hosted GitLab](#self-hosted-gitlab) For self-hosted GitLab instances:\n\n```\nGITLAB_INSTANCE_URL=https://gitlab.company.com GITLAB_TOKEN=glpat-xxxxxxxxxxxxxxxxxxxx opencode\n```\n\nOr add to your bash profile:\n\n```\nexport GITLAB_INSTANCE_URL=https://gitlab.company.comexport GITLAB_TOKEN=glpat-xxxxxxxxxxxxxxxxxxxx\n```\n\nCustomize through opencode.json:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"gitlab\": {      \"options\": {        \"instanceUrl\": \"https://gitlab.com\",        \"featureFlags\": {          \"duo_agent_platform_agentic_chat\": true,          \"duo_agent_platform\": true        }      }    }  }}\n```\n\n[GitLab API Tools (Optional)](#gitlab-api-tools-optional) To access GitLab tools (merge requests, issues, pipelines, CI/CD, etc.):\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"plugin\": [\"@gitlab/opencode-gitlab-plugin\"]}\n```\n\nThis plugin provides comprehensive GitLab repository management capabilities including MR reviews, issue tracking, pipeline monitoring, and more.\n\n### GitHub Copilot\n\nTo use your GitHub Copilot subscription with opencode:\n\nNote\n\nSome models might need a Pro+\nsubscription to use.\n\nSome models need to be manually enabled in your GitHub Copilot settings.\n\n- Run the /connect command and search for GitHub Copilot.\n/connect\nRun the /connect command and search for GitHub Copilot.\n\n```\n/connect\n```\n\n- Navigate to github.com/login/device and enter the code.\n┌ Login with GitHub Copilot││ https://github.com/login/device││ Enter code: 8F43-6FCF│└ Waiting for authorization...\nNavigate to github.com/login/device and enter the code.\n\n```\n┌ Login with GitHub Copilot││ https://github.com/login/device││ Enter code: 8F43-6FCF│└ Waiting for authorization...\n```\n\n- Now run the /models command to select the model you want.\n/models\nNow run the /models command to select the model you want.\n\n```\n/models\n```\n\n### Google Vertex AI\n\nTo use Google Vertex AI with OpenCode:\n\n- Head over to the Model Garden in the Google Cloud Console and check the\nmodels available in your region.\nNoteYou need to have a Google Cloud project with Vertex AI API enabled.\nHead over to the Model Garden in the Google Cloud Console and check the\nmodels available in your region.\n\nNote\n\nYou need to have a Google Cloud project with Vertex AI API enabled.\n\n- Set the required environment variables:\n\nGOOGLE_CLOUD_PROJECT: Your Google Cloud project ID\nVERTEX_LOCATION (optional): The region for Vertex AI (defaults to global)\nAuthentication (choose one):\n\nGOOGLE_APPLICATION_CREDENTIALS: Path to your service account JSON key file\nAuthenticate using gcloud CLI: gcloud auth application-default login\n\nSet them while running opencode.\nTerminal windowGOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json GOOGLE_CLOUD_PROJECT=your-project-id opencode\nOr add them to your bash profile.\n~/.bash_profileexport GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.jsonexport GOOGLE_CLOUD_PROJECT=your-project-idexport VERTEX_LOCATION=global\nSet the required environment variables:\n\n- GOOGLE_CLOUD_PROJECT: Your Google Cloud project ID\n- VERTEX_LOCATION (optional): The region for Vertex AI (defaults to global)\n- Authentication (choose one):\n\nGOOGLE_APPLICATION_CREDENTIALS: Path to your service account JSON key file\nAuthenticate using gcloud CLI: gcloud auth application-default login\n- GOOGLE_APPLICATION_CREDENTIALS: Path to your service account JSON key file\n- Authenticate using gcloud CLI: gcloud auth application-default login\nSet them while running opencode.\n\n```\nGOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json GOOGLE_CLOUD_PROJECT=your-project-id opencode\n```\n\nOr add them to your bash profile.\n\n```\nexport GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.jsonexport GOOGLE_CLOUD_PROJECT=your-project-idexport VERTEX_LOCATION=global\n```\n\nTip\n\nThe global region improves availability and reduces errors at no extra cost. Use regional endpoints (e.g., us-central1) for data residency requirements. Learn more\n\n- Run the /models command to select the model you want.\n/models\nRun the /models command to select the model you want.\n\n```\n/models\n```\n\n### Groq\n\n- Head over to the Groq console, click Create API Key, and copy the key.\nHead over to the Groq console, click Create API Key, and copy the key.\n\n- Run the /connect command and search for Groq.\n/connect\nRun the /connect command and search for Groq.\n\n```\n/connect\n```\n\n- Enter the API key for the provider.\n┌ API key││└ enter\nEnter the API key for the provider.\n\n```\n┌ API key││└ enter\n```\n\n- Run the /models command to select the one you want.\n/models\nRun the /models command to select the one you want.\n\n```\n/models\n```\n\n### Hugging Face\n\nHugging Face Inference Providers provides access to open models supported by 17+ providers.\n\n- Head over to Hugging Face settings to create a token with permission to make calls to Inference Providers.\nHead over to Hugging Face settings to create a token with permission to make calls to Inference Providers.\n\n- Run the /connect command and search for Hugging Face.\n/connect\nRun the /connect command and search for Hugging Face.\n\n```\n/connect\n```\n\n- Enter your Hugging Face token.\n┌ API key││└ enter\nEnter your Hugging Face token.\n\n```\n┌ API key││└ enter\n```\n\n- Run the /models command to select a model like Kimi-K2-Instruct or GLM-4.6.\n/models\nRun the /models command to select a model like Kimi-K2-Instruct or GLM-4.6.\n\n```\n/models\n```\n\n### Helicone\n\nHelicone is an LLM observability platform that provides logging, monitoring, and analytics for your AI applications. The Helicone AI Gateway routes your requests to the appropriate provider automatically based on the model.\n\n- Head over to Helicone, create an account, and generate an API key from your dashboard.\nHead over to Helicone, create an account, and generate an API key from your dashboard.\n\n- Run the /connect command and search for Helicone.\n/connect\nRun the /connect command and search for Helicone.\n\n```\n/connect\n```\n\n- Enter your Helicone API key.\n┌ API key││└ enter\nEnter your Helicone API key.\n\n```\n┌ API key││└ enter\n```\n\n- Run the /models command to select a model.\n/models\nRun the /models command to select a model.\n\n```\n/models\n```\n\nFor more providers and advanced features like caching and rate limiting, check the Helicone documentation.\n\n#### Optional Configs\n\nIn the event you see a feature or model from Helicone that isn’t configured automatically through opencode, you can always configure it yourself.\n\nHere’s Helicone’s Model Directory, you’ll need this to grab the IDs of the models you want to add.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"helicone\": {      \"npm\": \"@ai-sdk/openai-compatible\",      \"name\": \"Helicone\",      \"options\": {        \"baseURL\": \"https://ai-gateway.helicone.ai\",      },      \"models\": {        \"gpt-4o\": {          // Model ID (from Helicone's model directory page)          \"name\": \"GPT-4o\", // Your own custom name for the model        },        \"claude-sonnet-4-20250514\": {          \"name\": \"Claude Sonnet 4\",        },      },    },  },}\n```\n\n#### Custom Headers\n\nHelicone supports custom headers for features like caching, user tracking, and session management. Add them to your provider config using options.headers:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"helicone\": {      \"npm\": \"@ai-sdk/openai-compatible\",      \"name\": \"Helicone\",      \"options\": {        \"baseURL\": \"https://ai-gateway.helicone.ai\",        \"headers\": {          \"Helicone-Cache-Enabled\": \"true\",          \"Helicone-User-Id\": \"opencode\",        },      },    },  },}\n```\n\n[Session tracking](#session-tracking) Helicone’s Sessions feature lets you group related LLM requests together. Use the opencode-helicone-session plugin to automatically log each OpenCode conversation as a session in Helicone.\n\n```\nnpm install -g opencode-helicone-session\n```\n\nAdd it to your config.\n\n```\n{  \"plugin\": [\"opencode-helicone-session\"]}\n```\n\nThe plugin injects Helicone-Session-Id and Helicone-Session-Name headers into your requests. In Helicone’s Sessions page, you’ll see each OpenCode conversation listed as a separate session.\n\n[Common Helicone headers](#common-helicone-headers) See the Helicone Header Directory for all available headers.\n\n### llama.cpp\n\nYou can configure opencode to use local models through llama.cpp’s llama-server utility\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"llama.cpp\": {      \"npm\": \"@ai-sdk/openai-compatible\",      \"name\": \"llama-server (local)\",      \"options\": {        \"baseURL\": \"http://127.0.0.1:8080/v1\"      },      \"models\": {        \"qwen3-coder:a3b\": {          \"name\": \"Qwen3-Coder: a3b-30b (local)\",          \"limit\": {            \"context\": 128000,            \"output\": 65536          }        }      }    }  }}\n```\n\nIn this example:\n\n- llama.cpp is the custom provider ID. This can be any string you want.\n- npm specifies the package to use for this provider. Here, @ai-sdk/openai-compatible is used for any OpenAI-compatible API.\n- name is the display name for the provider in the UI.\n- options.baseURL is the endpoint for the local server.\n- models is a map of model IDs to their configurations. The model name will be displayed in the model selection list.\n\n### IO.NET\n\nIO.NET offers 17 models optimized for various use cases:\n\n- Head over to the IO.NET console, create an account, and generate an API key.\nHead over to the IO.NET console, create an account, and generate an API key.\n\n- Run the /connect command and search for IO.NET.\n/connect\nRun the /connect command and search for IO.NET.\n\n```\n/connect\n```\n\n- Enter your IO.NET API key.\n┌ API key││└ enter\nEnter your IO.NET API key.\n\n```\n┌ API key││└ enter\n```\n\n- Run the /models command to select a model.\n/models\nRun the /models command to select a model.\n\n```\n/models\n```\n\n### LM Studio\n\nYou can configure opencode to use local models through LM Studio.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"lmstudio\": {      \"npm\": \"@ai-sdk/openai-compatible\",      \"name\": \"LM Studio (local)\",      \"options\": {        \"baseURL\": \"http://127.0.0.1:1234/v1\"      },      \"models\": {        \"google/gemma-3n-e4b\": {          \"name\": \"Gemma 3n-e4b (local)\"        }      }    }  }}\n```\n\nIn this example:\n\n- lmstudio is the custom provider ID. This can be any string you want.\n- npm specifies the package to use for this provider. Here, @ai-sdk/openai-compatible is used for any OpenAI-compatible API.\n- name is the display name for the provider in the UI.\n- options.baseURL is the endpoint for the local server.\n- models is a map of model IDs to their configurations. The model name will be displayed in the model selection list.\n\n### Moonshot AI\n\nTo use Kimi K2 from Moonshot AI:\n\n- Head over to the Moonshot AI console, create an account, and click Create API key.\nHead over to the Moonshot AI console, create an account, and click Create API key.\n\n- Run the /connect command and search for Moonshot AI.\n/connect\nRun the /connect command and search for Moonshot AI.\n\n```\n/connect\n```\n\n- Enter your Moonshot API key.\n┌ API key││└ enter\nEnter your Moonshot API key.\n\n```\n┌ API key││└ enter\n```\n\n- Run the /models command to select Kimi K2.\n/models\nRun the /models command to select Kimi K2.\n\n```\n/models\n```\n\n### MiniMax\n\n- Head over to the MiniMax API Console, create an account, and generate an API key.\nHead over to the MiniMax API Console, create an account, and generate an API key.\n\n- Run the /connect command and search for MiniMax.\n/connect\nRun the /connect command and search for MiniMax.\n\n```\n/connect\n```\n\n- Enter your MiniMax API key.\n┌ API key││└ enter\nEnter your MiniMax API key.\n\n```\n┌ API key││└ enter\n```\n\n- Run the /models command to select a model like M2.1.\n/models\nRun the /models command to select a model like M2.1.\n\n```\n/models\n```\n\n### Nebius Token Factory\n\n- Head over to the Nebius Token Factory console, create an account, and click Add Key.\nHead over to the Nebius Token Factory console, create an account, and click Add Key.\n\n- Run the /connect command and search for Nebius Token Factory.\n/connect\nRun the /connect command and search for Nebius Token Factory.\n\n```\n/connect\n```\n\n- Enter your Nebius Token Factory API key.\n┌ API key││└ enter\nEnter your Nebius Token Factory API key.\n\n```\n┌ API key││└ enter\n```\n\n- Run the /models command to select a model like Kimi K2 Instruct.\n/models\nRun the /models command to select a model like Kimi K2 Instruct.\n\n```\n/models\n```\n\n### Ollama\n\nYou can configure opencode to use local models through Ollama.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"ollama\": {      \"npm\": \"@ai-sdk/openai-compatible\",      \"name\": \"Ollama (local)\",      \"options\": {        \"baseURL\": \"http://localhost:11434/v1\"      },      \"models\": {        \"llama2\": {          \"name\": \"Llama 2\"        }      }    }  }}\n```\n\nIn this example:\n\n- ollama is the custom provider ID. This can be any string you want.\n- npm specifies the package to use for this provider. Here, @ai-sdk/openai-compatible is used for any OpenAI-compatible API.\n- name is the display name for the provider in the UI.\n- options.baseURL is the endpoint for the local server.\n- models is a map of model IDs to their configurations. The model name will be displayed in the model selection list.\nTip\n\nIf tool calls aren’t working, try increasing num_ctx in Ollama. Start around 16k - 32k.\n\n### Ollama Cloud\n\nTo use Ollama Cloud with OpenCode:\n\n- Head over to https://ollama.com/ and sign in or create an account.\nHead over to https://ollama.com/ and sign in or create an account.\n\n- Navigate to Settings > Keys and click Add API Key to generate a new API key.\nNavigate to Settings > Keys and click Add API Key to generate a new API key.\n\n- Copy the API key for use in OpenCode.\nCopy the API key for use in OpenCode.\n\n- Run the /connect command and search for Ollama Cloud.\n/connect\nRun the /connect command and search for Ollama Cloud.\n\n```\n/connect\n```\n\n- Enter your Ollama Cloud API key.\n┌ API key││└ enter\nEnter your Ollama Cloud API key.\n\n```\n┌ API key││└ enter\n```\n\n- Important: Before using cloud models in OpenCode, you must pull the model information locally:\nTerminal windowollama pull gpt-oss:20b-cloud\nImportant: Before using cloud models in OpenCode, you must pull the model information locally:\n\n```\nollama pull gpt-oss:20b-cloud\n```\n\n- Run the /models command to select your Ollama Cloud model.\n/models\nRun the /models command to select your Ollama Cloud model.\n\n```\n/models\n```\n\n### OpenAI\n\nWe recommend signing up for ChatGPT Plus or Pro.\n\n- Once you’ve signed up, run the /connect command and select OpenAI.\n/connect\nOnce you’ve signed up, run the /connect command and select OpenAI.\n\n```\n/connect\n```\n\n- Here you can select the ChatGPT Plus/Pro option and it’ll open your browser\nand ask you to authenticate.\n┌ Select auth method││ ChatGPT Plus/Pro│ Manually enter API Key└\nHere you can select the ChatGPT Plus/Pro option and it’ll open your browser\nand ask you to authenticate.\n\n```\n┌ Select auth method││ ChatGPT Plus/Pro│ Manually enter API Key└\n```\n\n- Now all the OpenAI models should be available when you use the /models command.\n/models\nNow all the OpenAI models should be available when you use the /models command.\n\n```\n/models\n```\n\nIf you already have an API key, you can select Manually enter API Key and paste it in your terminal.\n\n### OpenCode Zen\n\nOpenCode Zen is a list of tested and verified models provided by the OpenCode team. Learn more.\n\n- Sign in to OpenCode Zen and click Create API Key.\nSign in to OpenCode Zen and click Create API Key.\n\n- Run the /connect command and search for OpenCode Zen.\n/connect\nRun the /connect command and search for OpenCode Zen.\n\n```\n/connect\n```\n\n- Enter your OpenCode API key.\n┌ API key││└ enter\nEnter your OpenCode API key.\n\n```\n┌ API key││└ enter\n```\n\n- Run the /models command to select a model like Qwen 3 Coder 480B.\n/models\nRun the /models command to select a model like Qwen 3 Coder 480B.\n\n```\n/models\n```\n\n### OpenRouter\n\n- Head over to the OpenRouter dashboard, click Create API Key, and copy the key.\nHead over to the OpenRouter dashboard, click Create API Key, and copy the key.\n\n- Run the /connect command and search for OpenRouter.\n/connect\nRun the /connect command and search for OpenRouter.\n\n```\n/connect\n```\n\n- Enter the API key for the provider.\n┌ API key││└ enter\nEnter the API key for the provider.\n\n```\n┌ API key││└ enter\n```\n\n- Many OpenRouter models are preloaded by default, run the /models command to select the one you want.\n/models\nYou can also add additional models through your opencode config.\nopencode.json{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"openrouter\": {      \"models\": {        \"somecoolnewmodel\": {}      }    }  }}\nMany OpenRouter models are preloaded by default, run the /models command to select the one you want.\n\n```\n/models\n```\n\nYou can also add additional models through your opencode config.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"openrouter\": {      \"models\": {        \"somecoolnewmodel\": {}      }    }  }}\n```\n\n- You can also customize them through your opencode config. Here’s an example of specifying a provider\nopencode.json{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"openrouter\": {      \"models\": {        \"moonshotai/kimi-k2\": {          \"options\": {            \"provider\": {              \"order\": [\"baseten\"],              \"allow_fallbacks\": false            }          }        }      }    }  }}\nYou can also customize them through your opencode config. Here’s an example of specifying a provider\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"openrouter\": {      \"models\": {        \"moonshotai/kimi-k2\": {          \"options\": {            \"provider\": {              \"order\": [\"baseten\"],              \"allow_fallbacks\": false            }          }        }      }    }  }}\n```\n\n### SAP AI Core\n\nSAP AI Core provides access to 40+ models from OpenAI, Anthropic, Google, Amazon, Meta, Mistral, and AI21 through a unified platform.\n\n- Go to your SAP BTP Cockpit, navigate to your SAP AI Core service instance, and create a service key.\nTipThe service key is a JSON object containing clientid, clientsecret, url, and serviceurls.AI_API_URL. You can find your AI Core instance under Services > Instances and Subscriptions in the BTP Cockpit.\nGo to your SAP BTP Cockpit, navigate to your SAP AI Core service instance, and create a service key.\n\nTip\n\nThe service key is a JSON object containing clientid, clientsecret, url, and serviceurls.AI_API_URL. You can find your AI Core instance under Services > Instances and Subscriptions in the BTP Cockpit.\n\n- Run the /connect command and search for SAP AI Core.\n/connect\nRun the /connect command and search for SAP AI Core.\n\n```\n/connect\n```\n\n- Enter your service key JSON.\n┌ Service key││└ enter\nOr set the AICORE_SERVICE_KEY environment variable:\nTerminal windowAICORE_SERVICE_KEY='{\"clientid\":\"...\",\"clientsecret\":\"...\",\"url\":\"...\",\"serviceurls\":{\"AI_API_URL\":\"...\"}}' opencode\nOr add it to your bash profile:\n~/.bash_profileexport AICORE_SERVICE_KEY='{\"clientid\":\"...\",\"clientsecret\":\"...\",\"url\":\"...\",\"serviceurls\":{\"AI_API_URL\":\"...\"}}'\nEnter your service key JSON.\n\n```\n┌ Service key││└ enter\n```\n\nOr set the AICORE_SERVICE_KEY environment variable:\n\n```\nAICORE_SERVICE_KEY='{\"clientid\":\"...\",\"clientsecret\":\"...\",\"url\":\"...\",\"serviceurls\":{\"AI_API_URL\":\"...\"}}' opencode\n```\n\nOr add it to your bash profile:\n\n```\nexport AICORE_SERVICE_KEY='{\"clientid\":\"...\",\"clientsecret\":\"...\",\"url\":\"...\",\"serviceurls\":{\"AI_API_URL\":\"...\"}}'\n```\n\n- Optionally set deployment ID and resource group:\nTerminal windowAICORE_DEPLOYMENT_ID=your-deployment-id AICORE_RESOURCE_GROUP=your-resource-group opencode\nNoteThese settings are optional and should be configured according to your SAP AI Core setup.\nOptionally set deployment ID and resource group:\n\n```\nAICORE_DEPLOYMENT_ID=your-deployment-id AICORE_RESOURCE_GROUP=your-resource-group opencode\n```\n\nNote\n\nThese settings are optional and should be configured according to your SAP AI Core setup.\n\n- Run the /models command to select from 40+ available models.\n/models\nRun the /models command to select from 40+ available models.\n\n```\n/models\n```\n\n### OVHcloud AI Endpoints\n\n- Head over to the OVHcloud panel. Navigate to the Public Cloud section, AI & Machine Learning > AI Endpoints and in API Keys tab, click Create a new API key.\nHead over to the OVHcloud panel. Navigate to the Public Cloud section, AI & Machine Learning > AI Endpoints and in API Keys tab, click Create a new API key.\n\n- Run the /connect command and search for OVHcloud AI Endpoints.\n/connect\nRun the /connect command and search for OVHcloud AI Endpoints.\n\n```\n/connect\n```\n\n- Enter your OVHcloud AI Endpoints API key.\n┌ API key││└ enter\nEnter your OVHcloud AI Endpoints API key.\n\n```\n┌ API key││└ enter\n```\n\n- Run the /models command to select a model like gpt-oss-120b.\n/models\nRun the /models command to select a model like gpt-oss-120b.\n\n```\n/models\n```\n\n### Scaleway\n\nTo use Scaleway Generative APIs with Opencode:\n\n- Head over to the Scaleway Console IAM settings to generate a new API key.\nHead over to the Scaleway Console IAM settings to generate a new API key.\n\n- Run the /connect command and search for Scaleway.\n/connect\nRun the /connect command and search for Scaleway.\n\n```\n/connect\n```\n\n- Enter your Scaleway API key.\n┌ API key││└ enter\nEnter your Scaleway API key.\n\n```\n┌ API key││└ enter\n```\n\n- Run the /models command to select a model like devstral-2-123b-instruct-2512 or gpt-oss-120b.\n/models\nRun the /models command to select a model like devstral-2-123b-instruct-2512 or gpt-oss-120b.\n\n```\n/models\n```\n\n### Together AI\n\n- Head over to the Together AI console, create an account, and click Add Key.\nHead over to the Together AI console, create an account, and click Add Key.\n\n- Run the /connect command and search for Together AI.\n/connect\nRun the /connect command and search for Together AI.\n\n```\n/connect\n```\n\n- Enter your Together AI API key.\n┌ API key││└ enter\nEnter your Together AI API key.\n\n```\n┌ API key││└ enter\n```\n\n- Run the /models command to select a model like Kimi K2 Instruct.\n/models\nRun the /models command to select a model like Kimi K2 Instruct.\n\n```\n/models\n```\n\n### Venice AI\n\n- Head over to the Venice AI console, create an account, and generate an API key.\nHead over to the Venice AI console, create an account, and generate an API key.\n\n- Run the /connect command and search for Venice AI.\n/connect\nRun the /connect command and search for Venice AI.\n\n```\n/connect\n```\n\n- Enter your Venice AI API key.\n┌ API key││└ enter\nEnter your Venice AI API key.\n\n```\n┌ API key││└ enter\n```\n\n- Run the /models command to select a model like Llama 3.3 70B.\n/models\nRun the /models command to select a model like Llama 3.3 70B.\n\n```\n/models\n```\n\n### Vercel AI Gateway\n\nVercel AI Gateway lets you access models from OpenAI, Anthropic, Google, xAI, and more through a unified endpoint. Models are offered at list price with no markup.\n\n- Head over to the Vercel dashboard, navigate to the AI Gateway tab, and click API keys to create a new API key.\nHead over to the Vercel dashboard, navigate to the AI Gateway tab, and click API keys to create a new API key.\n\n- Run the /connect command and search for Vercel AI Gateway.\n/connect\nRun the /connect command and search for Vercel AI Gateway.\n\n```\n/connect\n```\n\n- Enter your Vercel AI Gateway API key.\n┌ API key││└ enter\nEnter your Vercel AI Gateway API key.\n\n```\n┌ API key││└ enter\n```\n\n- Run the /models command to select a model.\n/models\nRun the /models command to select a model.\n\n```\n/models\n```\n\nYou can also customize models through your opencode config. Here’s an example of specifying provider routing order.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"vercel\": {      \"models\": {        \"anthropic/claude-sonnet-4\": {          \"options\": {            \"order\": [\"anthropic\", \"vertex\"]          }        }      }    }  }}\n```\n\nSome useful routing options:\n\n### xAI\n\n- Head over to the xAI console, create an account, and generate an API key.\nHead over to the xAI console, create an account, and generate an API key.\n\n- Run the /connect command and search for xAI.\n/connect\nRun the /connect command and search for xAI.\n\n```\n/connect\n```\n\n- Enter your xAI API key.\n┌ API key││└ enter\nEnter your xAI API key.\n\n```\n┌ API key││└ enter\n```\n\n- Run the /models command to select a model like Grok Beta.\n/models\nRun the /models command to select a model like Grok Beta.\n\n```\n/models\n```\n\n### Z.AI\n\n- Head over to the Z.AI API console, create an account, and click Create a new API key.\nHead over to the Z.AI API console, create an account, and click Create a new API key.\n\n- Run the /connect command and search for Z.AI.\n/connect\nIf you are subscribed to the GLM Coding Plan, select Z.AI Coding Plan.\nRun the /connect command and search for Z.AI.\n\n```\n/connect\n```\n\nIf you are subscribed to the GLM Coding Plan, select Z.AI Coding Plan.\n\n- Enter your Z.AI API key.\n┌ API key││└ enter\nEnter your Z.AI API key.\n\n```\n┌ API key││└ enter\n```\n\n- Run the /models command to select a model like GLM-4.7.\n/models\nRun the /models command to select a model like GLM-4.7.\n\n```\n/models\n```\n\n### ZenMux\n\n- Head over to the ZenMux dashboard, click Create API Key, and copy the key.\nHead over to the ZenMux dashboard, click Create API Key, and copy the key.\n\n- Run the /connect command and search for ZenMux.\n/connect\nRun the /connect command and search for ZenMux.\n\n```\n/connect\n```\n\n- Enter the API key for the provider.\n┌ API key││└ enter\nEnter the API key for the provider.\n\n```\n┌ API key││└ enter\n```\n\n- Many ZenMux models are preloaded by default, run the /models command to select the one you want.\n/models\nYou can also add additional models through your opencode config.\nopencode.json{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"zenmux\": {      \"models\": {        \"somecoolnewmodel\": {}      }    }  }}\nMany ZenMux models are preloaded by default, run the /models command to select the one you want.\n\n```\n/models\n```\n\nYou can also add additional models through your opencode config.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"zenmux\": {      \"models\": {        \"somecoolnewmodel\": {}      }    }  }}\n```\n\n## Custom provider\n\nTo add any OpenAI-compatible provider that’s not listed in the /connect command:\n\nTip\n\nYou can use any OpenAI-compatible provider with opencode. Most modern AI providers offer OpenAI-compatible APIs.\n\n- Run the /connect command and scroll down to Other.\nTerminal window$ /connect\n┌  Add credential│◆  Select provider│  ...│  ● Other└\nRun the /connect command and scroll down to Other.\n\n```\n$ /connect\n┌  Add credential│◆  Select provider│  ...│  ● Other└\n```\n\n- Enter a unique ID for the provider.\nTerminal window$ /connect\n┌  Add credential│◇  Enter provider id│  myprovider└\nNoteChoose a memorable ID, you’ll use this in your config file.\nEnter a unique ID for the provider.\n\n```\n$ /connect\n┌  Add credential│◇  Enter provider id│  myprovider└\n```\n\nNote\n\nChoose a memorable ID, you’ll use this in your config file.\n\n- Enter your API key for the provider.\nTerminal window$ /connect\n┌  Add credential│▲  This only stores a credential for myprovider - you will need to configure it in opencode.json, check the docs for examples.│◇  Enter your API key│  sk-...└\nEnter your API key for the provider.\n\n```\n$ /connect\n┌  Add credential│▲  This only stores a credential for myprovider - you will need to configure it in opencode.json, check the docs for examples.│◇  Enter your API key│  sk-...└\n```\n\n- Create or update your opencode.json file in your project directory:\nopencode.json{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"myprovider\": {      \"npm\": \"@ai-sdk/openai-compatible\",      \"name\": \"My AI ProviderDisplay Name\",      \"options\": {        \"baseURL\": \"https://api.myprovider.com/v1\"      },      \"models\": {        \"my-model-name\": {          \"name\": \"My Model Display Name\"        }      }    }  }}\nHere are the configuration options:\n\nnpm: AI SDK package to use, @ai-sdk/openai-compatible for OpenAI-compatible providers\nname: Display name in UI.\nmodels: Available models.\noptions.baseURL: API endpoint URL.\noptions.apiKey: Optionally set the API key, if not using auth.\noptions.headers: Optionally set custom headers.\n\nMore on the advanced options in the example below.\nCreate or update your opencode.json file in your project directory:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"myprovider\": {      \"npm\": \"@ai-sdk/openai-compatible\",      \"name\": \"My AI ProviderDisplay Name\",      \"options\": {        \"baseURL\": \"https://api.myprovider.com/v1\"      },      \"models\": {        \"my-model-name\": {          \"name\": \"My Model Display Name\"        }      }    }  }}\n```\n\nHere are the configuration options:\n\n- npm: AI SDK package to use, @ai-sdk/openai-compatible for OpenAI-compatible providers\n- name: Display name in UI.\n- models: Available models.\n- options.baseURL: API endpoint URL.\n- options.apiKey: Optionally set the API key, if not using auth.\n- options.headers: Optionally set custom headers.\nMore on the advanced options in the example below.\n\n- Run the /models command and your custom provider and models will appear in the selection list.\nRun the /models command and your custom provider and models will appear in the selection list.\n\n[Example](#example) Here’s an example setting the apiKey, headers, and model limit options.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"myprovider\": {      \"npm\": \"@ai-sdk/openai-compatible\",      \"name\": \"My AI ProviderDisplay Name\",      \"options\": {        \"baseURL\": \"https://api.myprovider.com/v1\",        \"apiKey\": \"{env:ANTHROPIC_API_KEY}\",        \"headers\": {          \"Authorization\": \"Bearer custom-token\"        }      },      \"models\": {        \"my-model-name\": {          \"name\": \"My Model Display Name\",          \"limit\": {            \"context\": 200000,            \"output\": 65536          }        }      }    }  }}\n```\n\nConfiguration details:\n\n- apiKey: Set using env variable syntax, learn more.\n- headers: Custom headers sent with each request.\n- limit.context: Maximum input tokens the model accepts.\n- limit.output: Maximum tokens the model can generate.\nThe limit fields allow OpenCode to understand how much context you have left. Standard providers pull these from models.dev automatically.\n\n## Troubleshooting\n\nIf you are having trouble with configuring a provider, check the following:\n\n- Check the auth setup: Run opencode auth list to see if the credentials\nfor the provider are added to your config.\nThis doesn’t apply to providers like Amazon Bedrock, that rely on environment variables for their auth.\nCheck the auth setup: Run opencode auth list to see if the credentials\nfor the provider are added to your config.\n\nThis doesn’t apply to providers like Amazon Bedrock, that rely on environment variables for their auth.\n\n- For custom providers, check the opencode config and:\n\nMake sure the provider ID used in the /connect command matches the ID in your opencode config.\nThe right npm package is used for the provider. For example, use @ai-sdk/cerebras for Cerebras. And for all other OpenAI-compatible providers, use @ai-sdk/openai-compatible.\nCheck correct API endpoint is used in the options.baseURL field.\nFor custom providers, check the opencode config and:\n\n- Make sure the provider ID used in the /connect command matches the ID in your opencode config.\n- The right npm package is used for the provider. For example, use @ai-sdk/cerebras for Cerebras. And for all other OpenAI-compatible providers, use @ai-sdk/openai-compatible.\n- Check correct API endpoint is used in the options.baseURL field.\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/providers.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "Providers",
          "id": "_top"
        },
        {
          "level": 3,
          "text": "Credentials",
          "id": "credentials"
        },
        {
          "level": 3,
          "text": "Config",
          "id": "config"
        },
        {
          "level": 4,
          "text": "Base URL",
          "id": "base-url"
        },
        {
          "level": 2,
          "text": "OpenCode Zen",
          "id": "opencode-zen"
        },
        {
          "level": 2,
          "text": "Directory",
          "id": "directory"
        },
        {
          "level": 3,
          "text": "302.AI",
          "id": "302ai"
        },
        {
          "level": 3,
          "text": "Amazon Bedrock",
          "id": "amazon-bedrock"
        },
        {
          "level": 4,
          "text": "Environment Variables (Quick Start)",
          "id": "environment-variables-quick-start"
        },
        {
          "level": 4,
          "text": "Configuration File (Recommended)",
          "id": "configuration-file-recommended"
        },
        {
          "level": 4,
          "text": "Advanced: VPC Endpoints",
          "id": "advanced-vpc-endpoints"
        },
        {
          "level": 4,
          "text": "Authentication Methods",
          "id": "authentication-methods"
        },
        {
          "level": 4,
          "text": "Authentication Precedence",
          "id": "authentication-precedence"
        },
        {
          "level": 3,
          "text": "Anthropic",
          "id": "anthropic"
        },
        {
          "level": 5,
          "text": "Using API keys",
          "id": "using-api-keys"
        },
        {
          "level": 3,
          "text": "Azure OpenAI",
          "id": "azure-openai"
        },
        {
          "level": 3,
          "text": "Azure Cognitive Services",
          "id": "azure-cognitive-services"
        },
        {
          "level": 3,
          "text": "Baseten",
          "id": "baseten"
        },
        {
          "level": 3,
          "text": "Cerebras",
          "id": "cerebras"
        },
        {
          "level": 3,
          "text": "Cloudflare AI Gateway",
          "id": "cloudflare-ai-gateway"
        },
        {
          "level": 3,
          "text": "Cortecs",
          "id": "cortecs"
        },
        {
          "level": 3,
          "text": "DeepSeek",
          "id": "deepseek"
        },
        {
          "level": 3,
          "text": "Deep Infra",
          "id": "deep-infra"
        },
        {
          "level": 3,
          "text": "Fireworks AI",
          "id": "fireworks-ai"
        },
        {
          "level": 3,
          "text": "GitLab Duo",
          "id": "gitlab-duo"
        },
        {
          "level": 4,
          "text": "Using OAuth (Recommended)",
          "id": "using-oauth-recommended"
        },
        {
          "level": 4,
          "text": "Using Personal Access Token",
          "id": "using-personal-access-token"
        },
        {
          "level": 5,
          "text": "Self-Hosted GitLab",
          "id": "self-hosted-gitlab"
        },
        {
          "level": 5,
          "text": "Configuration",
          "id": "configuration"
        },
        {
          "level": 5,
          "text": "GitLab API Tools (Optional)",
          "id": "gitlab-api-tools-optional"
        },
        {
          "level": 3,
          "text": "GitHub Copilot",
          "id": "github-copilot"
        },
        {
          "level": 3,
          "text": "Google Vertex AI",
          "id": "google-vertex-ai"
        },
        {
          "level": 3,
          "text": "Groq",
          "id": "groq"
        },
        {
          "level": 3,
          "text": "Hugging Face",
          "id": "hugging-face"
        },
        {
          "level": 3,
          "text": "Helicone",
          "id": "helicone"
        },
        {
          "level": 4,
          "text": "Optional Configs",
          "id": "optional-configs"
        },
        {
          "level": 4,
          "text": "Custom Headers",
          "id": "custom-headers"
        },
        {
          "level": 5,
          "text": "Session tracking",
          "id": "session-tracking"
        },
        {
          "level": 5,
          "text": "Common Helicone headers",
          "id": "common-helicone-headers"
        },
        {
          "level": 3,
          "text": "llama.cpp",
          "id": "llamacpp"
        },
        {
          "level": 3,
          "text": "IO.NET",
          "id": "ionet"
        },
        {
          "level": 3,
          "text": "LM Studio",
          "id": "lm-studio"
        },
        {
          "level": 3,
          "text": "Moonshot AI",
          "id": "moonshot-ai"
        },
        {
          "level": 3,
          "text": "MiniMax",
          "id": "minimax"
        },
        {
          "level": 3,
          "text": "Nebius Token Factory",
          "id": "nebius-token-factory"
        },
        {
          "level": 3,
          "text": "Ollama",
          "id": "ollama"
        },
        {
          "level": 3,
          "text": "Ollama Cloud",
          "id": "ollama-cloud"
        },
        {
          "level": 3,
          "text": "OpenAI",
          "id": "openai"
        },
        {
          "level": 5,
          "text": "Using API keys",
          "id": "using-api-keys-1"
        },
        {
          "level": 3,
          "text": "OpenCode Zen",
          "id": "opencode-zen-1"
        },
        {
          "level": 3,
          "text": "OpenRouter",
          "id": "openrouter"
        },
        {
          "level": 3,
          "text": "SAP AI Core",
          "id": "sap-ai-core"
        },
        {
          "level": 3,
          "text": "OVHcloud AI Endpoints",
          "id": "ovhcloud-ai-endpoints"
        },
        {
          "level": 3,
          "text": "Scaleway",
          "id": "scaleway"
        },
        {
          "level": 3,
          "text": "Together AI",
          "id": "together-ai"
        },
        {
          "level": 3,
          "text": "Venice AI",
          "id": "venice-ai"
        },
        {
          "level": 3,
          "text": "Vercel AI Gateway",
          "id": "vercel-ai-gateway"
        },
        {
          "level": 3,
          "text": "xAI",
          "id": "xai"
        },
        {
          "level": 3,
          "text": "Z.AI",
          "id": "zai"
        },
        {
          "level": 3,
          "text": "ZenMux",
          "id": "zenmux"
        },
        {
          "level": 2,
          "text": "Custom provider",
          "id": "custom-provider"
        },
        {
          "level": 5,
          "text": "Example",
          "id": "example"
        },
        {
          "level": 2,
          "text": "Troubleshooting",
          "id": "troubleshooting"
        }
      ],
      "category": "Getting Started",
      "scrapedAt": 1768685267276
    },
    {
      "path": "/docs/network/",
      "title": "Network",
      "url": "https://opencode.ai/docs/network/",
      "content": "# Network\n\nConfigure proxies and custom certificates.\n\nOpenCode supports standard proxy environment variables and custom certificates for enterprise network environments.\n\n## Proxy\n\nOpenCode respects standard proxy environment variables.\n\n```\n# HTTPS proxy (recommended)export HTTPS_PROXY=https://proxy.example.com:8080\n# HTTP proxy (if HTTPS not available)export HTTP_PROXY=http://proxy.example.com:8080\n# Bypass proxy for local server (required)export NO_PROXY=localhost,127.0.0.1\n```\n\nCaution\n\nThe TUI communicates with a local HTTP server. You must bypass the proxy for this connection to prevent routing loops.\n\nYou can configure the server’s port and hostname using CLI flags.\n\n### Authenticate\n\nIf your proxy requires basic authentication, include credentials in the URL.\n\n```\nexport HTTPS_PROXY=http://username:password@proxy.example.com:8080\n```\n\nCaution\n\nAvoid hardcoding passwords. Use environment variables or secure credential storage.\n\nFor proxies requiring advanced authentication like NTLM or Kerberos, consider using an LLM Gateway that supports your authentication method.\n\n## Custom certificates\n\nIf your enterprise uses custom CAs for HTTPS connections, configure OpenCode to trust them.\n\n```\nexport NODE_EXTRA_CA_CERTS=/path/to/ca-cert.pem\n```\n\nThis works for both proxy connections and direct API access.\n\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/network.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "Network",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "Proxy",
          "id": "proxy"
        },
        {
          "level": 3,
          "text": "Authenticate",
          "id": "authenticate"
        },
        {
          "level": 2,
          "text": "Custom certificates",
          "id": "custom-certificates"
        }
      ],
      "category": "Getting Started",
      "scrapedAt": 1768685267627
    },
    {
      "path": "/docs/enterprise/",
      "title": "Enterprise",
      "url": "https://opencode.ai/docs/enterprise/",
      "content": "# Enterprise\n\nUsing OpenCode securely in your organization.\n\nOpenCode Enterprise is for organizations that want to ensure that their code and data never leaves their infrastructure. It can do this by using a centralized config that integrates with your SSO and internal AI gateway.\n\nNote\n\nOpenCode does not store any of your code or context data.\n\nTo get started with OpenCode Enterprise:\n\n- Do a trial internally with your team.\n- Contact us to discuss pricing and implementation options.\n\n## Trial\n\nOpenCode is open source and does not store any of your code or context data, so your developers can simply get started and carry out a trial.\n\n### Data handling\n\nOpenCode does not store your code or context data. All processing happens locally or through direct API calls to your AI provider.\n\nThis means that as long as you are using a provider you trust, or an internal\nAI gateway, you can use OpenCode securely.\n\nThe only caveat here is the optional /share feature.\n\n#### Sharing conversations\n\nIf a user enables the /share feature, the conversation and the data associated with it are sent to the service we use to host these share pages at opencode.ai.\n\nThe data is currently served through our CDN’s edge network, and is cached on the edge near your users.\n\nWe recommend you disable this for your trial.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"share\": \"disabled\"}\n```\n\nLearn more about sharing.\n\n### Code ownership\n\nYou own all code produced by OpenCode. There are no licensing restrictions or ownership claims.\n\n## Pricing\n\nWe use a per-seat model for OpenCode Enterprise. If you have your own LLM gateway, we do not charge for tokens used. For further details about pricing and implementation options, contact us.\n\n## Deployment\n\nOnce you have completed your trial and you are ready to use OpenCode at\nyour organization, you can contact us to discuss\npricing and implementation options.\n\n### Central Config\n\nWe can set up OpenCode to use a single central config for your entire organization.\n\nThis centralized config can integrate with your SSO provider and ensures all users access only your internal AI gateway.\n\n### SSO integration\n\nThrough the central config, OpenCode can integrate with your organization’s SSO provider for authentication.\n\nThis allows OpenCode to obtain credentials for your internal AI gateway through your existing identity management system.\n\n### Internal AI gateway\n\nWith the central config, OpenCode can also be configured to use only your internal AI gateway.\n\nYou can also disable all other AI providers, ensuring all requests go through your organization’s approved infrastructure.\n\n### Self-hosting\n\nWhile we recommend disabling the share pages to ensure your data never leaves\nyour organization, we can also help you self-host them on your infrastructure.\n\nThis is currently on our roadmap. If you’re interested, let us know.\n\n## FAQ\n\nOpenCode Enterprise is for organizations that want to ensure that their code and data never leaves their infrastructure. It can do this by using a centralized config that integrates with your SSO and internal AI gateway.\n\nSimply start with an internal trial with your team. OpenCode by default does not store your code or context data, making it easy to get started.\n\nThen contact us to discuss pricing and implementation options.\n\nWe offer per-seat enterprise pricing. If you have your own LLM gateway, we do not charge for tokens used. For further details, contact us for a custom quote based on your organization’s needs.\n\nYes. OpenCode does not store your code or context data. All processing happens locally or through direct API calls to your AI provider. With central config and SSO integration, your data remains secure within your organization’s infrastructure.\n\nOpenCode supports private npm registries through Bun’s native .npmrc file support. If your organization uses a private registry, such as JFrog Artifactory, Nexus, or similar, ensure developers are authenticated before running OpenCode.\n\nTo set up authentication with your private registry:\n\n```\nnpm login --registry=https://your-company.jfrog.io/api/npm/npm-virtual/\n```\n\nThis creates ~/.npmrc with authentication details. OpenCode will automatically\npick this up.\n\nCaution\n\nYou must be logged into the private registry before running OpenCode.\n\nAlternatively, you can manually configure a .npmrc file:\n\n```\nregistry=https://your-company.jfrog.io/api/npm/npm-virtual///your-company.jfrog.io/api/npm/npm-virtual/:_authToken=${NPM_AUTH_TOKEN}\n```\n\nDevelopers must be logged into the private registry before running OpenCode to ensure packages can be installed from your enterprise registry.\n\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/enterprise.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "Enterprise",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "Trial",
          "id": "trial"
        },
        {
          "level": 3,
          "text": "Data handling",
          "id": "data-handling"
        },
        {
          "level": 4,
          "text": "Sharing conversations",
          "id": "sharing-conversations"
        },
        {
          "level": 3,
          "text": "Code ownership",
          "id": "code-ownership"
        },
        {
          "level": 2,
          "text": "Pricing",
          "id": "pricing"
        },
        {
          "level": 2,
          "text": "Deployment",
          "id": "deployment"
        },
        {
          "level": 3,
          "text": "Central Config",
          "id": "central-config"
        },
        {
          "level": 3,
          "text": "SSO integration",
          "id": "sso-integration"
        },
        {
          "level": 3,
          "text": "Internal AI gateway",
          "id": "internal-ai-gateway"
        },
        {
          "level": 3,
          "text": "Self-hosting",
          "id": "self-hosting"
        },
        {
          "level": 2,
          "text": "FAQ",
          "id": "faq"
        }
      ],
      "category": "Getting Started",
      "scrapedAt": 1768685267974
    },
    {
      "path": "/docs/troubleshooting/",
      "title": "Troubleshooting",
      "url": "https://opencode.ai/docs/troubleshooting/",
      "content": "# Troubleshooting\n\nCommon issues and how to resolve them.\n\nTo debug any issues with OpenCode, you can check the logs or the session data\nthat it stores locally.\n\n### Logs\n\nLog files are written to:\n\n- macOS/Linux: ~/.local/share/opencode/log/\n- Windows: %USERPROFILE%\\.local\\share\\opencode\\log\\\nLog files are named with timestamps (e.g., 2025-01-09T123456.log) and the most recent 10 log files are kept.\n\nYou can set the log level with the --log-level command-line option to get more detailed debug information. For example, opencode --log-level DEBUG.\n\n### Storage\n\nopencode stores session data and other application data on disk at:\n\n- macOS/Linux: ~/.local/share/opencode/\n- Windows: %USERPROFILE%\\.local\\share\\opencode\nThis directory contains:\n\n- auth.json - Authentication data like API keys, OAuth tokens\n- log/ - Application logs\n- project/ - Project-specific data like session and message data\n\nIf the project is within a Git repo, it is stored in ./<project-slug>/storage/\nIf it is not a Git repo, it is stored in ./global/storage/\n- If the project is within a Git repo, it is stored in ./<project-slug>/storage/\n- If it is not a Git repo, it is stored in ./global/storage/\n\n## Getting help\n\nIf you’re experiencing issues with OpenCode:\n\n- Report issues on GitHub\nThe best way to report bugs or request features is through our GitHub repository:\ngithub.com/anomalyco/opencode/issues\nBefore creating a new issue, search existing issues to see if your problem has already been reported.\nReport issues on GitHub\n\nThe best way to report bugs or request features is through our GitHub repository:\n\ngithub.com/anomalyco/opencode/issues\n\nBefore creating a new issue, search existing issues to see if your problem has already been reported.\n\n- Join our Discord\nFor real-time help and community discussion, join our Discord server:\nopencode.ai/discord\nJoin our Discord\n\nFor real-time help and community discussion, join our Discord server:\n\nopencode.ai/discord\n\n## Common issues\n\nHere are some common issues and how to resolve them.\n\n### OpenCode won’t start\n\n- Check the logs for error messages\n- Try running with --print-logs to see output in the terminal\n- Ensure you have the latest version with opencode upgrade\n\n### Authentication issues\n\n- Try re-authenticating with the /connect command in the TUI\n- Check that your API keys are valid\n- Ensure your network allows connections to the provider’s API\n\n### Model not available\n\n- Check that you’ve authenticated with the provider\n- Verify the model name in your config is correct\n- Some models may require specific access or subscriptions\nIf you encounter ProviderModelNotFoundError you are most likely incorrectly\nreferencing a model somewhere.\nModels should be referenced like so: <providerId>/<modelId>\n\nExamples:\n\n- openai/gpt-4.1\n- openrouter/google/gemini-2.5-flash\n- opencode/kimi-k2\nTo figure out what models you have access to, run opencode models\n\n### ProviderInitError\n\nIf you encounter a ProviderInitError, you likely have an invalid or corrupted configuration.\n\nTo resolve this:\n\n- First, verify your provider is set up correctly by following the providers guide\nFirst, verify your provider is set up correctly by following the providers guide\n\n- If the issue persists, try clearing your stored configuration:\nTerminal windowrm -rf ~/.local/share/opencode\nIf the issue persists, try clearing your stored configuration:\n\n```\nrm -rf ~/.local/share/opencode\n```\n\n- Re-authenticate with your provider using the /connect command in the TUI.\nRe-authenticate with your provider using the /connect command in the TUI.\n\n### AI_APICallError and provider package issues\n\nIf you encounter API call errors, this may be due to outdated provider packages. opencode dynamically installs provider packages (OpenAI, Anthropic, Google, etc.) as needed and caches them locally.\n\nTo resolve provider package issues:\n\n- Clear the provider package cache:\nTerminal windowrm -rf ~/.cache/opencode\nClear the provider package cache:\n\n```\nrm -rf ~/.cache/opencode\n```\n\n- Restart opencode to reinstall the latest provider packages\nRestart opencode to reinstall the latest provider packages\n\nThis will force opencode to download the most recent versions of provider packages, which often resolves compatibility issues with model parameters and API changes.\n\n### Copy/paste not working on Linux\n\nLinux users need to have one of the following clipboard utilities installed for copy/paste functionality to work:\n\nFor X11 systems:\n\n```\napt install -y xclip# orapt install -y xsel\n```\n\nFor Wayland systems:\n\n```\napt install -y wl-clipboard\n```\n\nFor headless environments:\n\n```\napt install -y xvfb# and run:Xvfb :99 -screen 0 1024x768x24 > /dev/null 2>&1 &export DISPLAY=:99.0\n```\n\nopencode will detect if you’re using Wayland and prefer wl-clipboard, otherwise it will try to find clipboard tools in order of: xclip and xsel.\n\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/troubleshooting.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "Troubleshooting",
          "id": "_top"
        },
        {
          "level": 3,
          "text": "Logs",
          "id": "logs"
        },
        {
          "level": 3,
          "text": "Storage",
          "id": "storage"
        },
        {
          "level": 2,
          "text": "Getting help",
          "id": "getting-help"
        },
        {
          "level": 2,
          "text": "Common issues",
          "id": "common-issues"
        },
        {
          "level": 3,
          "text": "OpenCode won’t start",
          "id": "opencode-wont-start"
        },
        {
          "level": 3,
          "text": "Authentication issues",
          "id": "authentication-issues"
        },
        {
          "level": 3,
          "text": "Model not available",
          "id": "model-not-available"
        },
        {
          "level": 3,
          "text": "ProviderInitError",
          "id": "provideriniterror"
        },
        {
          "level": 3,
          "text": "AI_APICallError and provider package issues",
          "id": "ai_apicallerror-and-provider-package-issues"
        },
        {
          "level": 3,
          "text": "Copy/paste not working on Linux",
          "id": "copypaste-not-working-on-linux"
        }
      ],
      "category": "Getting Started",
      "scrapedAt": 1768685268326
    },
    {
      "path": "/docs/1-0/",
      "title": "Migrating to 1.0",
      "url": "https://opencode.ai/docs/1-0/",
      "content": "# Migrating to 1.0\n\nWhat's new in OpenCode 1.0.\n\nOpenCode 1.0 is a complete rewrite of the TUI.\n\nWe moved from the go+bubbletea based TUI which had performance and capability issues to an in-house framework (OpenTUI) written in zig+solidjs.\n\nThe new TUI works like the old one since it connects to the same opencode server.\n\n## Upgrading\n\nYou should not be autoupgraded to 1.0 if you are currently using a previous\nversion. However some older versions of OpenCode always grab latest.\n\nTo upgrade manually, run\n\n```\n$ opencode upgrade 1.0.0\n```\n\nTo downgrade back to 0.x, run\n\n```\n$ opencode upgrade 0.15.31\n```\n\n## UX changes\n\nThe session history is more compressed, only showing full details of the edit and bash tool.\n\nWe added a command bar which almost everything flows through. Press ctrl+p to bring it up in any context and see everything you can do.\n\nAdded a session sidebar (can be toggled) with useful information.\n\nWe removed some functionality that we weren’t sure anyone actually used. If something important is missing please open an issue and we’ll add it back quickly.\n\n## Breaking changes\n\n### Keybinds renamed\n\n- messages_revert -> messages_undo\n- switch_agent -> agent_cycle\n- switch_agent_reverse -> agent_cycle_reverse\n- switch_mode -> agent_cycle\n- switch_mode_reverse -> agent_cycle_reverse\n\n### Keybinds removed\n\n- messages_layout_toggle\n- messages_next\n- messages_previous\n- file_diff_toggle\n- file_search\n- file_close\n- file_list\n- app_help\n- project_init\n- tool_details\n- thinking_blocks\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/1-0.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "Migrating to 1.0",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "Upgrading",
          "id": "upgrading"
        },
        {
          "level": 2,
          "text": "UX changes",
          "id": "ux-changes"
        },
        {
          "level": 2,
          "text": "Breaking changes",
          "id": "breaking-changes"
        },
        {
          "level": 3,
          "text": "Keybinds renamed",
          "id": "keybinds-renamed"
        },
        {
          "level": 3,
          "text": "Keybinds removed",
          "id": "keybinds-removed"
        }
      ],
      "category": "Getting Started",
      "scrapedAt": 1768685268668
    },
    {
      "path": "/docs/tui/",
      "title": "TUI",
      "url": "https://opencode.ai/docs/tui/",
      "content": "# TUI\n\nUsing the OpenCode terminal user interface.\n\nOpenCode provides an interactive terminal interface or TUI for working on your projects with an LLM.\n\nRunning OpenCode starts the TUI for the current directory.\n\n```\nopencode\n```\n\nOr you can start it for a specific working directory.\n\n```\nopencode /path/to/project\n```\n\nOnce you’re in the TUI, you can prompt it with a message.\n\n```\nGive me a quick summary of the codebase.\n```\n\n## File references\n\nYou can reference files in your messages using @. This does a fuzzy file search in the current working directory.\n\nTip\n\nYou can also use @ to reference files in your messages.\n\n```\nHow is auth handled in @packages/functions/src/api/index.ts?\n```\n\nThe content of the file is added to the conversation automatically.\n\n## Bash commands\n\nStart a message with ! to run a shell command.\n\n```\n!ls -la\n```\n\nThe output of the command is added to the conversation as a tool result.\n\n## Commands\n\nWhen using the OpenCode TUI, you can type / followed by a command name to quickly execute actions. For example:\n\n```\n/help\n```\n\nMost commands also have keybind using ctrl+x as the leader key, where ctrl+x is the default leader key. Learn more.\n\nHere are all available slash commands:\n\n### connect\n\nAdd a provider to OpenCode. Allows you to select from available providers and add their API keys.\n\n```\n/connect\n```\n\n### compact\n\nCompact the current session. Alias: /summarize\n\n```\n/compact\n```\n\nKeybind: ctrl+x c\n\n### details\n\nToggle tool execution details.\n\n```\n/details\n```\n\nKeybind: ctrl+x d\n\n### editor\n\nOpen external editor for composing messages. Uses the editor set in your EDITOR environment variable. Learn more.\n\n```\n/editor\n```\n\nKeybind: ctrl+x e\n\n### exit\n\nExit OpenCode. Aliases: /quit, /q\n\n```\n/exit\n```\n\nKeybind: ctrl+x q\n\n### export\n\nExport current conversation to Markdown and open in your default editor. Uses the editor set in your EDITOR environment variable. Learn more.\n\n```\n/export\n```\n\nKeybind: ctrl+x x\n\n### help\n\nShow the help dialog.\n\n```\n/help\n```\n\nKeybind: ctrl+x h\n\n### init\n\nCreate or update AGENTS.md file. Learn more.\n\n```\n/init\n```\n\nKeybind: ctrl+x i\n\n### models\n\nList available models.\n\n```\n/models\n```\n\nKeybind: ctrl+x m\n\n### new\n\nStart a new session. Alias: /clear\n\n```\n/new\n```\n\nKeybind: ctrl+x n\n\n### redo\n\nRedo a previously undone message. Only available after using /undo.\n\nTip\n\nAny file changes will also be restored.\n\nInternally, this uses Git to manage the file changes. So your project needs to\nbe a Git repository.\n\n```\n/redo\n```\n\nKeybind: ctrl+x r\n\n### sessions\n\nList and switch between sessions. Aliases: /resume, /continue\n\n```\n/sessions\n```\n\nKeybind: ctrl+x l\n\n### share\n\nShare current session. Learn more.\n\n```\n/share\n```\n\nKeybind: ctrl+x s\n\n### themes\n\nList available themes.\n\n```\n/theme\n```\n\nKeybind: ctrl+x t\n\n### thinking\n\nToggle the visibility of thinking/reasoning blocks in the conversation. When enabled, you can see the model’s reasoning process for models that support extended thinking.\n\nNote\n\nThis command only controls whether thinking blocks are displayed - it does not enable or disable the model’s reasoning capabilities. To toggle actual reasoning capabilities, use ctrl+t to cycle through model variants.\n\n```\n/thinking\n```\n\n### undo\n\nUndo last message in the conversation. Removes the most recent user message, all subsequent responses, and any file changes.\n\nTip\n\nAny file changes made will also be reverted.\n\nInternally, this uses Git to manage the file changes. So your project needs to\nbe a Git repository.\n\n```\n/undo\n```\n\nKeybind: ctrl+x u\n\n### unshare\n\nUnshare current session. Learn more.\n\n```\n/unshare\n```\n\n## Editor setup\n\nBoth the /editor and /export commands use the editor specified in your EDITOR environment variable.\n\n- Linux/macOS\n- Windows (CMD)\n- Windows (PowerShell)\n\n```\n# Example for nano or vimexport EDITOR=nanoexport EDITOR=vim\n# For GUI editors, VS Code, Cursor, VSCodium, Windsurf, Zed, etc.# include --waitexport EDITOR=\"code --wait\"\n```\n\nTo make it permanent, add this to your shell profile;\n~/.bashrc, ~/.zshrc, etc.\n\n```\nset EDITOR=notepad\n# For GUI editors, VS Code, Cursor, VSCodium, Windsurf, Zed, etc.# include --waitset EDITOR=code --wait\n```\n\nTo make it permanent, use System Properties > Environment\nVariables.\n\n```\n$env:EDITOR = \"notepad\"\n# For GUI editors, VS Code, Cursor, VSCodium, Windsurf, Zed, etc.# include --wait$env:EDITOR = \"code --wait\"\n```\n\nTo make it permanent, add this to your PowerShell profile.\n\nPopular editor options include:\n\n- code - Visual Studio Code\n- cursor - Cursor\n- windsurf - Windsurf\n- nvim - Neovim editor\n- vim - Vim editor\n- nano - Nano editor\n- notepad - Windows Notepad\n- subl - Sublime Text\nNote\n\nSome editors like VS Code need to be started with the --wait flag.\n\nSome editors need command-line arguments to run in blocking mode. The --wait flag makes the editor process block until closed.\n\n## Configure\n\nYou can customize TUI behavior through your OpenCode config file.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"tui\": {    \"scroll_speed\": 3,    \"scroll_acceleration\": {      \"enabled\": true    }  }}\n```\n\n### Options\n\n- scroll_acceleration - Enable macOS-style scroll acceleration for smooth, natural scrolling. When enabled, scroll speed increases with rapid scrolling gestures and stays precise for slower movements. This setting takes precedence over scroll_speed and overrides it when enabled.\n- scroll_speed - Controls how fast the TUI scrolls when using scroll commands (minimum: 1). Defaults to 3. Note: This is ignored if scroll_acceleration.enabled is set to true.\n\n## Customization\n\nYou can customize various aspects of the TUI view using the command palette (ctrl+x h or /help). These settings persist across restarts.\n\n#### Username display\n\nToggle whether your username appears in chat messages. Access this through:\n\n- Command palette: Search for “username” or “hide username”\n- The setting persists automatically and will be remembered across TUI sessions\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/tui.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "TUI",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "File references",
          "id": "file-references"
        },
        {
          "level": 2,
          "text": "Bash commands",
          "id": "bash-commands"
        },
        {
          "level": 2,
          "text": "Commands",
          "id": "commands"
        },
        {
          "level": 3,
          "text": "connect",
          "id": "connect"
        },
        {
          "level": 3,
          "text": "compact",
          "id": "compact"
        },
        {
          "level": 3,
          "text": "details",
          "id": "details"
        },
        {
          "level": 3,
          "text": "editor",
          "id": "editor"
        },
        {
          "level": 3,
          "text": "exit",
          "id": "exit"
        },
        {
          "level": 3,
          "text": "export",
          "id": "export"
        },
        {
          "level": 3,
          "text": "help",
          "id": "help"
        },
        {
          "level": 3,
          "text": "init",
          "id": "init"
        },
        {
          "level": 3,
          "text": "models",
          "id": "models"
        },
        {
          "level": 3,
          "text": "new",
          "id": "new"
        },
        {
          "level": 3,
          "text": "redo",
          "id": "redo"
        },
        {
          "level": 3,
          "text": "sessions",
          "id": "sessions"
        },
        {
          "level": 3,
          "text": "share",
          "id": "share"
        },
        {
          "level": 3,
          "text": "themes",
          "id": "themes"
        },
        {
          "level": 3,
          "text": "thinking",
          "id": "thinking"
        },
        {
          "level": 3,
          "text": "undo",
          "id": "undo"
        },
        {
          "level": 3,
          "text": "unshare",
          "id": "unshare"
        },
        {
          "level": 2,
          "text": "Editor setup",
          "id": "editor-setup"
        },
        {
          "level": 2,
          "text": "Configure",
          "id": "configure"
        },
        {
          "level": 3,
          "text": "Options",
          "id": "options"
        },
        {
          "level": 2,
          "text": "Customization",
          "id": "customization"
        },
        {
          "level": 4,
          "text": "Username display",
          "id": "username-display"
        }
      ],
      "category": "Usage",
      "scrapedAt": 1768685269024
    },
    {
      "path": "/docs/cli/",
      "title": "CLI",
      "url": "https://opencode.ai/docs/cli/",
      "content": "# CLI\n\nOpenCode CLI options and commands.\n\nThe OpenCode CLI by default starts the TUI when run without any arguments.\n\n```\nopencode\n```\n\nBut it also accepts commands as documented on this page. This allows you to interact with OpenCode programmatically.\n\n```\nopencode run \"Explain how closures work in JavaScript\"\n```\n\n### tui\n\nStart the OpenCode terminal user interface.\n\n```\nopencode [project]\n```\n\n#### Flags\n\n## Commands\n\nThe OpenCode CLI also has the following commands.\n\n### agent\n\nManage agents for OpenCode.\n\n```\nopencode agent [command]\n```\n\n### attach\n\nAttach a terminal to an already running OpenCode backend server started via serve or web commands.\n\n```\nopencode attach [url]\n```\n\nThis allows using the TUI with a remote OpenCode backend. For example:\n\n```\n# Start the backend server for web/mobile accessopencode web --port 4096 --hostname 0.0.0.0\n# In another terminal, attach the TUI to the running backendopencode attach http://10.20.30.40:4096\n```\n\n#### Flags\n\n#### create\n\nCreate a new agent with custom configuration.\n\n```\nopencode agent create\n```\n\nThis command will guide you through creating a new agent with a custom system prompt and tool configuration.\n\n#### list\n\nList all available agents.\n\n```\nopencode agent list\n```\n\n### auth\n\nCommand to manage credentials and login for providers.\n\n```\nopencode auth [command]\n```\n\n#### login\n\nOpenCode is powered by the provider list at Models.dev, so you can use opencode auth login to configure API keys for any provider you’d like to use. This is stored in ~/.local/share/opencode/auth.json.\n\n```\nopencode auth login\n```\n\nWhen OpenCode starts up it loads the providers from the credentials file. And if there are any keys defined in your environments or a .env file in your project.\n\n#### list\n\nLists all the authenticated providers as stored in the credentials file.\n\n```\nopencode auth list\n```\n\nOr the short version.\n\n```\nopencode auth ls\n```\n\n#### logout\n\nLogs you out of a provider by clearing it from the credentials file.\n\n```\nopencode auth logout\n```\n\n### github\n\nManage the GitHub agent for repository automation.\n\n```\nopencode github [command]\n```\n\n#### install\n\nInstall the GitHub agent in your repository.\n\n```\nopencode github install\n```\n\nThis sets up the necessary GitHub Actions workflow and guides you through the configuration process. Learn more.\n\n#### run\n\nRun the GitHub agent. This is typically used in GitHub Actions.\n\n```\nopencode github run\n```\n\n### mcp\n\nManage Model Context Protocol servers.\n\n```\nopencode mcp [command]\n```\n\n#### add\n\nAdd an MCP server to your configuration.\n\n```\nopencode mcp add\n```\n\nThis command will guide you through adding either a local or remote MCP server.\n\n#### list\n\nList all configured MCP servers and their connection status.\n\n```\nopencode mcp list\n```\n\nOr use the short version.\n\n```\nopencode mcp ls\n```\n\n#### auth\n\nAuthenticate with an OAuth-enabled MCP server.\n\n```\nopencode mcp auth [name]\n```\n\nIf you don’t provide a server name, you’ll be prompted to select from available OAuth-capable servers.\n\nYou can also list OAuth-capable servers and their authentication status.\n\n```\nopencode mcp auth list\n```\n\nOr use the short version.\n\n```\nopencode mcp auth ls\n```\n\n#### logout\n\nRemove OAuth credentials for an MCP server.\n\n```\nopencode mcp logout [name]\n```\n\n#### debug\n\nDebug OAuth connection issues for an MCP server.\n\n```\nopencode mcp debug <name>\n```\n\n### models\n\nList all available models from configured providers.\n\n```\nopencode models [provider]\n```\n\nThis command displays all models available across your configured providers in the format provider/model.\n\nThis is useful for figuring out the exact model name to use in your config.\n\nYou can optionally pass a provider ID to filter models by that provider.\n\n```\nopencode models anthropic\n```\n\n#### Flags\n\nUse the --refresh flag to update the cached model list. This is useful when new models have been added to a provider and you want to see them in OpenCode.\n\n```\nopencode models --refresh\n```\n\n### run\n\nRun opencode in non-interactive mode by passing a prompt directly.\n\n```\nopencode run [message..]\n```\n\nThis is useful for scripting, automation, or when you want a quick answer without launching the full TUI. For example.\n\n```\nopencode run Explain the use of context in Go\n```\n\nYou can also attach to a running opencode serve instance to avoid MCP server cold boot times on every run:\n\n```\n# Start a headless server in one terminalopencode serve\n# In another terminal, run commands that attach to itopencode run --attach http://localhost:4096 \"Explain async/await in JavaScript\"\n```\n\n#### Flags\n\n### serve\n\nStart a headless OpenCode server for API access. Check out the server docs for the full HTTP interface.\n\n```\nopencode serve\n```\n\nThis starts an HTTP server that provides API access to opencode functionality without the TUI interface. Set OPENCODE_SERVER_PASSWORD to enable HTTP basic auth (username defaults to opencode).\n\n#### Flags\n\n### session\n\nManage OpenCode sessions.\n\n```\nopencode session [command]\n```\n\n#### list\n\nList all OpenCode sessions.\n\n```\nopencode session list\n```\n\n### stats\n\nShow token usage and cost statistics for your OpenCode sessions.\n\n```\nopencode stats\n```\n\n#### Flags\n\n### export\n\nExport session data as JSON.\n\n```\nopencode export [sessionID]\n```\n\nIf you don’t provide a session ID, you’ll be prompted to select from available sessions.\n\n### import\n\nImport session data from a JSON file or OpenCode share URL.\n\n```\nopencode import <file>\n```\n\nYou can import from a local file or an OpenCode share URL.\n\n```\nopencode import session.jsonopencode import https://opncd.ai/s/abc123\n```\n\n### web\n\nStart a headless OpenCode server with a web interface.\n\n```\nopencode web\n```\n\nThis starts an HTTP server and opens a web browser to access OpenCode through a web interface. Set OPENCODE_SERVER_PASSWORD to enable HTTP basic auth (username defaults to opencode).\n\n#### Flags\n\n### acp\n\nStart an ACP (Agent Client Protocol) server.\n\n```\nopencode acp\n```\n\nThis command starts an ACP server that communicates via stdin/stdout using nd-JSON.\n\n#### Flags\n\n### uninstall\n\nUninstall OpenCode and remove all related files.\n\n```\nopencode uninstall\n```\n\n#### Flags\n\n### upgrade\n\nUpdates opencode to the latest version or a specific version.\n\n```\nopencode upgrade [target]\n```\n\nTo upgrade to the latest version.\n\n```\nopencode upgrade\n```\n\nTo upgrade to a specific version.\n\n```\nopencode upgrade v0.1.48\n```\n\n#### Flags\n\n## Global Flags\n\nThe opencode CLI takes the following global flags.\n\n## Environment variables\n\nOpenCode can be configured using environment variables.\n\n### Experimental\n\nThese environment variables enable experimental features that may change or be removed.\n\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/cli.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "CLI",
          "id": "_top"
        },
        {
          "level": 3,
          "text": "tui",
          "id": "tui"
        },
        {
          "level": 4,
          "text": "Flags",
          "id": "flags"
        },
        {
          "level": 2,
          "text": "Commands",
          "id": "commands"
        },
        {
          "level": 3,
          "text": "agent",
          "id": "agent"
        },
        {
          "level": 3,
          "text": "attach",
          "id": "attach"
        },
        {
          "level": 4,
          "text": "Flags",
          "id": "flags-1"
        },
        {
          "level": 4,
          "text": "create",
          "id": "create"
        },
        {
          "level": 4,
          "text": "list",
          "id": "list"
        },
        {
          "level": 3,
          "text": "auth",
          "id": "auth"
        },
        {
          "level": 4,
          "text": "login",
          "id": "login"
        },
        {
          "level": 4,
          "text": "list",
          "id": "list-1"
        },
        {
          "level": 4,
          "text": "logout",
          "id": "logout"
        },
        {
          "level": 3,
          "text": "github",
          "id": "github"
        },
        {
          "level": 4,
          "text": "install",
          "id": "install"
        },
        {
          "level": 4,
          "text": "run",
          "id": "run"
        },
        {
          "level": 5,
          "text": "Flags",
          "id": "flags-2"
        },
        {
          "level": 3,
          "text": "mcp",
          "id": "mcp"
        },
        {
          "level": 4,
          "text": "add",
          "id": "add"
        },
        {
          "level": 4,
          "text": "list",
          "id": "list-2"
        },
        {
          "level": 4,
          "text": "auth",
          "id": "auth-1"
        },
        {
          "level": 4,
          "text": "logout",
          "id": "logout-1"
        },
        {
          "level": 4,
          "text": "debug",
          "id": "debug"
        },
        {
          "level": 3,
          "text": "models",
          "id": "models"
        },
        {
          "level": 4,
          "text": "Flags",
          "id": "flags-3"
        },
        {
          "level": 3,
          "text": "run",
          "id": "run-1"
        },
        {
          "level": 4,
          "text": "Flags",
          "id": "flags-4"
        },
        {
          "level": 3,
          "text": "serve",
          "id": "serve"
        },
        {
          "level": 4,
          "text": "Flags",
          "id": "flags-5"
        },
        {
          "level": 3,
          "text": "session",
          "id": "session"
        },
        {
          "level": 4,
          "text": "list",
          "id": "list-3"
        },
        {
          "level": 5,
          "text": "Flags",
          "id": "flags-6"
        },
        {
          "level": 3,
          "text": "stats",
          "id": "stats"
        },
        {
          "level": 4,
          "text": "Flags",
          "id": "flags-7"
        },
        {
          "level": 3,
          "text": "export",
          "id": "export"
        },
        {
          "level": 3,
          "text": "import",
          "id": "import"
        },
        {
          "level": 3,
          "text": "web",
          "id": "web"
        },
        {
          "level": 4,
          "text": "Flags",
          "id": "flags-8"
        },
        {
          "level": 3,
          "text": "acp",
          "id": "acp"
        },
        {
          "level": 4,
          "text": "Flags",
          "id": "flags-9"
        },
        {
          "level": 3,
          "text": "uninstall",
          "id": "uninstall"
        },
        {
          "level": 4,
          "text": "Flags",
          "id": "flags-10"
        },
        {
          "level": 3,
          "text": "upgrade",
          "id": "upgrade"
        },
        {
          "level": 4,
          "text": "Flags",
          "id": "flags-11"
        },
        {
          "level": 2,
          "text": "Global Flags",
          "id": "global-flags"
        },
        {
          "level": 2,
          "text": "Environment variables",
          "id": "environment-variables"
        },
        {
          "level": 3,
          "text": "Experimental",
          "id": "experimental"
        }
      ],
      "category": "Usage",
      "scrapedAt": 1768685269381
    },
    {
      "path": "/docs/web/",
      "title": "Web",
      "url": "https://opencode.ai/docs/web/",
      "content": "# Web\n\nUsing OpenCode in your browser.\n\nOpenCode can run as a web application in your browser, providing the same powerful AI coding experience without needing a terminal.\n\n## Getting Started\n\nStart the web interface by running:\n\n```\nopencode web\n```\n\nThis starts a local server on 127.0.0.1 with a random available port and automatically opens OpenCode in your default browser.\n\nCaution\n\nIf OPENCODE_SERVER_PASSWORD is not set, the server will be unsecured. This is fine for local use but should be set for network access.\n\n## Configuration\n\nYou can configure the web server using command line flags or in your config file.\n\n### Port\n\nBy default, OpenCode picks an available port. You can specify a port:\n\n```\nopencode web --port 4096\n```\n\n### Hostname\n\nBy default, the server binds to 127.0.0.1 (localhost only). To make OpenCode accessible on your network:\n\n```\nopencode web --hostname 0.0.0.0\n```\n\nWhen using 0.0.0.0, OpenCode will display both local and network addresses:\n\n```\nLocal access:       http://localhost:4096  Network access:     http://192.168.1.100:4096\n```\n\n### mDNS Discovery\n\nEnable mDNS to make your server discoverable on the local network:\n\n```\nopencode web --mdns\n```\n\nThis automatically sets the hostname to 0.0.0.0 and advertises the server as opencode.local.\n\n### CORS\n\nTo allow additional domains for CORS (useful for custom frontends):\n\n```\nopencode web --cors https://example.com\n```\n\n### Authentication\n\nTo protect access, set a password using the OPENCODE_SERVER_PASSWORD environment variable:\n\n```\nOPENCODE_SERVER_PASSWORD=secret opencode web\n```\n\nThe username defaults to opencode but can be changed with OPENCODE_SERVER_USERNAME.\n\n## Using the Web Interface\n\nOnce started, the web interface provides access to your OpenCode sessions.\n\n### Sessions\n\nView and manage your sessions from the homepage. You can see active sessions and start new ones.\n\n### Server Status\n\nClick “See Servers” to view connected servers and their status.\n\n## Attaching a Terminal\n\nYou can attach a terminal TUI to a running web server:\n\n```\n# Start the web serveropencode web --port 4096\n# In another terminal, attach the TUIopencode attach http://localhost:4096\n```\n\nThis allows you to use both the web interface and terminal simultaneously, sharing the same sessions and state.\n\n## Config File\n\nYou can also configure server settings in your opencode.json config file:\n\n```\n{  \"server\": {    \"port\": 4096,    \"hostname\": \"0.0.0.0\",    \"mdns\": true,    \"cors\": [\"https://example.com\"]  }}\n```\n\nCommand line flags take precedence over config file settings.\n\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/web.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "Web",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "Getting Started",
          "id": "getting-started"
        },
        {
          "level": 2,
          "text": "Configuration",
          "id": "configuration"
        },
        {
          "level": 3,
          "text": "Port",
          "id": "port"
        },
        {
          "level": 3,
          "text": "Hostname",
          "id": "hostname"
        },
        {
          "level": 3,
          "text": "mDNS Discovery",
          "id": "mdns-discovery"
        },
        {
          "level": 3,
          "text": "CORS",
          "id": "cors"
        },
        {
          "level": 3,
          "text": "Authentication",
          "id": "authentication"
        },
        {
          "level": 2,
          "text": "Using the Web Interface",
          "id": "using-the-web-interface"
        },
        {
          "level": 3,
          "text": "Sessions",
          "id": "sessions"
        },
        {
          "level": 3,
          "text": "Server Status",
          "id": "server-status"
        },
        {
          "level": 2,
          "text": "Attaching a Terminal",
          "id": "attaching-a-terminal"
        },
        {
          "level": 2,
          "text": "Config File",
          "id": "config-file"
        }
      ],
      "category": "Usage",
      "scrapedAt": 1768685269745
    },
    {
      "path": "/docs/ide/",
      "title": "IDE",
      "url": "https://opencode.ai/docs/ide/",
      "content": "# IDE\n\nThe OpenCode extension for VS Code, Cursor, and other IDEs\n\nOpenCode integrates with VS Code, Cursor, or any IDE that supports a terminal. Just run opencode in the terminal to get started.\n\n## Usage\n\n- Quick Launch: Use Cmd+Esc (Mac) or Ctrl+Esc (Windows/Linux) to open OpenCode in a split terminal view, or focus an existing terminal session if one is already running.\n- New Session: Use Cmd+Shift+Esc (Mac) or Ctrl+Shift+Esc (Windows/Linux) to start a new OpenCode terminal session, even if one is already open. You can also click the OpenCode button in the UI.\n- Context Awareness: Automatically share your current selection or tab with OpenCode.\n- File Reference Shortcuts: Use Cmd+Option+K (Mac) or Alt+Ctrl+K (Linux/Windows) to insert file references. For example, @File#L37-42.\n\n## Installation\n\nTo install OpenCode on VS Code and popular forks like Cursor, Windsurf, VSCodium:\n\n- Open VS Code\n- Open the integrated terminal\n- Run opencode - the extension installs automatically\nIf on the other hand you want to use your own IDE when you run /editor or /export from the TUI, you’ll need to set export EDITOR=\"code --wait\". Learn more.\n\n### Manual Install\n\nSearch for OpenCode in the Extension Marketplace and click Install.\n\n### Troubleshooting\n\nIf the extension fails to install automatically:\n\n- Ensure you’re running opencode in the integrated terminal.\n- Confirm the CLI for your IDE is installed:\n\nFor VS Code: code command\nFor Cursor: cursor command\nFor Windsurf: windsurf command\nFor VSCodium: codium command\nIf not, run Cmd+Shift+P (Mac) or Ctrl+Shift+P (Windows/Linux) and search for “Shell Command: Install ‘code’ command in PATH” (or the equivalent for your IDE)\n- For VS Code: code command\n- For Cursor: cursor command\n- For Windsurf: windsurf command\n- For VSCodium: codium command\n- If not, run Cmd+Shift+P (Mac) or Ctrl+Shift+P (Windows/Linux) and search for “Shell Command: Install ‘code’ command in PATH” (or the equivalent for your IDE)\n- Ensure VS Code has permission to install extensions\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/ide.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "IDE",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "Usage",
          "id": "usage"
        },
        {
          "level": 2,
          "text": "Installation",
          "id": "installation"
        },
        {
          "level": 3,
          "text": "Manual Install",
          "id": "manual-install"
        },
        {
          "level": 3,
          "text": "Troubleshooting",
          "id": "troubleshooting"
        }
      ],
      "category": "Usage",
      "scrapedAt": 1768685270098
    },
    {
      "path": "/docs/zen/",
      "title": "Zen",
      "url": "https://opencode.ai/docs/zen/",
      "content": "# Zen\n\nCurated list of models provided by OpenCode.\n\nOpenCode Zen is a list of tested and verified models provided by the OpenCode team.\n\nNote\n\nOpenCode Zen is currently in beta.\n\nZen works like any other provider in OpenCode. You login to OpenCode Zen and get\nyour API key. It’s completely optional and you don’t need to use it to use\nOpenCode.\n\n## Background\n\nThere are a large number of models out there but only a few of\nthese models work well as coding agents. Additionally, most providers are\nconfigured very differently; so you get very different performance and quality.\n\nTip\n\nWe tested a select group of models and providers that work well with OpenCode.\n\nSo if you are using a model through something like OpenRouter, you can never be\nsure if you are getting the best version of the model you want.\n\nTo fix this, we did a couple of things:\n\n- We tested a select group of models and talked to their teams about how to\nbest run them.\n- We then worked with a few providers to make sure these were being served\ncorrectly.\n- Finally, we benchmarked the combination of the model/provider and came up\nwith a list that we feel good recommending.\nOpenCode Zen is an AI gateway that gives you access to these models.\n\n## How it works\n\nOpenCode Zen works like any other provider in OpenCode.\n\n- You sign in to OpenCode Zen, add your billing\ndetails, and copy your API key.\n- You run the /connect command in the TUI, select OpenCode Zen, and paste your API key.\n- Run /models in the TUI to see the list of models we recommend.\nYou are charged per request and you can add credits to your account.\n\n## Endpoints\n\nYou can also access our models through the following API endpoints.\n\nThe model id in your OpenCode config\nuses the format opencode/<model-id>. For example, for GPT 5.2 Codex, you would\nuse opencode/gpt-5.2-codex in your config.\n\n### Models\n\nYou can fetch the full list of available models and their metadata from:\n\n```\nhttps://opencode.ai/zen/v1/models\n```\n\n## Pricing\n\nWe support a pay-as-you-go model. Below are the prices per 1M tokens.\n\nYou might notice Claude Haiku 3.5 in your usage history. This is a low cost model that’s used to generate the titles of your sessions.\n\nNote\n\nCredit card fees are passed along at cost (4.4% + $0.30 per transaction); we don’t charge anything beyond that.\n\nThe free models:\n\n- Grok Code Fast 1 is currently free on OpenCode for a limited time. The xAI team is using this time to collect feedback and improve Grok Code.\n- GLM 4.7 is currently free on OpenCode for a limited time. The team is using this time to collect feedback and improve the model.\n- MiniMax M2.1 is currently free on OpenCode for a limited time. The team is using this time to collect feedback and improve the model.\n- Big Pickle is a stealth model that’s free on OpenCode for a limited time. The team is using this time to collect feedback and improve the model.\nContact us if you have any questions.\n\n### Auto-reload\n\nIf your balance goes below $5, Zen will automatically reload $20.\n\nYou can change the auto-reload amount. You can also disable auto-reload entirely.\n\n### Monthly limits\n\nYou can also set a monthly usage limit for the entire workspace and for each\nmember of your team.\n\nFor example, let’s say you set a monthly usage limit to $20, Zen will not use\nmore than $20 in a month. But if you have auto-reload enabled, Zen might end up\ncharging you more than $20 if your balance goes below $5.\n\n## Privacy\n\nAll our models are hosted in the US. Our providers follow a zero-retention policy and do not use your data for model training, with the following exceptions:\n\n- Grok Code Fast 1: During its free period, collected data may be used to improve Grok Code.\n- GLM 4.7: During its free period, collected data may be used to improve the model.\n- MiniMax M2.1: During its free period, collected data may be used to improve the model.\n- Big Pickle: During its free period, collected data may be used to improve the model.\n- OpenAI APIs: Requests are retained for 30 days in accordance with OpenAI’s Data Policies.\n- Anthropic APIs: Requests are retained for 30 days in accordance with Anthropic’s Data Policies.\n\n## For Teams\n\nZen also works great for teams. You can invite teammates, assign roles, curate\nthe models your team uses, and more.\n\nNote\n\nWorkspaces are currently free for teams as a part of the beta.\n\nManaging your workspace is currently free for teams as a part of the beta. We’ll be\nsharing more details on the pricing soon.\n\n### Roles\n\nYou can invite teammates to your workspace and assign roles:\n\n- Admin: Manage models, members, API keys, and billing\n- Member: Manage only their own API keys\nAdmins can also set monthly spending limits for each member to keep costs under control.\n\n### Model access\n\nAdmins can enable or disable specific models for the workspace. Requests made to a disabled model will return an error.\n\nThis is useful for cases where you want to disable the use of a model that\ncollects data.\n\n### Bring your own key\n\nYou can use your own OpenAI or Anthropic API keys while still accessing other models in Zen.\n\nWhen you use your own keys, tokens are billed directly by the provider, not by Zen.\n\nFor example, your organization might already have a key for OpenAI or Anthropic\nand you want to use that instead of the one that Zen provides.\n\n## Goals\n\nWe created OpenCode Zen to:\n\n- Benchmark the best models/providers for coding agents.\n- Have access to the highest quality options and not downgrade performance or route to cheaper providers.\n- Pass along any price drops by selling at cost; so the only markup is to cover our processing fees.\n- Have no lock-in by allowing you to use it with any other coding agent. And always let you use any other provider with OpenCode as well.\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/zen.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "Zen",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "Background",
          "id": "background"
        },
        {
          "level": 2,
          "text": "How it works",
          "id": "how-it-works"
        },
        {
          "level": 2,
          "text": "Endpoints",
          "id": "endpoints"
        },
        {
          "level": 3,
          "text": "Models",
          "id": "models"
        },
        {
          "level": 2,
          "text": "Pricing",
          "id": "pricing"
        },
        {
          "level": 3,
          "text": "Auto-reload",
          "id": "auto-reload"
        },
        {
          "level": 3,
          "text": "Monthly limits",
          "id": "monthly-limits"
        },
        {
          "level": 2,
          "text": "Privacy",
          "id": "privacy"
        },
        {
          "level": 2,
          "text": "For Teams",
          "id": "for-teams"
        },
        {
          "level": 3,
          "text": "Roles",
          "id": "roles"
        },
        {
          "level": 3,
          "text": "Model access",
          "id": "model-access"
        },
        {
          "level": 3,
          "text": "Bring your own key",
          "id": "bring-your-own-key"
        },
        {
          "level": 2,
          "text": "Goals",
          "id": "goals"
        }
      ],
      "category": "Usage",
      "scrapedAt": 1768685270452
    },
    {
      "path": "/docs/share/",
      "title": "Share",
      "url": "https://opencode.ai/docs/share/",
      "content": "# Share\n\nShare your OpenCode conversations.\n\nOpenCode’s share feature allows you to create public links to your OpenCode conversations, so you can collaborate with teammates or get help from others.\n\nNote\n\nShared conversations are publicly accessible to anyone with the link.\n\n## How it works\n\nWhen you share a conversation, OpenCode:\n\n- Creates a unique public URL for your session\n- Syncs your conversation history to our servers\n- Makes the conversation accessible via the shareable link — opncd.ai/s/<share-id>\n\n## Sharing\n\nOpenCode supports three sharing modes that control how conversations are shared:\n\n### Manual (default)\n\nBy default, OpenCode uses manual sharing mode. Sessions are not shared automatically, but you can manually share them using the /share command:\n\n```\n/share\n```\n\nThis will generate a unique URL that’ll be copied to your clipboard.\n\nTo explicitly set manual mode in your config file:\n\n```\n{  \"$schema\": \"https://opncd.ai/config.json\",  \"share\": \"manual\"}\n```\n\n### Auto-share\n\nYou can enable automatic sharing for all new conversations by setting the share option to \"auto\" in your config file:\n\n```\n{  \"$schema\": \"https://opncd.ai/config.json\",  \"share\": \"auto\"}\n```\n\nWith auto-share enabled, every new conversation will automatically be shared and a link will be generated.\n\n### Disabled\n\nYou can disable sharing entirely by setting the share option to \"disabled\" in your config file:\n\n```\n{  \"$schema\": \"https://opncd.ai/config.json\",  \"share\": \"disabled\"}\n```\n\nTo enforce this across your team for a given project, add it to the opencode.json in your project and check into Git.\n\n## Un-sharing\n\nTo stop sharing a conversation and remove it from public access:\n\n```\n/unshare\n```\n\nThis will remove the share link and delete the data related to the conversation.\n\n## Privacy\n\nThere are a few things to keep in mind when sharing a conversation.\n\n### Data retention\n\nShared conversations remain accessible until you explicitly unshare them. This\nincludes:\n\n- Full conversation history\n- All messages and responses\n- Session metadata\n\n### Recommendations\n\n- Only share conversations that don’t contain sensitive information.\n- Review conversation content before sharing.\n- Unshare conversations when collaboration is complete.\n- Avoid sharing conversations with proprietary code or confidential data.\n- For sensitive projects, disable sharing entirely.\n\n## For enterprises\n\nFor enterprise deployments, the share feature can be:\n\n- Disabled entirely for security compliance\n- Restricted to users authenticated through SSO only\n- Self-hosted on your own infrastructure\nLearn more about using opencode in your organization.\n\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/share.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "Share",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "How it works",
          "id": "how-it-works"
        },
        {
          "level": 2,
          "text": "Sharing",
          "id": "sharing"
        },
        {
          "level": 3,
          "text": "Manual (default)",
          "id": "manual-default"
        },
        {
          "level": 3,
          "text": "Auto-share",
          "id": "auto-share"
        },
        {
          "level": 3,
          "text": "Disabled",
          "id": "disabled"
        },
        {
          "level": 2,
          "text": "Un-sharing",
          "id": "un-sharing"
        },
        {
          "level": 2,
          "text": "Privacy",
          "id": "privacy"
        },
        {
          "level": 3,
          "text": "Data retention",
          "id": "data-retention"
        },
        {
          "level": 3,
          "text": "Recommendations",
          "id": "recommendations"
        },
        {
          "level": 2,
          "text": "For enterprises",
          "id": "for-enterprises"
        }
      ],
      "category": "Usage",
      "scrapedAt": 1768685270829
    },
    {
      "path": "/docs/github/",
      "title": "GitHub",
      "url": "https://opencode.ai/docs/github/",
      "content": "# GitHub\n\nUse OpenCode in GitHub issues and pull-requests.\n\nOpenCode integrates with your GitHub workflow. Mention /opencode or /oc in your comment, and OpenCode will execute tasks within your GitHub Actions runner.\n\n## Features\n\n- Triage issues: Ask OpenCode to look into an issue and explain it to you.\n- Fix and implement: Ask OpenCode to fix an issue or implement a feature. And it will work in a new branch and submits a PR with all the changes.\n- Secure: OpenCode runs inside your GitHub’s runners.\n\n## Installation\n\nRun the following command in a project that is in a GitHub repo:\n\n```\nopencode github install\n```\n\nThis will walk you through installing the GitHub app, creating the workflow, and setting up secrets.\n\n### Manual Setup\n\nOr you can set it up manually.\n\n- Install the GitHub app\nHead over to github.com/apps/opencode-agent. Make sure it’s installed on the target repository.\nInstall the GitHub app\n\nHead over to github.com/apps/opencode-agent. Make sure it’s installed on the target repository.\n\n- Add the workflow\nAdd the following workflow file to .github/workflows/opencode.yml in your repo. Make sure to set the appropriate model and required API keys in env.\n.github/workflows/opencode.ymlname: opencode\non:  issue_comment:    types: [created]  pull_request_review_comment:    types: [created]\njobs:  opencode:    if: |      contains(github.event.comment.body, '/oc') ||      contains(github.event.comment.body, '/opencode')    runs-on: ubuntu-latest    permissions:      id-token: write    steps:       - name: Checkout repository         uses: actions/checkout@v6         with:           fetch-depth: 1           persist-credentials: false\n       - name: Run OpenCode        uses: anomalyco/opencode/github@latest        env:          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}        with:          model: anthropic/claude-sonnet-4-20250514          # share: true          # github_token: xxxx\nAdd the workflow\n\nAdd the following workflow file to .github/workflows/opencode.yml in your repo. Make sure to set the appropriate model and required API keys in env.\n\n```\nname: opencode\non:  issue_comment:    types: [created]  pull_request_review_comment:    types: [created]\njobs:  opencode:    if: |      contains(github.event.comment.body, '/oc') ||      contains(github.event.comment.body, '/opencode')    runs-on: ubuntu-latest    permissions:      id-token: write    steps:       - name: Checkout repository         uses: actions/checkout@v6         with:           fetch-depth: 1           persist-credentials: false\n       - name: Run OpenCode        uses: anomalyco/opencode/github@latest        env:          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}        with:          model: anthropic/claude-sonnet-4-20250514          # share: true          # github_token: xxxx\n```\n\n- Store the API keys in secrets\nIn your organization or project settings, expand Secrets and variables on the left and select Actions. And add the required API keys.\nStore the API keys in secrets\n\nIn your organization or project settings, expand Secrets and variables on the left and select Actions. And add the required API keys.\n\n## Configuration\n\n- model: The model to use with OpenCode. Takes the format of provider/model. This is required.\nmodel: The model to use with OpenCode. Takes the format of provider/model. This is required.\n\n- agent: The agent to use. Must be a primary agent. Falls back to default_agent from config or \"build\" if not found.\nagent: The agent to use. Must be a primary agent. Falls back to default_agent from config or \"build\" if not found.\n\n- share: Whether to share the OpenCode session. Defaults to true for public repositories.\nshare: Whether to share the OpenCode session. Defaults to true for public repositories.\n\n- prompt: Optional custom prompt to override the default behavior. Use this to customize how OpenCode processes requests.\nprompt: Optional custom prompt to override the default behavior. Use this to customize how OpenCode processes requests.\n\n- token: Optional GitHub access token for performing operations such as creating comments, committing changes, and opening pull requests. By default, OpenCode uses the installation access token from the OpenCode GitHub App, so commits, comments, and pull requests appear as coming from the app.\nAlternatively, you can use the GitHub Action runner’s built-in GITHUB_TOKEN without installing the OpenCode GitHub App. Just make sure to grant the required permissions in your workflow:\npermissions:  id-token: write  contents: write  pull-requests: write  issues: write\nYou can also use a personal access tokens(PAT) if preferred.\ntoken: Optional GitHub access token for performing operations such as creating comments, committing changes, and opening pull requests. By default, OpenCode uses the installation access token from the OpenCode GitHub App, so commits, comments, and pull requests appear as coming from the app.\n\nAlternatively, you can use the GitHub Action runner’s built-in GITHUB_TOKEN without installing the OpenCode GitHub App. Just make sure to grant the required permissions in your workflow:\n\n```\npermissions:  id-token: write  contents: write  pull-requests: write  issues: write\n```\n\nYou can also use a personal access tokens(PAT) if preferred.\n\n## Supported Events\n\nOpenCode can be triggered by the following GitHub events:\n\n### Schedule Example\n\nRun OpenCode on a schedule to perform automated tasks:\n\n```\nname: Scheduled OpenCode Task\non:  schedule:    - cron: \"0 9 * * 1\" # Every Monday at 9am UTC\njobs:  opencode:    runs-on: ubuntu-latest    permissions:      id-token: write      contents: write      pull-requests: write      issues: write    steps:      - name: Checkout repository        uses: actions/checkout@v6        with:          persist-credentials: false\n      - name: Run OpenCode        uses: anomalyco/opencode/github@latest        env:          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}        with:          model: anthropic/claude-sonnet-4-20250514          prompt: |            Review the codebase for any TODO comments and create a summary.            If you find issues worth addressing, open an issue to track them.\n```\n\nFor scheduled events, the prompt input is required since there’s no comment to extract instructions from. Scheduled workflows run without a user context to permission-check, so the workflow must grant contents: write and pull-requests: write if you expect OpenCode to create branches or PRs.\n\n### Pull Request Example\n\nAutomatically review PRs when they are opened or updated:\n\n```\nname: opencode-review\non:  pull_request:    types: [opened, synchronize, reopened, ready_for_review]\njobs:  review:    runs-on: ubuntu-latest    permissions:      id-token: write      contents: read      pull-requests: read      issues: read    steps:      - uses: actions/checkout@v6        with:          persist-credentials: false      - uses: anomalyco/opencode/github@latest        env:          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}        with:          model: anthropic/claude-sonnet-4-20250514          prompt: |            Review this pull request:            - Check for code quality issues            - Look for potential bugs            - Suggest improvements\n```\n\nFor pull_request events, if no prompt is provided, OpenCode defaults to reviewing the pull request.\n\n### Issues Triage Example\n\nAutomatically triage new issues. This example filters to accounts older than 30 days to reduce spam:\n\n```\nname: Issue Triage\non:  issues:    types: [opened]\njobs:  triage:    runs-on: ubuntu-latest    permissions:      id-token: write      contents: write      pull-requests: write      issues: write    steps:      - name: Check account age        id: check        uses: actions/github-script@v7        with:          script: |            const user = await github.rest.users.getByUsername({              username: context.payload.issue.user.login            });            const created = new Date(user.data.created_at);            const days = (Date.now() - created) / (1000 * 60 * 60 * 24);            return days >= 30;          result-encoding: string\n      - uses: actions/checkout@v6        if: steps.check.outputs.result == 'true'        with:          persist-credentials: false\n      - uses: anomalyco/opencode/github@latest        if: steps.check.outputs.result == 'true'        env:          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}        with:          model: anthropic/claude-sonnet-4-20250514          prompt: |            Review this issue. If there's a clear fix or relevant docs:            - Provide documentation links            - Add error handling guidance for code examples            Otherwise, do not comment.\n```\n\nFor issues events, the prompt input is required since there’s no comment to extract instructions from.\n\n## Custom prompts\n\nOverride the default prompt to customize OpenCode’s behavior for your workflow.\n\n```\n- uses: anomalyco/opencode/github@latest  with:    model: anthropic/claude-sonnet-4-5    prompt: |      Review this pull request:      - Check for code quality issues      - Look for potential bugs      - Suggest improvements\n```\n\nThis is useful for enforcing specific review criteria, coding standards, or focus areas relevant to your project.\n\n## Examples\n\nHere are some examples of how you can use OpenCode in GitHub.\n\n- Explain an issue\nAdd this comment in a GitHub issue.\n/opencode explain this issue\nOpenCode will read the entire thread, including all comments, and reply with a clear explanation.\nExplain an issue\n\nAdd this comment in a GitHub issue.\n\n```\n/opencode explain this issue\n```\n\nOpenCode will read the entire thread, including all comments, and reply with a clear explanation.\n\n- Fix an issue\nIn a GitHub issue, say:\n/opencode fix this\nAnd OpenCode will create a new branch, implement the changes, and open a PR with the changes.\nFix an issue\n\nIn a GitHub issue, say:\n\n```\n/opencode fix this\n```\n\nAnd OpenCode will create a new branch, implement the changes, and open a PR with the changes.\n\n- Review PRs and make changes\nLeave the following comment on a GitHub PR.\nDelete the attachment from S3 when the note is removed /oc\nOpenCode will implement the requested change and commit it to the same PR.\nReview PRs and make changes\n\nLeave the following comment on a GitHub PR.\n\n```\nDelete the attachment from S3 when the note is removed /oc\n```\n\nOpenCode will implement the requested change and commit it to the same PR.\n\n- Review specific code lines\nLeave a comment directly on code lines in the PR’s “Files” tab. OpenCode automatically detects the file, line numbers, and diff context to provide precise responses.\n[Comment on specific lines in Files tab]/oc add error handling here\nWhen commenting on specific lines, OpenCode receives:\n\nThe exact file being reviewed\nThe specific lines of code\nThe surrounding diff context\nLine number information\n\nThis allows for more targeted requests without needing to specify file paths or line numbers manually.\nReview specific code lines\n\nLeave a comment directly on code lines in the PR’s “Files” tab. OpenCode automatically detects the file, line numbers, and diff context to provide precise responses.\n\n```\n[Comment on specific lines in Files tab]/oc add error handling here\n```\n\nWhen commenting on specific lines, OpenCode receives:\n\n- The exact file being reviewed\n- The specific lines of code\n- The surrounding diff context\n- Line number information\nThis allows for more targeted requests without needing to specify file paths or line numbers manually.\n\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/github.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "GitHub",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "Features",
          "id": "features"
        },
        {
          "level": 2,
          "text": "Installation",
          "id": "installation"
        },
        {
          "level": 3,
          "text": "Manual Setup",
          "id": "manual-setup"
        },
        {
          "level": 2,
          "text": "Configuration",
          "id": "configuration"
        },
        {
          "level": 2,
          "text": "Supported Events",
          "id": "supported-events"
        },
        {
          "level": 3,
          "text": "Schedule Example",
          "id": "schedule-example"
        },
        {
          "level": 3,
          "text": "Pull Request Example",
          "id": "pull-request-example"
        },
        {
          "level": 3,
          "text": "Issues Triage Example",
          "id": "issues-triage-example"
        },
        {
          "level": 2,
          "text": "Custom prompts",
          "id": "custom-prompts"
        },
        {
          "level": 2,
          "text": "Examples",
          "id": "examples"
        }
      ],
      "category": "Usage",
      "scrapedAt": 1768685271199
    },
    {
      "path": "/docs/gitlab/",
      "title": "GitLab",
      "url": "https://opencode.ai/docs/gitlab/",
      "content": "# GitLab\n\nUse OpenCode in GitLab issues and merge requests.\n\nOpenCode integrates with your GitLab workflow through your GitLab CI/CD pipeline or with GitLab Duo.\n\nIn both cases, OpenCode will run on your GitLab runners.\n\n## GitLab CI\n\nOpenCode works in a regular GitLab pipeline. You can build it into a pipeline as a CI component\n\nHere we are using a community-created CI/CD component for OpenCode — nagyv/gitlab-opencode.\n\n### Features\n\n- Use custom configuration per job: Configure OpenCode with a custom configuration directory, for example ./config/#custom-directory to enable or disable functionality per OpenCode invocation.\n- Minimal setup: The CI component sets up OpenCode in the background, you only need to create the OpenCode configuration and the initial prompt.\n- Flexible: The CI component supports several inputs for customizing its behavior\n\n### Setup\n\n- Store your OpenCode authentication JSON as a File type CI environment variables under Settings > CI/CD > Variables. Make sure to mark them as “Masked and hidden”.\nStore your OpenCode authentication JSON as a File type CI environment variables under Settings > CI/CD > Variables. Make sure to mark them as “Masked and hidden”.\n\n- Add the following to your .gitlab-ci.yml file.\n.gitlab-ci.ymlinclude:  - component: $CI_SERVER_FQDN/nagyv/gitlab-opencode/opencode@2    inputs:      config_dir: ${CI_PROJECT_DIR}/opencode-config      auth_json: $OPENCODE_AUTH_JSON # The variable name for your OpenCode authentication JSON      command: optional-custom-command      message: \"Your prompt here\"\nAdd the following to your .gitlab-ci.yml file.\n\n```\ninclude:  - component: $CI_SERVER_FQDN/nagyv/gitlab-opencode/opencode@2    inputs:      config_dir: ${CI_PROJECT_DIR}/opencode-config      auth_json: $OPENCODE_AUTH_JSON # The variable name for your OpenCode authentication JSON      command: optional-custom-command      message: \"Your prompt here\"\n```\n\nFor more inputs and use cases check out the docs for this component.\n\n## GitLab Duo\n\nOpenCode integrates with your GitLab workflow.\nMention @opencode in a comment, and OpenCode will execute tasks within your GitLab CI pipeline.\n\n### Features\n\n- Triage issues: Ask OpenCode to look into an issue and explain it to you.\n- Fix and implement: Ask OpenCode to fix an issue or implement a feature.\nIt will create a new branch and raise a merge request with the changes.\n- Secure: OpenCode runs on your GitLab runners.\n\n### Setup\n\nOpenCode runs in your GitLab CI/CD pipeline, here’s what you’ll need to set it up:\n\nTip\n\nCheck out the GitLab docs for up to date instructions.\n\n- Configure your GitLab environment\nConfigure your GitLab environment\n\n- Set up CI/CD\nSet up CI/CD\n\n- Get an AI model provider API key\nGet an AI model provider API key\n\n- Create a service account\nCreate a service account\n\n- Configure CI/CD variables\nConfigure CI/CD variables\n\n- Create a flow config file, here’s an example:\nFlow configurationimage: node:22-slimcommands:  - echo \"Installing opencode\"  - npm install --global opencode-ai  - echo \"Installing glab\"  - export GITLAB_TOKEN=$GITLAB_TOKEN_OPENCODE  - apt-get update --quiet && apt-get install --yes curl wget gpg git && rm --recursive --force /var/lib/apt/lists/*  - curl --silent --show-error --location \"https://raw.githubusercontent.com/upciti/wakemeops/main/assets/install_repository\" | bash  - apt-get install --yes glab  - echo \"Configuring glab\"  - echo $GITLAB_HOST  - echo \"Creating OpenCode auth configuration\"  - mkdir --parents ~/.local/share/opencode  - |    cat > ~/.local/share/opencode/auth.json << EOF    {      \"anthropic\": {        \"type\": \"api\",        \"key\": \"$ANTHROPIC_API_KEY\"      }    }    EOF  - echo \"Configuring git\"  - git config --global user.email \"opencode@gitlab.com\"  - git config --global user.name \"OpenCode\"  - echo \"Testing glab\"  - glab issue list  - echo \"Running OpenCode\"  - |    opencode run \"    You are an AI assistant helping with GitLab operations.\n    Context: $AI_FLOW_CONTEXT    Task: $AI_FLOW_INPUT    Event: $AI_FLOW_EVENT\n    Please execute the requested task using the available GitLab tools.    Be thorough in your analysis and provide clear explanations.\n    <important>    Please use the glab CLI to access data from GitLab. The glab CLI has already been authenticated. You can run the corresponding commands.\n    If you are asked to summarize an MR or issue or asked to provide more information then please post back a note to the MR/Issue so that the user can see it.    You don't need to commit or push up changes, those will be done automatically based on the file changes you make.    </important>    \"  - git checkout --branch $CI_WORKLOAD_REF origin/$CI_WORKLOAD_REF  - echo \"Checking for git changes and pushing if any exist\"  - |    if ! git diff --quiet || ! git diff --cached --quiet || [ --not --zero \"$(git ls-files --others --exclude-standard)\" ]; then      echo \"Git changes detected, adding and pushing...\"      git add .      if git diff --cached --quiet; then        echo \"No staged changes to commit\"      else        echo \"Committing changes to branch: $CI_WORKLOAD_REF\"        git commit --message \"Codex changes\"        echo \"Pushing changes up to $CI_WORKLOAD_REF\"        git push https://gitlab-ci-token:$GITLAB_TOKEN@$GITLAB_HOST/gl-demo-ultimate-dev-ai-epic-17570/test-java-project.git $CI_WORKLOAD_REF        echo \"Changes successfully pushed\"      fi    else      echo \"No git changes detected, skipping push\"    fivariables:  - ANTHROPIC_API_KEY  - GITLAB_TOKEN_OPENCODE  - GITLAB_HOST\nCreate a flow config file, here’s an example:\n\n```\nimage: node:22-slimcommands:  - echo \"Installing opencode\"  - npm install --global opencode-ai  - echo \"Installing glab\"  - export GITLAB_TOKEN=$GITLAB_TOKEN_OPENCODE  - apt-get update --quiet && apt-get install --yes curl wget gpg git && rm --recursive --force /var/lib/apt/lists/*  - curl --silent --show-error --location \"https://raw.githubusercontent.com/upciti/wakemeops/main/assets/install_repository\" | bash  - apt-get install --yes glab  - echo \"Configuring glab\"  - echo $GITLAB_HOST  - echo \"Creating OpenCode auth configuration\"  - mkdir --parents ~/.local/share/opencode  - |    cat > ~/.local/share/opencode/auth.json << EOF    {      \"anthropic\": {        \"type\": \"api\",        \"key\": \"$ANTHROPIC_API_KEY\"      }    }    EOF  - echo \"Configuring git\"  - git config --global user.email \"opencode@gitlab.com\"  - git config --global user.name \"OpenCode\"  - echo \"Testing glab\"  - glab issue list  - echo \"Running OpenCode\"  - |    opencode run \"    You are an AI assistant helping with GitLab operations.\n    Context: $AI_FLOW_CONTEXT    Task: $AI_FLOW_INPUT    Event: $AI_FLOW_EVENT\n    Please execute the requested task using the available GitLab tools.    Be thorough in your analysis and provide clear explanations.\n    <important>    Please use the glab CLI to access data from GitLab. The glab CLI has already been authenticated. You can run the corresponding commands.\n    If you are asked to summarize an MR or issue or asked to provide more information then please post back a note to the MR/Issue so that the user can see it.    You don't need to commit or push up changes, those will be done automatically based on the file changes you make.    </important>    \"  - git checkout --branch $CI_WORKLOAD_REF origin/$CI_WORKLOAD_REF  - echo \"Checking for git changes and pushing if any exist\"  - |    if ! git diff --quiet || ! git diff --cached --quiet || [ --not --zero \"$(git ls-files --others --exclude-standard)\" ]; then      echo \"Git changes detected, adding and pushing...\"      git add .      if git diff --cached --quiet; then        echo \"No staged changes to commit\"      else        echo \"Committing changes to branch: $CI_WORKLOAD_REF\"        git commit --message \"Codex changes\"        echo \"Pushing changes up to $CI_WORKLOAD_REF\"        git push https://gitlab-ci-token:$GITLAB_TOKEN@$GITLAB_HOST/gl-demo-ultimate-dev-ai-epic-17570/test-java-project.git $CI_WORKLOAD_REF        echo \"Changes successfully pushed\"      fi    else      echo \"No git changes detected, skipping push\"    fivariables:  - ANTHROPIC_API_KEY  - GITLAB_TOKEN_OPENCODE  - GITLAB_HOST\n```\n\nYou can refer to the GitLab CLI agents docs for detailed instructions.\n\n### Examples\n\nHere are some examples of how you can use OpenCode in GitLab.\n\nTip\n\nYou can configure to use a different trigger phrase than @opencode.\n\n- Explain an issue\nAdd this comment in a GitLab issue.\n@opencode explain this issue\nOpenCode will read the issue and reply with a clear explanation.\nExplain an issue\n\nAdd this comment in a GitLab issue.\n\n```\n@opencode explain this issue\n```\n\nOpenCode will read the issue and reply with a clear explanation.\n\n- Fix an issue\nIn a GitLab issue, say:\n@opencode fix this\nOpenCode will create a new branch, implement the changes, and open a merge request with the changes.\nFix an issue\n\nIn a GitLab issue, say:\n\n```\n@opencode fix this\n```\n\nOpenCode will create a new branch, implement the changes, and open a merge request with the changes.\n\n- Review merge requests\nLeave the following comment on a GitLab merge request.\n@opencode review this merge request\nOpenCode will review the merge request and provide feedback.\nReview merge requests\n\nLeave the following comment on a GitLab merge request.\n\n```\n@opencode review this merge request\n```\n\nOpenCode will review the merge request and provide feedback.\n\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/gitlab.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "GitLab",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "GitLab CI",
          "id": "gitlab-ci"
        },
        {
          "level": 3,
          "text": "Features",
          "id": "features"
        },
        {
          "level": 3,
          "text": "Setup",
          "id": "setup"
        },
        {
          "level": 2,
          "text": "GitLab Duo",
          "id": "gitlab-duo"
        },
        {
          "level": 3,
          "text": "Features",
          "id": "features-1"
        },
        {
          "level": 3,
          "text": "Setup",
          "id": "setup-1"
        },
        {
          "level": 3,
          "text": "Examples",
          "id": "examples"
        }
      ],
      "category": "Usage",
      "scrapedAt": 1768685271560
    },
    {
      "path": "/docs/tools/",
      "title": "Tools",
      "url": "https://opencode.ai/docs/tools/",
      "content": "# Tools\n\nManage the tools an LLM can use.\n\nTools allow the LLM to perform actions in your codebase. OpenCode comes with a set of built-in tools, but you can extend it with custom tools or MCP servers.\n\nBy default, all tools are enabled and don’t need permission to run. You can control tool behavior through permissions.\n\n## Configure\n\nUse the permission field to control tool behavior. You can allow, deny, or require approval for each tool.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"permission\": {    \"edit\": \"deny\",    \"bash\": \"ask\",    \"webfetch\": \"allow\"  }}\n```\n\nYou can also use wildcards to control multiple tools at once. For example, to require approval for all tools from an MCP server:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"permission\": {    \"mymcp_*\": \"ask\"  }}\n```\n\nLearn more about configuring permissions.\n\n## Built-in\n\nHere are all the built-in tools available in OpenCode.\n\n### bash\n\nExecute shell commands in your project environment.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"permission\": {    \"bash\": \"allow\"  }}\n```\n\nThis tool allows the LLM to run terminal commands like npm install, git status, or any other shell command.\n\n### edit\n\nModify existing files using exact string replacements.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"permission\": {    \"edit\": \"allow\"  }}\n```\n\nThis tool performs precise edits to files by replacing exact text matches. It’s the primary way the LLM modifies code.\n\n### write\n\nCreate new files or overwrite existing ones.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"permission\": {    \"edit\": \"allow\"  }}\n```\n\nUse this to allow the LLM to create new files. It will overwrite existing files if they already exist.\n\nNote\n\nThe write tool is controlled by the edit permission, which covers all file modifications (edit, write, patch, multiedit).\n\n### read\n\nRead file contents from your codebase.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"permission\": {    \"read\": \"allow\"  }}\n```\n\nThis tool reads files and returns their contents. It supports reading specific line ranges for large files.\n\n### grep\n\nSearch file contents using regular expressions.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"permission\": {    \"grep\": \"allow\"  }}\n```\n\nFast content search across your codebase. Supports full regex syntax and file pattern filtering.\n\n### glob\n\nFind files by pattern matching.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"permission\": {    \"glob\": \"allow\"  }}\n```\n\nSearch for files using glob patterns like **/*.js or src/**/*.ts. Returns matching file paths sorted by modification time.\n\n### list\n\nList files and directories in a given path.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"permission\": {    \"list\": \"allow\"  }}\n```\n\nThis tool lists directory contents. It accepts glob patterns to filter results.\n\n### lsp (experimental)\n\nInteract with your configured LSP servers to get code intelligence features like definitions, references, hover info, and call hierarchy.\n\nNote\n\nThis tool is only available when OPENCODE_EXPERIMENTAL_LSP_TOOL=true (or OPENCODE_EXPERIMENTAL=true).\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"permission\": {    \"lsp\": \"allow\"  }}\n```\n\nSupported operations include goToDefinition, findReferences, hover, documentSymbol, workspaceSymbol, goToImplementation, prepareCallHierarchy, incomingCalls, and outgoingCalls.\n\nTo configure which LSP servers are available for your project, see LSP Servers.\n\n### patch\n\nApply patches to files.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"permission\": {    \"edit\": \"allow\"  }}\n```\n\nThis tool applies patch files to your codebase. Useful for applying diffs and patches from various sources.\n\nNote\n\nThe patch tool is controlled by the edit permission, which covers all file modifications (edit, write, patch, multiedit).\n\n### skill\n\nLoad a skill (a SKILL.md file) and return its content in the conversation.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"permission\": {    \"skill\": \"allow\"  }}\n```\n\n### todowrite\n\nManage todo lists during coding sessions.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"permission\": {    \"todowrite\": \"allow\"  }}\n```\n\nCreates and updates task lists to track progress during complex operations. The LLM uses this to organize multi-step tasks.\n\nNote\n\nThis tool is disabled for subagents by default, but you can enable it manually. Learn more\n\n### todoread\n\nRead existing todo lists.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"permission\": {    \"todoread\": \"allow\"  }}\n```\n\nReads the current todo list state. Used by the LLM to track what tasks are pending or completed.\n\nNote\n\nThis tool is disabled for subagents by default, but you can enable it manually. Learn more\n\n### webfetch\n\nFetch web content.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"permission\": {    \"webfetch\": \"allow\"  }}\n```\n\nAllows the LLM to fetch and read web pages. Useful for looking up documentation or researching online resources.\n\n### question\n\nAsk the user questions during execution.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"permission\": {    \"question\": \"allow\"  }}\n```\n\nThis tool allows the LLM to ask the user questions during a task. It’s useful for:\n\n- Gathering user preferences or requirements\n- Clarifying ambiguous instructions\n- Getting decisions on implementation choices\n- Offering choices about what direction to take\nEach question includes a header, the question text, and a list of options. Users can select from the provided options or type a custom answer. When there are multiple questions, users can navigate between them before submitting all answers.\n\n## Custom tools\n\nCustom tools let you define your own functions that the LLM can call. These are defined in your config file and can execute arbitrary code.\n\nLearn more about creating custom tools.\n\n## MCP servers\n\nMCP (Model Context Protocol) servers allow you to integrate external tools and services. This includes database access, API integrations, and third-party services.\n\nLearn more about configuring MCP servers.\n\n## Internals\n\nInternally, tools like grep, glob, and list use ripgrep under the hood. By default, ripgrep respects .gitignore patterns, which means files and directories listed in your .gitignore will be excluded from searches and listings.\n\n### Ignore patterns\n\nTo include files that would normally be ignored, create a .ignore file in your project root. This file can explicitly allow certain paths.\n\n```\n!node_modules/!dist/!build/\n```\n\nFor example, this .ignore file allows ripgrep to search within node_modules/, dist/, and build/ directories even if they’re listed in .gitignore.\n\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/tools.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "Tools",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "Configure",
          "id": "configure"
        },
        {
          "level": 2,
          "text": "Built-in",
          "id": "built-in"
        },
        {
          "level": 3,
          "text": "bash",
          "id": "bash"
        },
        {
          "level": 3,
          "text": "edit",
          "id": "edit"
        },
        {
          "level": 3,
          "text": "write",
          "id": "write"
        },
        {
          "level": 3,
          "text": "read",
          "id": "read"
        },
        {
          "level": 3,
          "text": "grep",
          "id": "grep"
        },
        {
          "level": 3,
          "text": "glob",
          "id": "glob"
        },
        {
          "level": 3,
          "text": "list",
          "id": "list"
        },
        {
          "level": 3,
          "text": "lsp (experimental)",
          "id": "lsp-experimental"
        },
        {
          "level": 3,
          "text": "patch",
          "id": "patch"
        },
        {
          "level": 3,
          "text": "skill",
          "id": "skill"
        },
        {
          "level": 3,
          "text": "todowrite",
          "id": "todowrite"
        },
        {
          "level": 3,
          "text": "todoread",
          "id": "todoread"
        },
        {
          "level": 3,
          "text": "webfetch",
          "id": "webfetch"
        },
        {
          "level": 3,
          "text": "question",
          "id": "question"
        },
        {
          "level": 2,
          "text": "Custom tools",
          "id": "custom-tools"
        },
        {
          "level": 2,
          "text": "MCP servers",
          "id": "mcp-servers"
        },
        {
          "level": 2,
          "text": "Internals",
          "id": "internals"
        },
        {
          "level": 3,
          "text": "Ignore patterns",
          "id": "ignore-patterns"
        }
      ],
      "category": "Configure",
      "scrapedAt": 1768685271919
    },
    {
      "path": "/docs/rules/",
      "title": "Rules",
      "url": "https://opencode.ai/docs/rules/",
      "content": "# Rules\n\nSet custom instructions for opencode.\n\nYou can provide custom instructions to opencode by creating an AGENTS.md file. This is similar to Cursor’s rules. It contains instructions that will be included in the LLM’s context to customize its behavior for your specific project.\n\n## Initialize\n\nTo create a new AGENTS.md file, you can run the /init command in opencode.\n\nTip\n\nYou should commit your project’s AGENTS.md file to Git.\n\nThis will scan your project and all its contents to understand what the project is about and generate an AGENTS.md file with it. This helps opencode to navigate the project better.\n\nIf you have an existing AGENTS.md file, this will try to add to it.\n\n## Example\n\nYou can also just create this file manually. Here’s an example of some things you can put into an AGENTS.md file.\n\n```\n# SST v3 Monorepo Project\nThis is an SST v3 monorepo with TypeScript. The project uses bun workspaces for package management.\n## Project Structure\n- `packages/` - Contains all workspace packages (functions, core, web, etc.)- `infra/` - Infrastructure definitions split by service (storage.ts, api.ts, web.ts)- `sst.config.ts` - Main SST configuration with dynamic imports\n## Code Standards\n- Use TypeScript with strict mode enabled- Shared code goes in `packages/core/` with proper exports configuration- Functions go in `packages/functions/`- Infrastructure should be split into logical files in `infra/`\n## Monorepo Conventions\n- Import shared modules using workspace names: `@my-app/core/example`\n```\n\nWe are adding project-specific instructions here and this will be shared across your team.\n\n## Types\n\nopencode also supports reading the AGENTS.md file from multiple locations. And this serves different purposes.\n\n### Project\n\nPlace an AGENTS.md in your project root for project-specific rules. These only apply when you are working in this directory or its sub-directories.\n\n### Global\n\nYou can also have global rules in a ~/.config/opencode/AGENTS.md file. This gets applied across all opencode sessions.\n\nSince this isn’t committed to Git or shared with your team, we recommend using this to specify any personal rules that the LLM should follow.\n\n### Claude Code Compatibility\n\nFor users migrating from Claude Code, OpenCode supports Claude Code’s file conventions as fallbacks:\n\n- Project rules: CLAUDE.md in your project directory (used if no AGENTS.md exists)\n- Global rules: ~/.claude/CLAUDE.md (used if no ~/.config/opencode/AGENTS.md exists)\n- Skills: ~/.claude/skills/ — see Agent Skills for details\nTo disable Claude Code compatibility, set one of these environment variables:\n\n```\nexport OPENCODE_DISABLE_CLAUDE_CODE=1        # Disable all .claude supportexport OPENCODE_DISABLE_CLAUDE_CODE_PROMPT=1 # Disable only ~/.claude/CLAUDE.mdexport OPENCODE_DISABLE_CLAUDE_CODE_SKILLS=1 # Disable only .claude/skills\n```\n\n## Precedence\n\nWhen opencode starts, it looks for rule files in this order:\n\n- Local files by traversing up from the current directory (AGENTS.md, CLAUDE.md, or CONTEXT.md)\n- Global file at ~/.config/opencode/AGENTS.md\n- Claude Code file at ~/.claude/CLAUDE.md (unless disabled)\nThe first matching file wins in each category. For example, if you have both AGENTS.md and CLAUDE.md, only AGENTS.md is used. Similarly, ~/.config/opencode/AGENTS.md takes precedence over ~/.claude/CLAUDE.md.\n\n## Custom Instructions\n\nYou can specify custom instruction files in your opencode.json or the global ~/.config/opencode/opencode.json. This allows you and your team to reuse existing rules rather than having to duplicate them to AGENTS.md.\n\nExample:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"instructions\": [\"CONTRIBUTING.md\", \"docs/guidelines.md\", \".cursor/rules/*.md\"]}\n```\n\nYou can also use remote URLs to load instructions from the web.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"instructions\": [\"https://raw.githubusercontent.com/my-org/shared-rules/main/style.md\"]}\n```\n\nRemote instructions are fetched with a 5 second timeout.\n\nAll instruction files are combined with your AGENTS.md files.\n\n## Referencing External Files\n\nWhile opencode doesn’t automatically parse file references in AGENTS.md, you can achieve similar functionality in two ways:\n\n### Using opencode.json\n\nThe recommended approach is to use the instructions field in opencode.json:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"instructions\": [\"docs/development-standards.md\", \"test/testing-guidelines.md\", \"packages/*/AGENTS.md\"]}\n```\n\n### Manual Instructions in AGENTS.md\n\nYou can teach opencode to read external files by providing explicit instructions in your AGENTS.md. Here’s a practical example:\n\n```\n# TypeScript Project Rules\n## External File Loading\nCRITICAL: When you encounter a file reference (e.g., @rules/general.md), use your Read tool to load it on a need-to-know basis. They're relevant to the SPECIFIC task at hand.\nInstructions:\n- Do NOT preemptively load all references - use lazy loading based on actual need- When loaded, treat content as mandatory instructions that override defaults- Follow references recursively when needed\n## Development Guidelines\nFor TypeScript code style and best practices: @docs/typescript-guidelines.mdFor React component architecture and hooks patterns: @docs/react-patterns.mdFor REST API design and error handling: @docs/api-standards.mdFor testing strategies and coverage requirements: @test/testing-guidelines.md\n## General Guidelines\nRead the following file immediately as it's relevant to all workflows: @rules/general-guidelines.md.\n```\n\nThis approach allows you to:\n\n- Create modular, reusable rule files\n- Share rules across projects via symlinks or git submodules\n- Keep AGENTS.md concise while referencing detailed guidelines\n- Ensure opencode loads files only when needed for the specific task\nTip\n\nFor monorepos or projects with shared standards, using opencode.json with glob patterns (like packages/*/AGENTS.md) is more maintainable than manual instructions.\n\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/rules.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "Rules",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "Initialize",
          "id": "initialize"
        },
        {
          "level": 2,
          "text": "Example",
          "id": "example"
        },
        {
          "level": 2,
          "text": "Types",
          "id": "types"
        },
        {
          "level": 3,
          "text": "Project",
          "id": "project"
        },
        {
          "level": 3,
          "text": "Global",
          "id": "global"
        },
        {
          "level": 3,
          "text": "Claude Code Compatibility",
          "id": "claude-code-compatibility"
        },
        {
          "level": 2,
          "text": "Precedence",
          "id": "precedence"
        },
        {
          "level": 2,
          "text": "Custom Instructions",
          "id": "custom-instructions"
        },
        {
          "level": 2,
          "text": "Referencing External Files",
          "id": "referencing-external-files"
        },
        {
          "level": 3,
          "text": "Using opencode.json",
          "id": "using-opencodejson"
        },
        {
          "level": 3,
          "text": "Manual Instructions in AGENTS.md",
          "id": "manual-instructions-in-agentsmd"
        }
      ],
      "category": "Configure",
      "scrapedAt": 1768685272269
    },
    {
      "path": "/docs/agents/",
      "title": "Agents",
      "url": "https://opencode.ai/docs/agents/",
      "content": "# Agents\n\nConfigure and use specialized agents.\n\nAgents are specialized AI assistants that can be configured for specific tasks and workflows. They allow you to create focused tools with custom prompts, models, and tool access.\n\nTip\n\nUse the plan agent to analyze code and review suggestions without making any code changes.\n\nYou can switch between agents during a session or invoke them with the @ mention.\n\n## Types\n\nThere are two types of agents in OpenCode; primary agents and subagents.\n\n### Primary agents\n\nPrimary agents are the main assistants you interact with directly. You can cycle through them using the Tab key, or your configured switch_agent keybind. These agents handle your main conversation and can access all configured tools.\n\nTip\n\nYou can use the Tab key to switch between primary agents during a session.\n\nOpenCode comes with two built-in primary agents, Build and Plan. We’ll\nlook at these below.\n\n### Subagents\n\nSubagents are specialized assistants that primary agents can invoke for specific tasks. You can also manually invoke them by @ mentioning them in your messages.\n\nOpenCode comes with two built-in subagents, General and Explore. We’ll look at this below.\n\n## Built-in\n\nOpenCode comes with two built-in primary agents and two built-in subagents.\n\n### Build\n\nMode: primary\n\nBuild is the default primary agent with all tools enabled. This is the standard agent for development work where you need full access to file operations and system commands.\n\n### Plan\n\nMode: primary\n\nA restricted agent designed for planning and analysis. We use a permission system to give you more control and prevent unintended changes.\nBy default, all of the following are set to ask:\n\n- file edits: All writes, patches, and edits\n- bash: All bash commands\nThis agent is useful when you want the LLM to analyze code, suggest changes, or create plans without making any actual modifications to your codebase.\n\n### General\n\nMode: subagent\n\nA general-purpose agent for researching complex questions, searching for code, and executing multi-step tasks. Use when searching for keywords or files and you’re not confident you’ll find the right match in the first few tries.\n\n### Explore\n\nMode: subagent\n\nA fast agent specialized for exploring codebases. Use this when you need to quickly find files by patterns, search code for keywords, or answer questions about the codebase.\n\n## Usage\n\n- For primary agents, use the Tab key to cycle through them during a session. You can also use your configured switch_agent keybind.\nFor primary agents, use the Tab key to cycle through them during a session. You can also use your configured switch_agent keybind.\n\n- Subagents can be invoked:\n\nAutomatically by primary agents for specialized tasks based on their descriptions.\n\nManually by @ mentioning a subagent in your message. For example.\n@general help me search for this function\nSubagents can be invoked:\n\n- Automatically by primary agents for specialized tasks based on their descriptions.\nAutomatically by primary agents for specialized tasks based on their descriptions.\n\n- Manually by @ mentioning a subagent in your message. For example.\n@general help me search for this function\nManually by @ mentioning a subagent in your message. For example.\n\n```\n@general help me search for this function\n```\n\n- Navigation between sessions: When subagents create their own child sessions, you can navigate between the parent session and all child sessions using:\n\n<Leader>+Right (or your configured session_child_cycle keybind) to cycle forward through parent → child1 → child2 → … → parent\n<Leader>+Left (or your configured session_child_cycle_reverse keybind) to cycle backward through parent ← child1 ← child2 ← … ← parent\n\nThis allows you to seamlessly switch between the main conversation and specialized subagent work.\nNavigation between sessions: When subagents create their own child sessions, you can navigate between the parent session and all child sessions using:\n\n- <Leader>+Right (or your configured session_child_cycle keybind) to cycle forward through parent → child1 → child2 → … → parent\n- <Leader>+Left (or your configured session_child_cycle_reverse keybind) to cycle backward through parent ← child1 ← child2 ← … ← parent\nThis allows you to seamlessly switch between the main conversation and specialized subagent work.\n\n## Configure\n\nYou can customize the built-in agents or create your own through configuration. Agents can be configured in two ways:\n\n### JSON\n\nConfigure agents in your opencode.json config file:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"agent\": {    \"build\": {      \"mode\": \"primary\",      \"model\": \"anthropic/claude-sonnet-4-20250514\",      \"prompt\": \"{file:./prompts/build.txt}\",      \"tools\": {        \"write\": true,        \"edit\": true,        \"bash\": true      }    },    \"plan\": {      \"mode\": \"primary\",      \"model\": \"anthropic/claude-haiku-4-20250514\",      \"tools\": {        \"write\": false,        \"edit\": false,        \"bash\": false      }    },    \"code-reviewer\": {      \"description\": \"Reviews code for best practices and potential issues\",      \"mode\": \"subagent\",      \"model\": \"anthropic/claude-sonnet-4-20250514\",      \"prompt\": \"You are a code reviewer. Focus on security, performance, and maintainability.\",      \"tools\": {        \"write\": false,        \"edit\": false      }    }  }}\n```\n\n### Markdown\n\nYou can also define agents using markdown files. Place them in:\n\n- Global: ~/.config/opencode/agent/\n- Per-project: .opencode/agent/\n\n```\n---description: Reviews code for quality and best practicesmode: subagentmodel: anthropic/claude-sonnet-4-20250514temperature: 0.1tools:  write: false  edit: false  bash: false---\nYou are in code review mode. Focus on:\n- Code quality and best practices- Potential bugs and edge cases- Performance implications- Security considerations\nProvide constructive feedback without making direct changes.\n```\n\nThe markdown file name becomes the agent name. For example, review.md creates a review agent.\n\n## Options\n\nLet’s look at these configuration options in detail.\n\n### Description\n\nUse the description option to provide a brief description of what the agent does and when to use it.\n\n```\n{  \"agent\": {    \"review\": {      \"description\": \"Reviews code for best practices and potential issues\"    }  }}\n```\n\nThis is a required config option.\n\n### Temperature\n\nControl the randomness and creativity of the LLM’s responses with the temperature config.\n\nLower values make responses more focused and deterministic, while higher values increase creativity and variability.\n\n```\n{  \"agent\": {    \"plan\": {      \"temperature\": 0.1    },    \"creative\": {      \"temperature\": 0.8    }  }}\n```\n\nTemperature values typically range from 0.0 to 1.0:\n\n- 0.0-0.2: Very focused and deterministic responses, ideal for code analysis and planning\n- 0.3-0.5: Balanced responses with some creativity, good for general development tasks\n- 0.6-1.0: More creative and varied responses, useful for brainstorming and exploration\n\n```\n{  \"agent\": {    \"analyze\": {      \"temperature\": 0.1,      \"prompt\": \"{file:./prompts/analysis.txt}\"    },    \"build\": {      \"temperature\": 0.3    },    \"brainstorm\": {      \"temperature\": 0.7,      \"prompt\": \"{file:./prompts/creative.txt}\"    }  }}\n```\n\nIf no temperature is specified, OpenCode uses model-specific defaults; typically 0 for most models, 0.55 for Qwen models.\n\n### Max steps\n\nControl the maximum number of agentic iterations an agent can perform before being forced to respond with text only. This allows users who wish to control costs to set a limit on agentic actions.\n\nIf this is not set, the agent will continue to iterate until the model chooses to stop or the user interrupts the session.\n\n```\n{  \"agent\": {    \"quick-thinker\": {      \"description\": \"Fast reasoning with limited iterations\",      \"prompt\": \"You are a quick thinker. Solve problems with minimal steps.\",      \"maxSteps\": 5    }  }}\n```\n\nWhen the limit is reached, the agent receives a special system prompt instructing it to respond with a summarization of its work and recommended remaining tasks.\n\n### Disable\n\nSet to true to disable the agent.\n\n```\n{  \"agent\": {    \"review\": {      \"disable\": true    }  }}\n```\n\n### Prompt\n\nSpecify a custom system prompt file for this agent with the prompt config. The prompt file should contain instructions specific to the agent’s purpose.\n\n```\n{  \"agent\": {    \"review\": {      \"prompt\": \"{file:./prompts/code-review.txt}\"    }  }}\n```\n\nThis path is relative to where the config file is located. So this works for both the global OpenCode config and the project specific config.\n\n### Model\n\nUse the model config to override the model for this agent. Useful for using different models optimized for different tasks. For example, a faster model for planning, a more capable model for implementation.\n\nTip\n\nIf you don’t specify a model, primary agents use the model globally configured while subagents will use the model of the primary agent that invoked the subagent.\n\n```\n{  \"agent\": {    \"plan\": {      \"model\": \"anthropic/claude-haiku-4-20250514\"    }  }}\n```\n\nThe model ID in your OpenCode config uses the format provider/model-id. For example, if you’re using OpenCode Zen, you would use opencode/gpt-5.1-codex for GPT 5.1 Codex.\n\n### Tools\n\nControl which tools are available in this agent with the tools config. You can enable or disable specific tools by setting them to true or false.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"tools\": {    \"write\": true,    \"bash\": true  },  \"agent\": {    \"plan\": {      \"tools\": {        \"write\": false,        \"bash\": false      }    }  }}\n```\n\nNote\n\nThe agent-specific config overrides the global config.\n\nYou can also use wildcards to control multiple tools at once. For example, to disable all tools from an MCP server:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"agent\": {    \"readonly\": {      \"tools\": {        \"mymcp_*\": false,        \"write\": false,        \"edit\": false      }    }  }}\n```\n\nLearn more about tools.\n\n### Permissions\n\nYou can configure permissions to manage what actions an agent can take. Currently, the permissions for the edit, bash, and webfetch tools can be configured to:\n\n- \"ask\" — Prompt for approval before running the tool\n- \"allow\" — Allow all operations without approval\n- \"deny\" — Disable the tool\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"permission\": {    \"edit\": \"deny\"  }}\n```\n\nYou can override these permissions per agent.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"permission\": {    \"edit\": \"deny\"  },  \"agent\": {    \"build\": {      \"permission\": {        \"edit\": \"ask\"      }    }  }}\n```\n\nYou can also set permissions in Markdown agents.\n\n```\n---description: Code review without editsmode: subagentpermission:  edit: deny  bash:    \"*\": ask    \"git diff\": allow    \"git log*\": allow    \"grep *\": allow  webfetch: deny---\nOnly analyze code and suggest changes.\n```\n\nYou can set permissions for specific bash commands.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"agent\": {    \"build\": {      \"permission\": {        \"bash\": {          \"git push\": \"ask\",          \"grep *\": \"allow\"        }      }    }  }}\n```\n\nThis can take a glob pattern.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"agent\": {    \"build\": {      \"permission\": {        \"bash\": {          \"git *\": \"ask\"        }      }    }  }}\n```\n\nAnd you can also use the * wildcard to manage permissions for all commands.\nSince the last matching rule takes precedence, put the * wildcard first and specific rules after.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"agent\": {    \"build\": {      \"permission\": {        \"bash\": {          \"*\": \"ask\",          \"git status *\": \"allow\"        }      }    }  }}\n```\n\nLearn more about permissions.\n\n### Mode\n\nControl the agent’s mode with the mode config. The mode option is used to determine how the agent can be used.\n\n```\n{  \"agent\": {    \"review\": {      \"mode\": \"subagent\"    }  }}\n```\n\nThe mode option can be set to primary, subagent, or all. If no mode is specified, it defaults to all.\n\n### Hidden\n\nHide a subagent from the @ autocomplete menu with hidden: true. Useful for internal subagents that should only be invoked programmatically by other agents via the Task tool.\n\n```\n{  \"agent\": {    \"internal-helper\": {      \"mode\": \"subagent\",      \"hidden\": true    }  }}\n```\n\nThis only affects user visibility in the autocomplete menu. Hidden agents can still be invoked by the model via the Task tool if permissions allow.\n\nNote\n\nOnly applies to mode: subagent agents.\n\n### Task permissions\n\nControl which subagents an agent can invoke via the Task tool with permission.task. Uses glob patterns for flexible matching.\n\n```\n{  \"agent\": {    \"orchestrator\": {      \"mode\": \"primary\",      \"permission\": {        \"task\": {          \"*\": \"deny\",          \"orchestrator-*\": \"allow\",          \"code-reviewer\": \"ask\"        }      }    }  }}\n```\n\nWhen set to deny, the subagent is removed from the Task tool description entirely, so the model won’t attempt to invoke it.\n\nTip\n\nRules are evaluated in order, and the last matching rule wins. In the example above, orchestrator-planner matches both * (deny) and orchestrator-* (allow), but since orchestrator-* comes after *, the result is allow.\n\nTip\n\nUsers can always invoke any subagent directly via the @ autocomplete menu, even if the agent’s task permissions would deny it.\n\n### Additional\n\nAny other options you specify in your agent configuration will be passed through directly to the provider as model options. This allows you to use provider-specific features and parameters.\n\nFor example, with OpenAI’s reasoning models, you can control the reasoning effort:\n\n```\n{  \"agent\": {    \"deep-thinker\": {      \"description\": \"Agent that uses high reasoning effort for complex problems\",      \"model\": \"openai/gpt-5\",      \"reasoningEffort\": \"high\",      \"textVerbosity\": \"low\"    }  }}\n```\n\nThese additional options are model and provider-specific. Check your provider’s documentation for available parameters.\n\nTip\n\nRun opencode models to see a list of the available models.\n\n## Create agents\n\nYou can create new agents using the following command:\n\n```\nopencode agent create\n```\n\nThis interactive command will:\n\n- Ask where to save the agent; global or project-specific.\n- Description of what the agent should do.\n- Generate an appropriate system prompt and identifier.\n- Let you select which tools the agent can access.\n- Finally, create a markdown file with the agent configuration.\n\n## Use cases\n\nHere are some common use cases for different agents.\n\n- Build agent: Full development work with all tools enabled\n- Plan agent: Analysis and planning without making changes\n- Review agent: Code review with read-only access plus documentation tools\n- Debug agent: Focused on investigation with bash and read tools enabled\n- Docs agent: Documentation writing with file operations but no system commands\n\n## Examples\n\nHere are some example agents you might find useful.\n\nTip\n\nDo you have an agent you’d like to share? Submit a PR.\n\n### Documentation agent\n\n```\n---description: Writes and maintains project documentationmode: subagenttools:  bash: false---\nYou are a technical writer. Create clear, comprehensive documentation.\nFocus on:\n- Clear explanations- Proper structure- Code examples- User-friendly language\n```\n\n### Security auditor\n\n```\n---description: Performs security audits and identifies vulnerabilitiesmode: subagenttools:  write: false  edit: false---\nYou are a security expert. Focus on identifying potential security issues.\nLook for:\n- Input validation vulnerabilities- Authentication and authorization flaws- Data exposure risks- Dependency vulnerabilities- Configuration security issues\n```\n\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/agents.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "Agents",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "Types",
          "id": "types"
        },
        {
          "level": 3,
          "text": "Primary agents",
          "id": "primary-agents"
        },
        {
          "level": 3,
          "text": "Subagents",
          "id": "subagents"
        },
        {
          "level": 2,
          "text": "Built-in",
          "id": "built-in"
        },
        {
          "level": 3,
          "text": "Build",
          "id": "build"
        },
        {
          "level": 3,
          "text": "Plan",
          "id": "plan"
        },
        {
          "level": 3,
          "text": "General",
          "id": "general"
        },
        {
          "level": 3,
          "text": "Explore",
          "id": "explore"
        },
        {
          "level": 2,
          "text": "Usage",
          "id": "usage"
        },
        {
          "level": 2,
          "text": "Configure",
          "id": "configure"
        },
        {
          "level": 3,
          "text": "JSON",
          "id": "json"
        },
        {
          "level": 3,
          "text": "Markdown",
          "id": "markdown"
        },
        {
          "level": 2,
          "text": "Options",
          "id": "options"
        },
        {
          "level": 3,
          "text": "Description",
          "id": "description"
        },
        {
          "level": 3,
          "text": "Temperature",
          "id": "temperature"
        },
        {
          "level": 3,
          "text": "Max steps",
          "id": "max-steps"
        },
        {
          "level": 3,
          "text": "Disable",
          "id": "disable"
        },
        {
          "level": 3,
          "text": "Prompt",
          "id": "prompt"
        },
        {
          "level": 3,
          "text": "Model",
          "id": "model"
        },
        {
          "level": 3,
          "text": "Tools",
          "id": "tools"
        },
        {
          "level": 3,
          "text": "Permissions",
          "id": "permissions"
        },
        {
          "level": 3,
          "text": "Mode",
          "id": "mode"
        },
        {
          "level": 3,
          "text": "Hidden",
          "id": "hidden"
        },
        {
          "level": 3,
          "text": "Task permissions",
          "id": "task-permissions"
        },
        {
          "level": 3,
          "text": "Additional",
          "id": "additional"
        },
        {
          "level": 2,
          "text": "Create agents",
          "id": "create-agents"
        },
        {
          "level": 2,
          "text": "Use cases",
          "id": "use-cases"
        },
        {
          "level": 2,
          "text": "Examples",
          "id": "examples"
        },
        {
          "level": 3,
          "text": "Documentation agent",
          "id": "documentation-agent"
        },
        {
          "level": 3,
          "text": "Security auditor",
          "id": "security-auditor"
        }
      ],
      "category": "Configure",
      "scrapedAt": 1768685272623
    },
    {
      "path": "/docs/models/",
      "title": "Models",
      "url": "https://opencode.ai/docs/models/",
      "content": "# Models\n\nConfiguring an LLM provider and model.\n\nOpenCode uses the AI SDK and Models.dev to support 75+ LLM providers and it supports running local models.\n\n## Providers\n\nMost popular providers are preloaded by default. If you’ve added the credentials for a provider through the /connect command, they’ll be available when you start OpenCode.\n\nLearn more about providers.\n\n## Select a model\n\nOnce you’ve configured your provider you can select the model you want by typing in:\n\n```\n/models\n```\n\n## Recommended models\n\nThere are a lot of models out there, with new models coming out every week.\n\nTip\n\nConsider using one of the models we recommend.\n\nHowever, there are only a few of them that are good at both generating code and tool calling.\n\nHere are several models that work well with OpenCode, in no particular order. (This is not an exhaustive list nor is it necessarily up to date):\n\n- GPT 5.2\n- GPT 5.1 Codex\n- Claude Opus 4.5\n- Claude Sonnet 4.5\n- Minimax M2.1\n- Gemini 3 Pro\n\n## Set a default\n\nTo set one of these as the default model, you can set the model key in your\nOpenCode config.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"model\": \"lmstudio/google/gemma-3n-e4b\"}\n```\n\nHere the full ID is provider_id/model_id. For example, if you’re using OpenCode Zen, you would use opencode/gpt-5.1-codex for GPT 5.1 Codex.\n\nIf you’ve configured a custom provider, the provider_id is key from the provider part of your config, and the model_id is the key from provider.models.\n\n## Configure models\n\nYou can globally configure a model’s options through the config.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"openai\": {      \"models\": {        \"gpt-5\": {          \"options\": {            \"reasoningEffort\": \"high\",            \"textVerbosity\": \"low\",            \"reasoningSummary\": \"auto\",            \"include\": [\"reasoning.encrypted_content\"],          },        },      },    },    \"anthropic\": {      \"models\": {        \"claude-sonnet-4-5-20250929\": {          \"options\": {            \"thinking\": {              \"type\": \"enabled\",              \"budgetTokens\": 16000,            },          },        },      },    },  },}\n```\n\nHere we’re configuring global settings for two built-in models: gpt-5 when accessed via the openai provider, and claude-sonnet-4-20250514 when accessed via the anthropic provider.\nThe built-in provider and model names can be found on Models.dev.\n\nYou can also configure these options for any agents that you are using. The agent config overrides any global options here. Learn more.\n\nYou can also define custom variants that extend built-in ones. Variants let you configure different settings for the same model without creating duplicate entries:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"opencode\": {      \"models\": {        \"gpt-5\": {          \"variants\": {            \"high\": {              \"reasoningEffort\": \"high\",              \"textVerbosity\": \"low\",              \"reasoningSummary\": \"auto\",            },            \"low\": {              \"reasoningEffort\": \"low\",              \"textVerbosity\": \"low\",              \"reasoningSummary\": \"auto\",            },          },        },      },    },  },}\n```\n\n## Variants\n\nMany models support multiple variants with different configurations. OpenCode ships with built-in default variants for popular providers.\n\n### Built-in variants\n\nOpenCode ships with default variants for many providers:\n\nAnthropic:\n\n- high - High thinking budget (default)\n- max - Maximum thinking budget\nOpenAI:\n\nVaries by model but roughly:\n\n- none - No reasoning\n- minimal - Minimal reasoning effort\n- low - Low reasoning effort\n- medium - Medium reasoning effort\n- high - High reasoning effort\n- xhigh - Extra high reasoning effort\nGoogle:\n\n- low - Lower effort/token budget\n- high - Higher effort/token budget\nTip\n\nThis list is not comprehensive. Many other providers have built-in defaults too.\n\n### Custom variants\n\nYou can override existing variants or add your own:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"provider\": {    \"openai\": {      \"models\": {        \"gpt-5\": {          \"variants\": {            \"thinking\": {              \"reasoningEffort\": \"high\",              \"textVerbosity\": \"low\",            },            \"fast\": {              \"disabled\": true,            },          },        },      },    },  },}\n```\n\n### Cycle variants\n\nUse the keybind variant_cycle to quickly switch between variants. Learn more.\n\n## Loading models\n\nWhen OpenCode starts up, it checks for models in the following priority order:\n\n- The --model or -m command line flag. The format is the same as in the config file: provider_id/model_id.\nThe --model or -m command line flag. The format is the same as in the config file: provider_id/model_id.\n\n- The model list in the OpenCode config.\nopencode.json{  \"$schema\": \"https://opencode.ai/config.json\",  \"model\": \"anthropic/claude-sonnet-4-20250514\"}\nThe format here is provider/model.\nThe model list in the OpenCode config.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"model\": \"anthropic/claude-sonnet-4-20250514\"}\n```\n\nThe format here is provider/model.\n\n- The last used model.\nThe last used model.\n\n- The first model using an internal priority.\nThe first model using an internal priority.\n\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/models.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "Models",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "Providers",
          "id": "providers"
        },
        {
          "level": 2,
          "text": "Select a model",
          "id": "select-a-model"
        },
        {
          "level": 2,
          "text": "Recommended models",
          "id": "recommended-models"
        },
        {
          "level": 2,
          "text": "Set a default",
          "id": "set-a-default"
        },
        {
          "level": 2,
          "text": "Configure models",
          "id": "configure-models"
        },
        {
          "level": 2,
          "text": "Variants",
          "id": "variants"
        },
        {
          "level": 3,
          "text": "Built-in variants",
          "id": "built-in-variants"
        },
        {
          "level": 3,
          "text": "Custom variants",
          "id": "custom-variants"
        },
        {
          "level": 3,
          "text": "Cycle variants",
          "id": "cycle-variants"
        },
        {
          "level": 2,
          "text": "Loading models",
          "id": "loading-models"
        }
      ],
      "category": "Configure",
      "scrapedAt": 1768685272973
    },
    {
      "path": "/docs/themes/",
      "title": "Themes",
      "url": "https://opencode.ai/docs/themes/",
      "content": "# Themes\n\nSelect a built-in theme or define your own.\n\nWith OpenCode you can select from one of several built-in themes, use a theme that adapts to your terminal theme, or define your own custom theme.\n\nBy default, OpenCode uses our own opencode theme.\n\n## Terminal requirements\n\nFor themes to display correctly with their full color palette, your terminal must support truecolor (24-bit color). Most modern terminals support this by default, but you may need to enable it:\n\n- Check support: Run echo $COLORTERM - it should output truecolor or 24bit\n- Enable truecolor: Set the environment variable COLORTERM=truecolor in your shell profile\n- Terminal compatibility: Ensure your terminal emulator supports 24-bit color (most modern terminals like iTerm2, Alacritty, Kitty, Windows Terminal, and recent versions of GNOME Terminal do)\nWithout truecolor support, themes may appear with reduced color accuracy or fall back to the nearest 256-color approximation.\n\n## Built-in themes\n\nOpenCode comes with several built-in themes.\n\n[Tokyonight](https://github.com/folke/tokyonight.nvim) [Everforest](https://github.com/sainnhe/everforest) [Ayu](https://github.com/ayu-theme) [Catppuccin](https://github.com/catppuccin) [Gruvbox](https://github.com/morhetz/gruvbox) [Kanagawa](https://github.com/rebelot/kanagawa.nvim) [Nord](https://github.com/nordtheme/nord) [Atom One](https://github.com/Th3Whit3Wolf/one-nvim) And more, we are constantly adding new themes.\n\n## System theme\n\nThe system theme is designed to automatically adapt to your terminal’s color scheme. Unlike traditional themes that use fixed colors, the system theme:\n\n- Generates gray scale: Creates a custom gray scale based on your terminal’s background color, ensuring optimal contrast.\n- Uses ANSI colors: Leverages standard ANSI colors (0-15) for syntax highlighting and UI elements, which respect your terminal’s color palette.\n- Preserves terminal defaults: Uses none for text and background colors to maintain your terminal’s native appearance.\nThe system theme is for users who:\n\n- Want OpenCode to match their terminal’s appearance\n- Use custom terminal color schemes\n- Prefer a consistent look across all terminal applications\n\n## Using a theme\n\nYou can select a theme by bringing up the theme select with the /theme command. Or you can specify it in your config.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"theme\": \"tokyonight\"}\n```\n\n## Custom themes\n\nOpenCode supports a flexible JSON-based theme system that allows users to create and customize themes easily.\n\n### Hierarchy\n\nThemes are loaded from multiple directories in the following order where later directories override earlier ones:\n\n- Built-in themes - These are embedded in the binary\n- User config directory - Defined in ~/.config/opencode/themes/*.json or $XDG_CONFIG_HOME/opencode/themes/*.json\n- Project root directory - Defined in the <project-root>/.opencode/themes/*.json\n- Current working directory - Defined in ./.opencode/themes/*.json\nIf multiple directories contain a theme with the same name, the theme from the directory with higher priority will be used.\n\n### Creating a theme\n\nTo create a custom theme, create a JSON file in one of the theme directories.\n\nFor user-wide themes:\n\n```\nmkdir -p ~/.config/opencode/themesvim ~/.config/opencode/themes/my-theme.json\n```\n\nAnd for project-specific themes.\n\n```\nmkdir -p .opencode/themesvim .opencode/themes/my-theme.json\n```\n\n### JSON format\n\nThemes use a flexible JSON format with support for:\n\n- Hex colors: \"#ffffff\"\n- ANSI colors: 3 (0-255)\n- Color references: \"primary\" or custom definitions\n- Dark/light variants: {\"dark\": \"#000\", \"light\": \"#fff\"}\n- No color: \"none\" - Uses the terminal’s default color or transparent\n\n### Color definitions\n\nThe defs section is optional and it allows you to define reusable colors that can be referenced in the theme.\n\n### Terminal defaults\n\nThe special value \"none\" can be used for any color to inherit the terminal’s default color. This is particularly useful for creating themes that blend seamlessly with your terminal’s color scheme:\n\n- \"text\": \"none\" - Uses terminal’s default foreground color\n- \"background\": \"none\" - Uses terminal’s default background color\n\n### Example\n\nHere’s an example of a custom theme:\n\n```\n{  \"$schema\": \"https://opencode.ai/theme.json\",  \"defs\": {    \"nord0\": \"#2E3440\",    \"nord1\": \"#3B4252\",    \"nord2\": \"#434C5E\",    \"nord3\": \"#4C566A\",    \"nord4\": \"#D8DEE9\",    \"nord5\": \"#E5E9F0\",    \"nord6\": \"#ECEFF4\",    \"nord7\": \"#8FBCBB\",    \"nord8\": \"#88C0D0\",    \"nord9\": \"#81A1C1\",    \"nord10\": \"#5E81AC\",    \"nord11\": \"#BF616A\",    \"nord12\": \"#D08770\",    \"nord13\": \"#EBCB8B\",    \"nord14\": \"#A3BE8C\",    \"nord15\": \"#B48EAD\"  },  \"theme\": {    \"primary\": {      \"dark\": \"nord8\",      \"light\": \"nord10\"    },    \"secondary\": {      \"dark\": \"nord9\",      \"light\": \"nord9\"    },    \"accent\": {      \"dark\": \"nord7\",      \"light\": \"nord7\"    },    \"error\": {      \"dark\": \"nord11\",      \"light\": \"nord11\"    },    \"warning\": {      \"dark\": \"nord12\",      \"light\": \"nord12\"    },    \"success\": {      \"dark\": \"nord14\",      \"light\": \"nord14\"    },    \"info\": {      \"dark\": \"nord8\",      \"light\": \"nord10\"    },    \"text\": {      \"dark\": \"nord4\",      \"light\": \"nord0\"    },    \"textMuted\": {      \"dark\": \"nord3\",      \"light\": \"nord1\"    },    \"background\": {      \"dark\": \"nord0\",      \"light\": \"nord6\"    },    \"backgroundPanel\": {      \"dark\": \"nord1\",      \"light\": \"nord5\"    },    \"backgroundElement\": {      \"dark\": \"nord1\",      \"light\": \"nord4\"    },    \"border\": {      \"dark\": \"nord2\",      \"light\": \"nord3\"    },    \"borderActive\": {      \"dark\": \"nord3\",      \"light\": \"nord2\"    },    \"borderSubtle\": {      \"dark\": \"nord2\",      \"light\": \"nord3\"    },    \"diffAdded\": {      \"dark\": \"nord14\",      \"light\": \"nord14\"    },    \"diffRemoved\": {      \"dark\": \"nord11\",      \"light\": \"nord11\"    },    \"diffContext\": {      \"dark\": \"nord3\",      \"light\": \"nord3\"    },    \"diffHunkHeader\": {      \"dark\": \"nord3\",      \"light\": \"nord3\"    },    \"diffHighlightAdded\": {      \"dark\": \"nord14\",      \"light\": \"nord14\"    },    \"diffHighlightRemoved\": {      \"dark\": \"nord11\",      \"light\": \"nord11\"    },    \"diffAddedBg\": {      \"dark\": \"#3B4252\",      \"light\": \"#E5E9F0\"    },    \"diffRemovedBg\": {      \"dark\": \"#3B4252\",      \"light\": \"#E5E9F0\"    },    \"diffContextBg\": {      \"dark\": \"nord1\",      \"light\": \"nord5\"    },    \"diffLineNumber\": {      \"dark\": \"nord2\",      \"light\": \"nord4\"    },    \"diffAddedLineNumberBg\": {      \"dark\": \"#3B4252\",      \"light\": \"#E5E9F0\"    },    \"diffRemovedLineNumberBg\": {      \"dark\": \"#3B4252\",      \"light\": \"#E5E9F0\"    },    \"markdownText\": {      \"dark\": \"nord4\",      \"light\": \"nord0\"    },    \"markdownHeading\": {      \"dark\": \"nord8\",      \"light\": \"nord10\"    },    \"markdownLink\": {      \"dark\": \"nord9\",      \"light\": \"nord9\"    },    \"markdownLinkText\": {      \"dark\": \"nord7\",      \"light\": \"nord7\"    },    \"markdownCode\": {      \"dark\": \"nord14\",      \"light\": \"nord14\"    },    \"markdownBlockQuote\": {      \"dark\": \"nord3\",      \"light\": \"nord3\"    },    \"markdownEmph\": {      \"dark\": \"nord12\",      \"light\": \"nord12\"    },    \"markdownStrong\": {      \"dark\": \"nord13\",      \"light\": \"nord13\"    },    \"markdownHorizontalRule\": {      \"dark\": \"nord3\",      \"light\": \"nord3\"    },    \"markdownListItem\": {      \"dark\": \"nord8\",      \"light\": \"nord10\"    },    \"markdownListEnumeration\": {      \"dark\": \"nord7\",      \"light\": \"nord7\"    },    \"markdownImage\": {      \"dark\": \"nord9\",      \"light\": \"nord9\"    },    \"markdownImageText\": {      \"dark\": \"nord7\",      \"light\": \"nord7\"    },    \"markdownCodeBlock\": {      \"dark\": \"nord4\",      \"light\": \"nord0\"    },    \"syntaxComment\": {      \"dark\": \"nord3\",      \"light\": \"nord3\"    },    \"syntaxKeyword\": {      \"dark\": \"nord9\",      \"light\": \"nord9\"    },    \"syntaxFunction\": {      \"dark\": \"nord8\",      \"light\": \"nord8\"    },    \"syntaxVariable\": {      \"dark\": \"nord7\",      \"light\": \"nord7\"    },    \"syntaxString\": {      \"dark\": \"nord14\",      \"light\": \"nord14\"    },    \"syntaxNumber\": {      \"dark\": \"nord15\",      \"light\": \"nord15\"    },    \"syntaxType\": {      \"dark\": \"nord7\",      \"light\": \"nord7\"    },    \"syntaxOperator\": {      \"dark\": \"nord9\",      \"light\": \"nord9\"    },    \"syntaxPunctuation\": {      \"dark\": \"nord4\",      \"light\": \"nord0\"    }  }}\n```\n\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/themes.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "Themes",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "Terminal requirements",
          "id": "terminal-requirements"
        },
        {
          "level": 2,
          "text": "Built-in themes",
          "id": "built-in-themes"
        },
        {
          "level": 2,
          "text": "System theme",
          "id": "system-theme"
        },
        {
          "level": 2,
          "text": "Using a theme",
          "id": "using-a-theme"
        },
        {
          "level": 2,
          "text": "Custom themes",
          "id": "custom-themes"
        },
        {
          "level": 3,
          "text": "Hierarchy",
          "id": "hierarchy"
        },
        {
          "level": 3,
          "text": "Creating a theme",
          "id": "creating-a-theme"
        },
        {
          "level": 3,
          "text": "JSON format",
          "id": "json-format"
        },
        {
          "level": 3,
          "text": "Color definitions",
          "id": "color-definitions"
        },
        {
          "level": 3,
          "text": "Terminal defaults",
          "id": "terminal-defaults"
        },
        {
          "level": 3,
          "text": "Example",
          "id": "example"
        }
      ],
      "category": "Configure",
      "scrapedAt": 1768685273330
    },
    {
      "path": "/docs/keybinds/",
      "title": "Keybinds",
      "url": "https://opencode.ai/docs/keybinds/",
      "content": "# Keybinds\n\nCustomize your keybinds.\n\nOpenCode has a list of keybinds that you can customize through the OpenCode config.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"keybinds\": {    \"leader\": \"ctrl+x\",    \"app_exit\": \"ctrl+c,ctrl+d,<leader>q\",    \"editor_open\": \"<leader>e\",    \"theme_list\": \"<leader>t\",    \"sidebar_toggle\": \"<leader>b\",    \"scrollbar_toggle\": \"none\",    \"username_toggle\": \"none\",    \"status_view\": \"<leader>s\",    \"tool_details\": \"none\",    \"session_export\": \"<leader>x\",    \"session_new\": \"<leader>n\",    \"session_list\": \"<leader>l\",    \"session_timeline\": \"<leader>g\",    \"session_fork\": \"none\",    \"session_rename\": \"none\",    \"session_share\": \"none\",    \"session_unshare\": \"none\",    \"session_interrupt\": \"escape\",    \"session_compact\": \"<leader>c\",    \"session_child_cycle\": \"<leader>right\",    \"session_child_cycle_reverse\": \"<leader>left\",    \"session_parent\": \"<leader>up\",    \"messages_page_up\": \"pageup\",    \"messages_page_down\": \"pagedown\",    \"messages_half_page_up\": \"ctrl+alt+u\",    \"messages_half_page_down\": \"ctrl+alt+d\",    \"messages_first\": \"ctrl+g,home\",    \"messages_last\": \"ctrl+alt+g,end\",    \"messages_next\": \"none\",    \"messages_previous\": \"none\",    \"messages_copy\": \"<leader>y\",    \"messages_undo\": \"<leader>u\",    \"messages_redo\": \"<leader>r\",    \"messages_last_user\": \"none\",    \"messages_toggle_conceal\": \"<leader>h\",    \"model_list\": \"<leader>m\",    \"model_cycle_recent\": \"f2\",    \"model_cycle_recent_reverse\": \"shift+f2\",    \"model_cycle_favorite\": \"none\",    \"model_cycle_favorite_reverse\": \"none\",    \"variant_cycle\": \"ctrl+t\",    \"command_list\": \"ctrl+p\",    \"agent_list\": \"<leader>a\",    \"agent_cycle\": \"tab\",    \"agent_cycle_reverse\": \"shift+tab\",    \"input_clear\": \"ctrl+c\",    \"input_paste\": \"ctrl+v\",    \"input_submit\": \"return\",    \"input_newline\": \"shift+return,ctrl+return,alt+return,ctrl+j\",    \"input_move_left\": \"left,ctrl+b\",    \"input_move_right\": \"right,ctrl+f\",    \"input_move_up\": \"up\",    \"input_move_down\": \"down\",    \"input_select_left\": \"shift+left\",    \"input_select_right\": \"shift+right\",    \"input_select_up\": \"shift+up\",    \"input_select_down\": \"shift+down\",    \"input_line_home\": \"ctrl+a\",    \"input_line_end\": \"ctrl+e\",    \"input_select_line_home\": \"ctrl+shift+a\",    \"input_select_line_end\": \"ctrl+shift+e\",    \"input_visual_line_home\": \"alt+a\",    \"input_visual_line_end\": \"alt+e\",    \"input_select_visual_line_home\": \"alt+shift+a\",    \"input_select_visual_line_end\": \"alt+shift+e\",    \"input_buffer_home\": \"home\",    \"input_buffer_end\": \"end\",    \"input_select_buffer_home\": \"shift+home\",    \"input_select_buffer_end\": \"shift+end\",    \"input_delete_line\": \"ctrl+shift+d\",    \"input_delete_to_line_end\": \"ctrl+k\",    \"input_delete_to_line_start\": \"ctrl+u\",    \"input_backspace\": \"backspace,shift+backspace\",    \"input_delete\": \"ctrl+d,delete,shift+delete\",    \"input_undo\": \"ctrl+-,super+z\",    \"input_redo\": \"ctrl+.,super+shift+z\",    \"input_word_forward\": \"alt+f,alt+right,ctrl+right\",    \"input_word_backward\": \"alt+b,alt+left,ctrl+left\",    \"input_select_word_forward\": \"alt+shift+f,alt+shift+right\",    \"input_select_word_backward\": \"alt+shift+b,alt+shift+left\",    \"input_delete_word_forward\": \"alt+d,alt+delete,ctrl+delete\",    \"input_delete_word_backward\": \"ctrl+w,ctrl+backspace,alt+backspace\",    \"history_previous\": \"up\",    \"history_next\": \"down\",    \"terminal_suspend\": \"ctrl+z\",    \"terminal_title_toggle\": \"none\",    \"tips_toggle\": \"<leader>h\"  }}\n```\n\n## Leader key\n\nOpenCode uses a leader key for most keybinds. This avoids conflicts in your terminal.\n\nBy default, ctrl+x is the leader key and most actions require you to first press the leader key and then the shortcut. For example, to start a new session you first press ctrl+x and then press n.\n\nYou don’t need to use a leader key for your keybinds but we recommend doing so.\n\n## Disable keybind\n\nYou can disable a keybind by adding the key to your config with a value of “none”.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"keybinds\": {    \"session_compact\": \"none\"  }}\n```\n\n## Desktop prompt shortcuts\n\nThe OpenCode desktop app prompt input supports common Readline/Emacs-style shortcuts for editing text. These are built-in and currently not configurable via opencode.json.\n\n## Shift+Enter\n\nSome terminals don’t send modifier keys with Enter by default. You may need to configure your terminal to send Shift+Enter as an escape sequence.\n\n### Windows Terminal\n\nOpen your settings.json at:\n\n```\n%LOCALAPPDATA%\\Packages\\Microsoft.WindowsTerminal_8wekyb3d8bbwe\\LocalState\\settings.json\n```\n\nAdd this to the root-level actions array:\n\n```\n\"actions\": [  {    \"command\": {      \"action\": \"sendInput\",      \"input\": \"\\u001b[13;2u\"    },    \"id\": \"User.sendInput.ShiftEnterCustom\"  }]\n```\n\nAdd this to the root-level keybindings array:\n\n```\n\"keybindings\": [  {    \"keys\": \"shift+enter\",    \"id\": \"User.sendInput.ShiftEnterCustom\"  }]\n```\n\nSave the file and restart Windows Terminal or open a new tab.\n\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/keybinds.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "Keybinds",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "Leader key",
          "id": "leader-key"
        },
        {
          "level": 2,
          "text": "Disable keybind",
          "id": "disable-keybind"
        },
        {
          "level": 2,
          "text": "Desktop prompt shortcuts",
          "id": "desktop-prompt-shortcuts"
        },
        {
          "level": 2,
          "text": "Shift+Enter",
          "id": "shiftenter"
        },
        {
          "level": 3,
          "text": "Windows Terminal",
          "id": "windows-terminal"
        }
      ],
      "category": "Configure",
      "scrapedAt": 1768685273685
    },
    {
      "path": "/docs/commands/",
      "title": "Commands",
      "url": "https://opencode.ai/docs/commands/",
      "content": "# Commands\n\nCreate custom commands for repetitive tasks.\n\nCustom commands let you specify a prompt you want to run when that command is executed in the TUI.\n\n```\n/my-command\n```\n\nCustom commands are in addition to the built-in commands like /init, /undo, /redo, /share, /help. Learn more.\n\n## Create command files\n\nCreate markdown files in the command/ directory to define custom commands.\n\nCreate .opencode/command/test.md:\n\n```\n---description: Run tests with coverageagent: buildmodel: anthropic/claude-3-5-sonnet-20241022---\nRun the full test suite with coverage report and show any failures.Focus on the failing tests and suggest fixes.\n```\n\nThe frontmatter defines command properties. The content becomes the template.\n\nUse the command by typing / followed by the command name.\n\n```\n\"/test\"\n```\n\n## Configure\n\nYou can add custom commands through the OpenCode config or by creating markdown files in the command/ directory.\n\n### JSON\n\nUse the command option in your OpenCode config:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"command\": {    // This becomes the name of the command    \"test\": {      // This is the prompt that will be sent to the LLM      \"template\": \"Run the full test suite with coverage report and show any failures.\\nFocus on the failing tests and suggest fixes.\",      // This is shown as the description in the TUI      \"description\": \"Run tests with coverage\",      \"agent\": \"build\",      \"model\": \"anthropic/claude-3-5-sonnet-20241022\"    }  }}\n```\n\nNow you can run this command in the TUI:\n\n```\n/test\n```\n\n### Markdown\n\nYou can also define commands using markdown files. Place them in:\n\n- Global: ~/.config/opencode/command/\n- Per-project: .opencode/command/\n\n```\n---description: Run tests with coverageagent: buildmodel: anthropic/claude-3-5-sonnet-20241022---\nRun the full test suite with coverage report and show any failures.Focus on the failing tests and suggest fixes.\n```\n\nThe markdown file name becomes the command name. For example, test.md lets\nyou run:\n\n```\n/test\n```\n\n## Prompt config\n\nThe prompts for the custom commands support several special placeholders and syntax.\n\n### Arguments\n\nPass arguments to commands using the $ARGUMENTS placeholder.\n\n```\n---description: Create a new component---\nCreate a new React component named $ARGUMENTS with TypeScript support.Include proper typing and basic structure.\n```\n\nRun the command with arguments:\n\n```\n/component Button\n```\n\nAnd $ARGUMENTS will be replaced with Button.\n\nYou can also access individual arguments using positional parameters:\n\n- $1 - First argument\n- $2 - Second argument\n- $3 - Third argument\n- And so on…\nFor example:\n\n```\n---description: Create a new file with content---\nCreate a file named $1 in the directory $2with the following content: $3\n```\n\nRun the command:\n\n```\n/create-file config.json src \"{ \\\"key\\\": \\\"value\\\" }\"\n```\n\nThis replaces:\n\n- $1 with config.json\n- $2 with src\n- $3 with { \"key\": \"value\" }\n\n### Shell output\n\nUse !command to inject bash command output into your prompt.\n\nFor example, to create a custom command that analyzes test coverage:\n\n```\n---description: Analyze test coverage---\nHere are the current test results:!`npm test`\nBased on these results, suggest improvements to increase coverage.\n```\n\nOr to review recent changes:\n\n```\n---description: Review recent changes---\nRecent git commits:!`git log --oneline -10`\nReview these changes and suggest any improvements.\n```\n\nCommands run in your project’s root directory and their output becomes part of the prompt.\n\n### File references\n\nInclude files in your command using @ followed by the filename.\n\n```\n---description: Review component---\nReview the component in @src/components/Button.tsx.Check for performance issues and suggest improvements.\n```\n\nThe file content gets included in the prompt automatically.\n\n## Options\n\nLet’s look at the configuration options in detail.\n\n### Template\n\nThe template option defines the prompt that will be sent to the LLM when the command is executed.\n\n```\n{  \"command\": {    \"test\": {      \"template\": \"Run the full test suite with coverage report and show any failures.\\nFocus on the failing tests and suggest fixes.\"    }  }}\n```\n\nThis is a required config option.\n\n### Description\n\nUse the description option to provide a brief description of what the command does.\n\n```\n{  \"command\": {    \"test\": {      \"description\": \"Run tests with coverage\"    }  }}\n```\n\nThis is shown as the description in the TUI when you type in the command.\n\n### Agent\n\nUse the agent config to optionally specify which agent should execute this command.\nIf this is a subagent the command will trigger a subagent invocation by default.\nTo disable this behavior, set subtask to false.\n\n```\n{  \"command\": {    \"review\": {      \"agent\": \"plan\"    }  }}\n```\n\nThis is an optional config option. If not specified, defaults to your current agent.\n\n### Subtask\n\nUse the subtask boolean to force the command to trigger a subagent invocation.\nThis is useful if you want the command to not pollute your primary context and will force the agent to act as a subagent,\neven if mode is set to primary on the agent configuration.\n\n```\n{  \"command\": {    \"analyze\": {      \"subtask\": true    }  }}\n```\n\nThis is an optional config option.\n\n### Model\n\nUse the model config to override the default model for this command.\n\n```\n{  \"command\": {    \"analyze\": {      \"model\": \"anthropic/claude-3-5-sonnet-20241022\"    }  }}\n```\n\nThis is an optional config option.\n\n## Built-in\n\nopencode includes several built-in commands like /init, /undo, /redo, /share, /help; learn more.\n\nNote\n\nCustom commands can override built-in commands.\n\nIf you define a custom command with the same name, it will override the built-in command.\n\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/commands.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "Commands",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "Create command files",
          "id": "create-command-files"
        },
        {
          "level": 2,
          "text": "Configure",
          "id": "configure"
        },
        {
          "level": 3,
          "text": "JSON",
          "id": "json"
        },
        {
          "level": 3,
          "text": "Markdown",
          "id": "markdown"
        },
        {
          "level": 2,
          "text": "Prompt config",
          "id": "prompt-config"
        },
        {
          "level": 3,
          "text": "Arguments",
          "id": "arguments"
        },
        {
          "level": 3,
          "text": "Shell output",
          "id": "shell-output"
        },
        {
          "level": 3,
          "text": "File references",
          "id": "file-references"
        },
        {
          "level": 2,
          "text": "Options",
          "id": "options"
        },
        {
          "level": 3,
          "text": "Template",
          "id": "template"
        },
        {
          "level": 3,
          "text": "Description",
          "id": "description"
        },
        {
          "level": 3,
          "text": "Agent",
          "id": "agent"
        },
        {
          "level": 3,
          "text": "Subtask",
          "id": "subtask"
        },
        {
          "level": 3,
          "text": "Model",
          "id": "model"
        },
        {
          "level": 2,
          "text": "Built-in",
          "id": "built-in"
        }
      ],
      "category": "Configure",
      "scrapedAt": 1768685274034
    },
    {
      "path": "/docs/formatters/",
      "title": "Formatters",
      "url": "https://opencode.ai/docs/formatters/",
      "content": "# Formatters\n\nOpenCode uses language specific formatters.\n\nOpenCode automatically formats files after they are written or edited using language-specific formatters. This ensures that the code that is generated follows the code styles of your project.\n\n## Built-in\n\nOpenCode comes with several built-in formatters for popular languages and frameworks. Below is a list of the formatters, supported file extensions, and commands or config options it needs.\n\n[more](https://prettier.io/docs/en/index.html) [experimental env variable flag](/docs/cli/#experimental) So if your project has prettier in your package.json, OpenCode will automatically use it.\n\n## How it works\n\nWhen OpenCode writes or edits a file, it:\n\n- Checks the file extension against all enabled formatters.\n- Runs the appropriate formatter command on the file.\n- Applies the formatting changes automatically.\nThis process happens in the background, ensuring your code styles are maintained without any manual steps.\n\n## Configure\n\nYou can customize formatters through the formatter section in your OpenCode config.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"formatter\": {}}\n```\n\nEach formatter configuration supports the following:\n\nLet’s look at some examples.\n\n### Disabling formatters\n\nTo disable all formatters globally, set formatter to false:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"formatter\": false}\n```\n\nTo disable a specific formatter, set disabled to true:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"formatter\": {    \"prettier\": {      \"disabled\": true    }  }}\n```\n\n### Custom formatters\n\nYou can override the built-in formatters or add new ones by specifying the command, environment variables, and file extensions:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"formatter\": {    \"prettier\": {      \"command\": [\"npx\", \"prettier\", \"--write\", \"$FILE\"],      \"environment\": {        \"NODE_ENV\": \"development\"      },      \"extensions\": [\".js\", \".ts\", \".jsx\", \".tsx\"]    },    \"custom-markdown-formatter\": {      \"command\": [\"deno\", \"fmt\", \"$FILE\"],      \"extensions\": [\".md\"]    }  }}\n```\n\nThe $FILE placeholder in the command will be replaced with the path to the file being formatted.\n\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/formatters.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "Formatters",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "Built-in",
          "id": "built-in"
        },
        {
          "level": 2,
          "text": "How it works",
          "id": "how-it-works"
        },
        {
          "level": 2,
          "text": "Configure",
          "id": "configure"
        },
        {
          "level": 3,
          "text": "Disabling formatters",
          "id": "disabling-formatters"
        },
        {
          "level": 3,
          "text": "Custom formatters",
          "id": "custom-formatters"
        }
      ],
      "category": "Configure",
      "scrapedAt": 1768685274389
    },
    {
      "path": "/docs/permissions/",
      "title": "Permissions",
      "url": "https://opencode.ai/docs/permissions/",
      "content": "# Permissions\n\nControl which actions require approval to run.\n\nOpenCode uses the permission config to decide whether a given action should run automatically, prompt you, or be blocked.\n\nAs of v1.1.1, the legacy tools boolean config is deprecated and has been merged into permission. The old tools config is still supported for backwards compatibility.\n\n## Actions\n\nEach permission rule resolves to one of:\n\n- \"allow\" — run without approval\n- \"ask\" — prompt for approval\n- \"deny\" — block the action\n\n## Configuration\n\nYou can set permissions globally (with *), and override specific tools.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"permission\": {    \"*\": \"ask\",    \"bash\": \"allow\",    \"edit\": \"deny\"  }}\n```\n\nYou can also set all permissions at once:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"permission\": \"allow\"}\n```\n\n## Granular Rules (Object Syntax)\n\nFor most permissions, you can use an object to apply different actions based on the tool input.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"permission\": {    \"bash\": {      \"*\": \"ask\",      \"git *\": \"allow\",      \"npm *\": \"allow\",      \"rm *\": \"deny\",      \"grep *\": \"allow\"    },    \"edit\": {      \"*\": \"deny\",      \"packages/web/src/content/docs/*.mdx\": \"allow\"    }  }}\n```\n\nRules are evaluated by pattern match, with the last matching rule winning. A common pattern is to put the catch-all \"*\" rule first, and more specific rules after it.\n\n### Wildcards\n\nPermission patterns use simple wildcard matching:\n\n- * matches zero or more of any character\n- ? matches exactly one character\n- All other characters match literally\n\n## Available Permissions\n\nOpenCode permissions are keyed by tool name, plus a couple of safety guards:\n\n- read — reading a file (matches the file path)\n- edit — all file modifications (covers edit, write, patch, multiedit)\n- glob — file globbing (matches the glob pattern)\n- grep — content search (matches the regex pattern)\n- list — listing files in a directory (matches the directory path)\n- bash — running shell commands (matches parsed commands like git status --porcelain)\n- task — launching subagents (matches the subagent type)\n- skill — loading a skill (matches the skill name)\n- lsp — running LSP queries (currently non-granular)\n- todoread, todowrite — reading/updating the todo list\n- webfetch — fetching a URL (matches the URL)\n- websearch, codesearch — web/code search (matches the query)\n- external_directory — triggered when a tool touches paths outside the project working directory\n- doom_loop — triggered when the same tool call repeats 3 times with identical input\n\n## Defaults\n\nIf you don’t specify anything, OpenCode starts from permissive defaults:\n\n- Most permissions default to \"allow\".\n- doom_loop and external_directory default to \"ask\".\n- read is \"allow\", but .env files are denied by default:\n\n```\n{  \"permission\": {    \"read\": {      \"*\": \"allow\",      \"*.env\": \"deny\",      \"*.env.*\": \"deny\",      \"*.env.example\": \"allow\"    }  }}\n```\n\n## What “Ask” Does\n\nWhen OpenCode prompts for approval, the UI offers three outcomes:\n\n- once — approve just this request\n- always — approve future requests matching the suggested patterns (for the rest of the current OpenCode session)\n- reject — deny the request\nThe set of patterns that always would approve is provided by the tool (for example, bash approvals typically whitelist a safe command prefix like git status*).\n\n## Agents\n\nYou can override permissions per agent. Agent permissions are merged with the global config, and agent rules take precedence. Learn more about agent permissions.\n\nNote\n\nRefer to the Granular Rules (Object Syntax) section above for more detailed pattern matching examples.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"permission\": {    \"bash\": {      \"*\": \"ask\",      \"git *\": \"allow\",      \"git commit *\": \"deny\",      \"git push *\": \"deny\",      \"grep *\": \"allow\"    }  },  \"agent\": {    \"build\": {      \"permission\": {        \"bash\": {          \"*\": \"ask\",          \"git *\": \"allow\",          \"git commit *\": \"ask\",          \"git push *\": \"deny\",          \"grep *\": \"allow\"        }      }    }  }}\n```\n\nYou can also configure agent permissions in Markdown:\n\n```\n---description: Code review without editsmode: subagentpermission:  edit: deny  bash: ask  webfetch: deny---\nOnly analyze code and suggest changes.\n```\n\nTip\n\nUse pattern matching for commands with arguments. \"grep *\" allows grep pattern file.txt, while \"grep\" alone would block it. Commands like git status work for default behavior but require explicit permission (like \"git status *\") when arguments are passed.\n\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/permissions.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "Permissions",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "Actions",
          "id": "actions"
        },
        {
          "level": 2,
          "text": "Configuration",
          "id": "configuration"
        },
        {
          "level": 2,
          "text": "Granular Rules (Object Syntax)",
          "id": "granular-rules-object-syntax"
        },
        {
          "level": 3,
          "text": "Wildcards",
          "id": "wildcards"
        },
        {
          "level": 2,
          "text": "Available Permissions",
          "id": "available-permissions"
        },
        {
          "level": 2,
          "text": "Defaults",
          "id": "defaults"
        },
        {
          "level": 2,
          "text": "What “Ask” Does",
          "id": "what-ask-does"
        },
        {
          "level": 2,
          "text": "Agents",
          "id": "agents"
        }
      ],
      "category": "Configure",
      "scrapedAt": 1768685274739
    },
    {
      "path": "/docs/lsp/",
      "title": "LSP Servers",
      "url": "https://opencode.ai/docs/lsp/",
      "content": "# LSP Servers\n\nOpenCode integrates with your LSP servers.\n\nOpenCode integrates with your Language Server Protocol (LSP) to help the LLM interact with your codebase. It uses diagnostics to provide feedback to the LLM.\n\n## Built-in\n\nOpenCode comes with several built-in LSP servers for popular languages:\n\nLSP servers are automatically enabled when one of the above file extensions are detected and the requirements are met.\n\nNote\n\nYou can disable automatic LSP server downloads by setting the OPENCODE_DISABLE_LSP_DOWNLOAD environment variable to true.\n\n## How It Works\n\nWhen opencode opens a file, it:\n\n- Checks the file extension against all enabled LSP servers.\n- Starts the appropriate LSP server if not already running.\n\n## Configure\n\nYou can customize LSP servers through the lsp section in your opencode config.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"lsp\": {}}\n```\n\nEach LSP server supports the following:\n\nLet’s look at some examples.\n\n### Disabling LSP servers\n\nTo disable all LSP servers globally, set lsp to false:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"lsp\": false}\n```\n\nTo disable a specific LSP server, set disabled to true:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"lsp\": {    \"typescript\": {      \"disabled\": true    }  }}\n```\n\n### Custom LSP servers\n\nYou can add custom LSP servers by specifying the command and file extensions:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"lsp\": {    \"custom-lsp\": {      \"command\": [\"custom-lsp-server\", \"--stdio\"],      \"extensions\": [\".custom\"]    }  }}\n```\n\n## Additional Information\n\n### PHP Intelephense\n\nPHP Intelephense offers premium features through a license key. You can provide a license key by placing (only) the key in a text file at:\n\n- On macOS/Linux: $HOME/intelephense/licence.txt\n- On Windows: %USERPROFILE%/intelephense/licence.txt\nThe file should contain only the license key with no additional content.\n\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/lsp.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "LSP Servers",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "Built-in",
          "id": "built-in"
        },
        {
          "level": 2,
          "text": "How It Works",
          "id": "how-it-works"
        },
        {
          "level": 2,
          "text": "Configure",
          "id": "configure"
        },
        {
          "level": 3,
          "text": "Disabling LSP servers",
          "id": "disabling-lsp-servers"
        },
        {
          "level": 3,
          "text": "Custom LSP servers",
          "id": "custom-lsp-servers"
        },
        {
          "level": 2,
          "text": "Additional Information",
          "id": "additional-information"
        },
        {
          "level": 3,
          "text": "PHP Intelephense",
          "id": "php-intelephense"
        }
      ],
      "category": "Configure",
      "scrapedAt": 1768685275088
    },
    {
      "path": "/docs/mcp-servers/",
      "title": "MCP servers",
      "url": "https://opencode.ai/docs/mcp-servers/",
      "content": "# MCP servers\n\nAdd local and remote MCP tools.\n\nYou can add external tools to OpenCode using the Model Context Protocol, or MCP. OpenCode supports both local and remote servers.\n\nOnce added, MCP tools are automatically available to the LLM alongside built-in tools.\n\n#### Caveats\n\nWhen you use an MCP server, it adds to the context. This can quickly add up if you have a lot of tools. So we recommend being careful with which MCP servers you use.\n\nTip\n\nMCP servers add to your context, so you want to be careful with which ones you enable.\n\nCertain MCP servers, like the GitHub MCP server, tend to add a lot of tokens and can easily exceed the context limit.\n\n## Enable\n\nYou can define MCP servers in your OpenCode Config under mcp. Add each MCP with a unique name. You can refer to that MCP by name when prompting the LLM.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"mcp\": {    \"name-of-mcp-server\": {      // ...      \"enabled\": true,    },    \"name-of-other-mcp-server\": {      // ...    },  },}\n```\n\nYou can also disable a server by setting enabled to false. This is useful if you want to temporarily disable a server without removing it from your config.\n\n### Overriding remote defaults\n\nOrganizations can provide default MCP servers via their .well-known/opencode endpoint. These servers may be disabled by default, allowing users to opt-in to the ones they need.\n\nTo enable a specific server from your organization’s remote config, add it to your local config with enabled: true:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"mcp\": {    \"jira\": {      \"type\": \"remote\",      \"url\": \"https://jira.example.com/mcp\",      \"enabled\": true    }  }}\n```\n\nYour local config values override the remote defaults. See config precedence for more details.\n\n## Local\n\nAdd local MCP servers using type to \"local\" within the MCP object.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"mcp\": {    \"my-local-mcp-server\": {      \"type\": \"local\",      // Or [\"bun\", \"x\", \"my-mcp-command\"]      \"command\": [\"npx\", \"-y\", \"my-mcp-command\"],      \"enabled\": true,      \"environment\": {        \"MY_ENV_VAR\": \"my_env_var_value\",      },    },  },}\n```\n\nThe command is how the local MCP server is started. You can also pass in a list of environment variables as well.\n\nFor example, here’s how you can add the test @modelcontextprotocol/server-everything MCP server.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"mcp\": {    \"mcp_everything\": {      \"type\": \"local\",      \"command\": [\"npx\", \"-y\", \"@modelcontextprotocol/server-everything\"],    },  },}\n```\n\nAnd to use it I can add use the mcp_everything tool to my prompts.\n\n```\nuse the mcp_everything tool to add the number 3 and 4\n```\n\n#### Options\n\nHere are all the options for configuring a local MCP server.\n\n## Remote\n\nAdd remote MCP servers by setting type to \"remote\".\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"mcp\": {    \"my-remote-mcp\": {      \"type\": \"remote\",      \"url\": \"https://my-mcp-server.com\",      \"enabled\": true,      \"headers\": {        \"Authorization\": \"Bearer MY_API_KEY\"      }    }  }}\n```\n\nThe url is the URL of the remote MCP server and with the headers option you can pass in a list of headers.\n\n#### Options\n\n[OAuth](#oauth) \n## OAuth\n\nOpenCode automatically handles OAuth authentication for remote MCP servers. When a server requires authentication, OpenCode will:\n\n- Detect the 401 response and initiate the OAuth flow\n- Use Dynamic Client Registration (RFC 7591) if supported by the server\n- Store tokens securely for future requests\n\n### Automatic\n\nFor most OAuth-enabled MCP servers, no special configuration is needed. Just configure the remote server:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"mcp\": {    \"my-oauth-server\": {      \"type\": \"remote\",      \"url\": \"https://mcp.example.com/mcp\"    }  }}\n```\n\nIf the server requires authentication, OpenCode will prompt you to authenticate when you first try to use it. If not, you can manually trigger the flow with opencode mcp auth <server-name>.\n\n### Pre-registered\n\nIf you have client credentials from the MCP server provider, you can configure them:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"mcp\": {    \"my-oauth-server\": {      \"type\": \"remote\",      \"url\": \"https://mcp.example.com/mcp\",      \"oauth\": {        \"clientId\": \"{env:MY_MCP_CLIENT_ID}\",        \"clientSecret\": \"{env:MY_MCP_CLIENT_SECRET}\",        \"scope\": \"tools:read tools:execute\"      }    }  }}\n```\n\n### Authenticating\n\nYou can manually trigger authentication or manage credentials.\n\nAuthenticate with a specific MCP server:\n\n```\nopencode mcp auth my-oauth-server\n```\n\nList all MCP servers and their auth status:\n\n```\nopencode mcp list\n```\n\nRemove stored credentials:\n\n```\nopencode mcp logout my-oauth-server\n```\n\nThe mcp auth command will open your browser for authorization. After you authorize, OpenCode will store the tokens securely in ~/.local/share/opencode/mcp-auth.json.\n\n#### Disabling OAuth\n\nIf you want to disable automatic OAuth for a server (e.g., for servers that use API keys instead), set oauth to false:\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"mcp\": {    \"my-api-key-server\": {      \"type\": \"remote\",      \"url\": \"https://mcp.example.com/mcp\",      \"oauth\": false,      \"headers\": {        \"Authorization\": \"Bearer {env:MY_API_KEY}\"      }    }  }}\n```\n\n#### OAuth Options\n\n#### Debugging\n\nIf a remote MCP server is failing to authenticate, you can diagnose issues with:\n\n```\n# View auth status for all OAuth-capable serversopencode mcp auth list\n# Debug connection and OAuth flow for a specific serveropencode mcp debug my-oauth-server\n```\n\nThe mcp debug command shows the current auth status, tests HTTP connectivity, and attempts the OAuth discovery flow.\n\n## Manage\n\nYour MCPs are available as tools in OpenCode, alongside built-in tools. So you can manage them through the OpenCode config like any other tool.\n\n### Global\n\nThis means that you can enable or disable them globally.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"mcp\": {    \"my-mcp-foo\": {      \"type\": \"local\",      \"command\": [\"bun\", \"x\", \"my-mcp-command-foo\"]    },    \"my-mcp-bar\": {      \"type\": \"local\",      \"command\": [\"bun\", \"x\", \"my-mcp-command-bar\"]    }  },  \"tools\": {    \"my-mcp-foo\": false  }}\n```\n\nWe can also use a glob pattern to disable all matching MCPs.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"mcp\": {    \"my-mcp-foo\": {      \"type\": \"local\",      \"command\": [\"bun\", \"x\", \"my-mcp-command-foo\"]    },    \"my-mcp-bar\": {      \"type\": \"local\",      \"command\": [\"bun\", \"x\", \"my-mcp-command-bar\"]    }  },  \"tools\": {    \"my-mcp*\": false  }}\n```\n\nHere we are using the glob pattern my-mcp* to disable all MCPs.\n\n### Per agent\n\nIf you have a large number of MCP servers you may want to only enable them per agent and disable them globally. To do this:\n\n- Disable it as a tool globally.\n- In your agent config, enable the MCP server as a tool.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"mcp\": {    \"my-mcp\": {      \"type\": \"local\",      \"command\": [\"bun\", \"x\", \"my-mcp-command\"],      \"enabled\": true    }  },  \"tools\": {    \"my-mcp*\": false  },  \"agent\": {    \"my-agent\": {      \"tools\": {        \"my-mcp*\": true      }    }  }}\n```\n\n#### Glob patterns\n\nThe glob pattern uses simple regex globbing patterns:\n\n- * matches zero or more of any character (e.g., \"my-mcp*\" matches my-mcp_search, my-mcp_list, etc.)\n- ? matches exactly one character\n- All other characters match literally\nNote\n\nMCP server tools are registered with server name as prefix, so to disable all tools for a server simply use:\n\n```\n\"mymcpservername_*\": false\n```\n\n## Examples\n\nBelow are examples of some common MCP servers. You can submit a PR if you want to document other servers.\n\n### Sentry\n\nAdd the Sentry MCP server to interact with your Sentry projects and issues.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"mcp\": {    \"sentry\": {      \"type\": \"remote\",      \"url\": \"https://mcp.sentry.dev/mcp\",      \"oauth\": {}    }  }}\n```\n\nAfter adding the configuration, authenticate with Sentry:\n\n```\nopencode mcp auth sentry\n```\n\nThis will open a browser window to complete the OAuth flow and connect OpenCode to your Sentry account.\n\nOnce authenticated, you can use Sentry tools in your prompts to query issues, projects, and error data.\n\n```\nShow me the latest unresolved issues in my project. use sentry\n```\n\n### Context7\n\nAdd the Context7 MCP server to search through docs.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"mcp\": {    \"context7\": {      \"type\": \"remote\",      \"url\": \"https://mcp.context7.com/mcp\"    }  }}\n```\n\nIf you have signed up for a free account, you can use your API key and get higher rate-limits.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"mcp\": {    \"context7\": {      \"type\": \"remote\",      \"url\": \"https://mcp.context7.com/mcp\",      \"headers\": {        \"CONTEXT7_API_KEY\": \"{env:CONTEXT7_API_KEY}\"      }    }  }}\n```\n\nHere we are assuming that you have the CONTEXT7_API_KEY environment variable set.\n\nAdd use context7 to your prompts to use Context7 MCP server.\n\n```\nConfigure a Cloudflare Worker script to cache JSON API responses for five minutes. use context7\n```\n\nAlternatively, you can add something like this to your AGENTS.md.\n\n```\nWhen you need to search docs, use `context7` tools.\n```\n\n### Grep by Vercel\n\nAdd the Grep by Vercel MCP server to search through code snippets on GitHub.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"mcp\": {    \"gh_grep\": {      \"type\": \"remote\",      \"url\": \"https://mcp.grep.app\"    }  }}\n```\n\nSince we named our MCP server gh_grep, you can add use the gh_grep tool to your prompts to get the agent to use it.\n\n```\nWhat's the right way to set a custom domain in an SST Astro component? use the gh_grep tool\n```\n\nAlternatively, you can add something like this to your AGENTS.md.\n\n```\nIf you are unsure how to do something, use `gh_grep` to search code examples from GitHub.\n```\n\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/mcp-servers.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "MCP servers",
          "id": "_top"
        },
        {
          "level": 4,
          "text": "Caveats",
          "id": "caveats"
        },
        {
          "level": 2,
          "text": "Enable",
          "id": "enable"
        },
        {
          "level": 3,
          "text": "Overriding remote defaults",
          "id": "overriding-remote-defaults"
        },
        {
          "level": 2,
          "text": "Local",
          "id": "local"
        },
        {
          "level": 4,
          "text": "Options",
          "id": "options"
        },
        {
          "level": 2,
          "text": "Remote",
          "id": "remote"
        },
        {
          "level": 4,
          "text": "Options",
          "id": "options-1"
        },
        {
          "level": 2,
          "text": "OAuth",
          "id": "oauth"
        },
        {
          "level": 3,
          "text": "Automatic",
          "id": "automatic"
        },
        {
          "level": 3,
          "text": "Pre-registered",
          "id": "pre-registered"
        },
        {
          "level": 3,
          "text": "Authenticating",
          "id": "authenticating"
        },
        {
          "level": 4,
          "text": "Disabling OAuth",
          "id": "disabling-oauth"
        },
        {
          "level": 4,
          "text": "OAuth Options",
          "id": "oauth-options"
        },
        {
          "level": 4,
          "text": "Debugging",
          "id": "debugging"
        },
        {
          "level": 2,
          "text": "Manage",
          "id": "manage"
        },
        {
          "level": 3,
          "text": "Global",
          "id": "global"
        },
        {
          "level": 3,
          "text": "Per agent",
          "id": "per-agent"
        },
        {
          "level": 4,
          "text": "Glob patterns",
          "id": "glob-patterns"
        },
        {
          "level": 2,
          "text": "Examples",
          "id": "examples"
        },
        {
          "level": 3,
          "text": "Sentry",
          "id": "sentry"
        },
        {
          "level": 3,
          "text": "Context7",
          "id": "context7"
        },
        {
          "level": 3,
          "text": "Grep by Vercel",
          "id": "grep-by-vercel"
        }
      ],
      "category": "Configure",
      "scrapedAt": 1768685275445
    },
    {
      "path": "/docs/acp/",
      "title": "ACP Support",
      "url": "https://opencode.ai/docs/acp/",
      "content": "# ACP Support\n\nUse OpenCode in any ACP-compatible editor.\n\nOpenCode supports the Agent Client Protocol or (ACP), allowing you to use it directly in compatible editors and IDEs.\n\nTip\n\nFor a list of editors and tools that support ACP, check out the ACP progress report.\n\nACP is an open protocol that standardizes communication between code editors and AI coding agents.\n\n## Configure\n\nTo use OpenCode via ACP, configure your editor to run the opencode acp command.\n\nThe command starts OpenCode as an ACP-compatible subprocess that communicates with your editor over JSON-RPC via stdio.\n\nBelow are examples for popular editors that support ACP.\n\n### Zed\n\nAdd to your Zed configuration (~/.config/zed/settings.json):\n\n```\n{  \"agent_servers\": {    \"OpenCode\": {      \"command\": \"opencode\",      \"args\": [\"acp\"]    }  }}\n```\n\nTo open it, use the agent: new thread action in the Command Palette.\n\nYou can also bind a keyboard shortcut by editing your keymap.json:\n\n```\n[  {    \"bindings\": {      \"cmd-alt-o\": [        \"agent::NewExternalAgentThread\",        {          \"agent\": {            \"custom\": {              \"name\": \"OpenCode\",              \"command\": {                \"command\": \"opencode\",                \"args\": [\"acp\"]              }            }          }        }      ]    }  }]\n```\n\n### JetBrains IDEs\n\nAdd to your JetBrains IDE acp.json according to the documentation:\n\n```\n{  \"agent_servers\": {    \"OpenCode\": {      \"command\": \"/absolute/path/bin/opencode\",      \"args\": [\"acp\"]    }  }}\n```\n\nTo open it, use the new ‘OpenCode’ agent in the AI Chat agent selector.\n\n### Avante.nvim\n\nAdd to your Avante.nvim configuration:\n\n```\n{  acp_providers = {    [\"opencode\"] = {      command = \"opencode\",      args = { \"acp\" }    }  }}\n```\n\nIf you need to pass environment variables:\n\n```\n{  acp_providers = {    [\"opencode\"] = {      command = \"opencode\",      args = { \"acp\" },      env = {        OPENCODE_API_KEY = os.getenv(\"OPENCODE_API_KEY\")      }    }  }}\n```\n\n### CodeCompanion.nvim\n\nTo use OpenCode as an ACP agent in CodeCompanion.nvim, add the following to your Neovim config:\n\n```\nrequire(\"codecompanion\").setup({  strategies = {    chat = {      adapter = {        name = \"opencode\",        model = \"claude-sonnet-4\",      },    },  },})\n```\n\nThis config sets up CodeCompanion to use OpenCode as the ACP agent for chat.\n\nIf you need to pass environment variables (like OPENCODE_API_KEY), refer to Configuring Adapters: Environment Variables in the CodeCompanion.nvim documentation for full details.\n\n## Support\n\nOpenCode works the same via ACP as it does in the terminal. All features are supported:\n\nNote\n\nSome built-in slash commands like /undo and /redo are currently unsupported.\n\n- Built-in tools (file operations, terminal commands, etc.)\n- Custom tools and slash commands\n- MCP servers configured in your OpenCode config\n- Project-specific rules from AGENTS.md\n- Custom formatters and linters\n- Agents and permissions system\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/acp.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "ACP Support",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "Configure",
          "id": "configure"
        },
        {
          "level": 3,
          "text": "Zed",
          "id": "zed"
        },
        {
          "level": 3,
          "text": "JetBrains IDEs",
          "id": "jetbrains-ides"
        },
        {
          "level": 3,
          "text": "Avante.nvim",
          "id": "avantenvim"
        },
        {
          "level": 3,
          "text": "CodeCompanion.nvim",
          "id": "codecompanionnvim"
        },
        {
          "level": 2,
          "text": "Support",
          "id": "support"
        }
      ],
      "category": "Configure",
      "scrapedAt": 1768685275798
    },
    {
      "path": "/docs/skills/",
      "title": "Agent Skills",
      "url": "https://opencode.ai/docs/skills/",
      "content": "# Agent Skills\n\nDefine reusable behavior via SKILL.md definitions\n\nAgent skills let OpenCode discover reusable instructions from your repo or home directory.\nSkills are loaded on-demand via the native skill tool—agents see available skills and can load the full content when needed.\n\n## Place files\n\nCreate one folder per skill name and put a SKILL.md inside it.\nOpenCode searches these locations:\n\n- Project config: .opencode/skill/<name>/SKILL.md\n- Global config: ~/.config/opencode/skill/<name>/SKILL.md\n- Project Claude-compatible: .claude/skills/<name>/SKILL.md\n- Global Claude-compatible: ~/.claude/skills/<name>/SKILL.md\n\n## Understand discovery\n\nFor project-local paths, OpenCode walks up from your current working directory until it reaches the git worktree.\nIt loads any matching skill/*/SKILL.md in .opencode/ and any matching .claude/skills/*/SKILL.md along the way.\n\nGlobal definitions are also loaded from ~/.config/opencode/skill/*/SKILL.md and ~/.claude/skills/*/SKILL.md.\n\n## Write frontmatter\n\nEach SKILL.md must start with YAML frontmatter.\nOnly these fields are recognized:\n\n- name (required)\n- description (required)\n- license (optional)\n- compatibility (optional)\n- metadata (optional, string-to-string map)\nUnknown frontmatter fields are ignored.\n\n## Validate names\n\nname must:\n\n- Be 1–64 characters\n- Be lowercase alphanumeric with single hyphen separators\n- Not start or end with -\n- Not contain consecutive --\n- Match the directory name that contains SKILL.md\nEquivalent regex:\n\n```\n^[a-z0-9]+(-[a-z0-9]+)*$\n```\n\n## Follow length rules\n\ndescription must be 1-1024 characters.\nKeep it specific enough for the agent to choose correctly.\n\n## Use an example\n\nCreate .opencode/skill/git-release/SKILL.md like this:\n\n```\n---name: git-releasedescription: Create consistent releases and changelogslicense: MITcompatibility: opencodemetadata:  audience: maintainers  workflow: github---\n## What I do\n- Draft release notes from merged PRs- Propose a version bump- Provide a copy-pasteable `gh release create` command\n## When to use me\nUse this when you are preparing a tagged release.Ask clarifying questions if the target versioning scheme is unclear.\n```\n\n## Recognize tool description\n\nOpenCode lists available skills in the skill tool description.\nEach entry includes the skill name and description:\n\n```\n<available_skills>  <skill>    <name>git-release</name>    <description>Create consistent releases and changelogs</description>  </skill></available_skills>\n```\n\nThe agent loads a skill by calling the tool:\n\n```\nskill({ name: \"git-release\" })\n```\n\n## Configure permissions\n\nControl which skills agents can access using pattern-based permissions in opencode.json:\n\n```\n{  \"permission\": {    \"skill\": {      \"*\": \"allow\",      \"pr-review\": \"allow\",      \"internal-*\": \"deny\",      \"experimental-*\": \"ask\"    }  }}\n```\n\nPatterns support wildcards: internal-* matches internal-docs, internal-tools, etc.\n\n## Override per agent\n\nGive specific agents different permissions than the global defaults.\n\nFor custom agents (in agent frontmatter):\n\n```\n---permission:  skill:    \"documents-*\": \"allow\"---\n```\n\nFor built-in agents (in opencode.json):\n\n```\n{  \"agent\": {    \"plan\": {      \"permission\": {        \"skill\": {          \"internal-*\": \"allow\"        }      }    }  }}\n```\n\n## Disable the skill tool\n\nCompletely disable skills for agents that shouldn’t use them:\n\nFor custom agents:\n\n```\n---tools:  skill: false---\n```\n\nFor built-in agents:\n\n```\n{  \"agent\": {    \"plan\": {      \"tools\": {        \"skill\": false      }    }  }}\n```\n\nWhen disabled, the <available_skills> section is omitted entirely.\n\n## Troubleshoot loading\n\nIf a skill does not show up:\n\n- Verify SKILL.md is spelled in all caps\n- Check that frontmatter includes name and description\n- Ensure skill names are unique across all locations\n- Check permissions—skills with deny are hidden from agents\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/skills.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "Agent Skills",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "Place files",
          "id": "place-files"
        },
        {
          "level": 2,
          "text": "Understand discovery",
          "id": "understand-discovery"
        },
        {
          "level": 2,
          "text": "Write frontmatter",
          "id": "write-frontmatter"
        },
        {
          "level": 2,
          "text": "Validate names",
          "id": "validate-names"
        },
        {
          "level": 2,
          "text": "Follow length rules",
          "id": "follow-length-rules"
        },
        {
          "level": 2,
          "text": "Use an example",
          "id": "use-an-example"
        },
        {
          "level": 2,
          "text": "Recognize tool description",
          "id": "recognize-tool-description"
        },
        {
          "level": 2,
          "text": "Configure permissions",
          "id": "configure-permissions"
        },
        {
          "level": 2,
          "text": "Override per agent",
          "id": "override-per-agent"
        },
        {
          "level": 2,
          "text": "Disable the skill tool",
          "id": "disable-the-skill-tool"
        },
        {
          "level": 2,
          "text": "Troubleshoot loading",
          "id": "troubleshoot-loading"
        }
      ],
      "category": "Configure",
      "scrapedAt": 1768685276155
    },
    {
      "path": "/docs/custom-tools/",
      "title": "Custom Tools",
      "url": "https://opencode.ai/docs/custom-tools/",
      "content": "# Custom Tools\n\nCreate tools the LLM can call in opencode.\n\nCustom tools are functions you create that the LLM can call during conversations. They work alongside opencode’s built-in tools like read, write, and bash.\n\n## Creating a tool\n\nTools are defined as TypeScript or JavaScript files. However, the tool definition can invoke scripts written in any language — TypeScript or JavaScript is only used for the tool definition itself.\n\n### Location\n\nThey can be defined:\n\n- Locally by placing them in the .opencode/tool/ directory of your project.\n- Or globally, by placing them in ~/.config/opencode/tool/.\n\n### Structure\n\nThe easiest way to create tools is using the tool() helper which provides type-safety and validation.\n\n```\nimport { tool } from \"@opencode-ai/plugin\"\nexport default tool({  description: \"Query the project database\",  args: {    query: tool.schema.string().describe(\"SQL query to execute\"),  },  async execute(args) {    // Your database logic here    return `Executed query: ${args.query}`  },})\n```\n\nThe filename becomes the tool name. The above creates a database tool.\n\n#### Multiple tools per file\n\nYou can also export multiple tools from a single file. Each export becomes a separate tool with the name <filename>_<exportname>:\n\n```\nimport { tool } from \"@opencode-ai/plugin\"\nexport const add = tool({  description: \"Add two numbers\",  args: {    a: tool.schema.number().describe(\"First number\"),    b: tool.schema.number().describe(\"Second number\"),  },  async execute(args) {    return args.a + args.b  },})\nexport const multiply = tool({  description: \"Multiply two numbers\",  args: {    a: tool.schema.number().describe(\"First number\"),    b: tool.schema.number().describe(\"Second number\"),  },  async execute(args) {    return args.a * args.b  },})\n```\n\nThis creates two tools: math_add and math_multiply.\n\n### Arguments\n\nYou can use tool.schema, which is just Zod, to define argument types.\n\n```\nargs: {  query: tool.schema.string().describe(\"SQL query to execute\")}\n```\n\nYou can also import Zod directly and return a plain object:\n\n```\nimport { z } from \"zod\"\nexport default {  description: \"Tool description\",  args: {    param: z.string().describe(\"Parameter description\"),  },  async execute(args, context) {    // Tool implementation    return \"result\"  },}\n```\n\n### Context\n\nTools receive context about the current session:\n\n```\nimport { tool } from \"@opencode-ai/plugin\"\nexport default tool({  description: \"Get project information\",  args: {},  async execute(args, context) {    // Access context information    const { agent, sessionID, messageID } = context    return `Agent: ${agent}, Session: ${sessionID}, Message: ${messageID}`  },})\n```\n\n## Examples\n\n### Write a tool in Python\n\nYou can write your tools in any language you want. Here’s an example that adds two numbers using Python.\n\nFirst, create the tool as a Python script:\n\n```\nimport sys\na = int(sys.argv[1])b = int(sys.argv[2])print(a + b)\n```\n\nThen create the tool definition that invokes it:\n\n```\nimport { tool } from \"@opencode-ai/plugin\"\nexport default tool({  description: \"Add two numbers using Python\",  args: {    a: tool.schema.number().describe(\"First number\"),    b: tool.schema.number().describe(\"Second number\"),  },  async execute(args) {    const result = await Bun.$`python3 .opencode/tool/add.py ${args.a} ${args.b}`.text()    return result.trim()  },})\n```\n\nHere we are using the Bun.$ utility to run the Python script.\n\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/custom-tools.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "Custom Tools",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "Creating a tool",
          "id": "creating-a-tool"
        },
        {
          "level": 3,
          "text": "Location",
          "id": "location"
        },
        {
          "level": 3,
          "text": "Structure",
          "id": "structure"
        },
        {
          "level": 4,
          "text": "Multiple tools per file",
          "id": "multiple-tools-per-file"
        },
        {
          "level": 3,
          "text": "Arguments",
          "id": "arguments"
        },
        {
          "level": 3,
          "text": "Context",
          "id": "context"
        },
        {
          "level": 2,
          "text": "Examples",
          "id": "examples"
        },
        {
          "level": 3,
          "text": "Write a tool in Python",
          "id": "write-a-tool-in-python"
        }
      ],
      "category": "Configure",
      "scrapedAt": 1768685276504
    },
    {
      "path": "/docs/sdk/",
      "title": "SDK",
      "url": "https://opencode.ai/docs/sdk/",
      "content": "# SDK\n\nType-safe JS client for opencode server.\n\nThe opencode JS/TS SDK provides a type-safe client for interacting with the server.\nUse it to build integrations and control opencode programmatically.\n\nLearn more about how the server works. For examples, check out the projects built by the community.\n\n## Install\n\nInstall the SDK from npm:\n\n```\nnpm install @opencode-ai/sdk\n```\n\n## Create client\n\nCreate an instance of opencode:\n\n```\nimport { createOpencode } from \"@opencode-ai/sdk\"\nconst { client } = await createOpencode()\n```\n\nThis starts both a server and a client\n\n#### Options\n\n## Config\n\nYou can pass a configuration object to customize behavior. The instance still picks up your opencode.json, but you can override or add configuration inline:\n\n```\nimport { createOpencode } from \"@opencode-ai/sdk\"\nconst opencode = await createOpencode({  hostname: \"127.0.0.1\",  port: 4096,  config: {    model: \"anthropic/claude-3-5-sonnet-20241022\",  },})\nconsole.log(`Server running at ${opencode.server.url}`)\nopencode.server.close()\n```\n\n## Client only\n\nIf you already have a running instance of opencode, you can create a client instance to connect to it:\n\n```\nimport { createOpencodeClient } from \"@opencode-ai/sdk\"\nconst client = createOpencodeClient({  baseUrl: \"http://localhost:4096\",})\n```\n\n#### Options\n\n## Types\n\nThe SDK includes TypeScript definitions for all API types. Import them directly:\n\n```\nimport type { Session, Message, Part } from \"@opencode-ai/sdk\"\n```\n\nAll types are generated from the server’s OpenAPI specification and available in the types file.\n\n## Errors\n\nThe SDK can throw errors that you can catch and handle:\n\n```\ntry {  await client.session.get({ path: { id: \"invalid-id\" } })} catch (error) {  console.error(\"Failed to get session:\", (error as Error).message)}\n```\n\n## APIs\n\nThe SDK exposes all server APIs through a type-safe client.\n\n### Global\n\n#### Examples\n\n```\nconst health = await client.global.health()console.log(health.data.version)\n```\n\n### App\n\n[Agent[]](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) \n#### Examples\n\n```\n// Write a log entryawait client.app.log({  body: {    service: \"my-app\",    level: \"info\",    message: \"Operation completed\",  },})\n// List available agentsconst agents = await client.app.agents()\n```\n\n### Project\n\n[Project[]](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) \n#### Examples\n\n```\n// List all projectsconst projects = await client.project.list()\n// Get current projectconst currentProject = await client.project.current()\n```\n\n### Path\n\n#### Examples\n\n```\n// Get current path informationconst pathInfo = await client.path.get()\n```\n\n### Config\n\n[Provider[]](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) \n#### Examples\n\n```\nconst config = await client.config.get()\nconst { providers, default: defaults } = await client.config.providers()\n```\n\n### Sessions\n\n[Session[]](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) [Part[]](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) [AssistantMessage](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) \n#### Examples\n\n```\n// Create and manage sessionsconst session = await client.session.create({  body: { title: \"My session\" },})\nconst sessions = await client.session.list()\n// Send a prompt messageconst result = await client.session.prompt({  path: { id: session.id },  body: {    model: { providerID: \"anthropic\", modelID: \"claude-3-5-sonnet-20241022\" },    parts: [{ type: \"text\", text: \"Hello!\" }],  },})\n// Inject context without triggering AI response (useful for plugins)await client.session.prompt({  path: { id: session.id },  body: {    noReply: true,    parts: [{ type: \"text\", text: \"You are a helpful assistant.\" }],  },})\n```\n\n### Files\n\n[Symbol[]](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) [File[]](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) find.files supports a few optional query fields:\n\n- type: \"file\" or \"directory\"\n- directory: override the project root for the search\n- limit: max results (1–200)\n\n#### Examples\n\n```\n// Search and read filesconst textResults = await client.find.text({  query: { pattern: \"function.*opencode\" },})\nconst files = await client.find.files({  query: { query: \"*.ts\", type: \"file\" },})\nconst directories = await client.find.files({  query: { query: \"packages\", type: \"directory\", limit: 20 },})\nconst content = await client.file.read({  query: { path: \"src/index.ts\" },})\n```\n\n### TUI\n\n#### Examples\n\n```\n// Control TUI interfaceawait client.tui.appendPrompt({  body: { text: \"Add this to prompt\" },})\nawait client.tui.showToast({  body: { message: \"Task completed\", variant: \"success\" },})\n```\n\n### Auth\n\n#### Examples\n\n```\nawait client.auth.set({  path: { id: \"anthropic\" },  body: { type: \"api\", key: \"your-api-key\" },})\n```\n\n### Events\n\n#### Examples\n\n```\n// Listen to real-time eventsconst events = await client.event.subscribe()for await (const event of events.stream) {  console.log(\"Event:\", event.type, event.properties)}\n```\n\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/sdk.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "SDK",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "Install",
          "id": "install"
        },
        {
          "level": 2,
          "text": "Create client",
          "id": "create-client"
        },
        {
          "level": 4,
          "text": "Options",
          "id": "options"
        },
        {
          "level": 2,
          "text": "Config",
          "id": "config"
        },
        {
          "level": 2,
          "text": "Client only",
          "id": "client-only"
        },
        {
          "level": 4,
          "text": "Options",
          "id": "options-1"
        },
        {
          "level": 2,
          "text": "Types",
          "id": "types"
        },
        {
          "level": 2,
          "text": "Errors",
          "id": "errors"
        },
        {
          "level": 2,
          "text": "APIs",
          "id": "apis"
        },
        {
          "level": 3,
          "text": "Global",
          "id": "global"
        },
        {
          "level": 4,
          "text": "Examples",
          "id": "examples"
        },
        {
          "level": 3,
          "text": "App",
          "id": "app"
        },
        {
          "level": 4,
          "text": "Examples",
          "id": "examples-1"
        },
        {
          "level": 3,
          "text": "Project",
          "id": "project"
        },
        {
          "level": 4,
          "text": "Examples",
          "id": "examples-2"
        },
        {
          "level": 3,
          "text": "Path",
          "id": "path"
        },
        {
          "level": 4,
          "text": "Examples",
          "id": "examples-3"
        },
        {
          "level": 3,
          "text": "Config",
          "id": "config-1"
        },
        {
          "level": 4,
          "text": "Examples",
          "id": "examples-4"
        },
        {
          "level": 3,
          "text": "Sessions",
          "id": "sessions"
        },
        {
          "level": 4,
          "text": "Examples",
          "id": "examples-5"
        },
        {
          "level": 3,
          "text": "Files",
          "id": "files"
        },
        {
          "level": 4,
          "text": "Examples",
          "id": "examples-6"
        },
        {
          "level": 3,
          "text": "TUI",
          "id": "tui"
        },
        {
          "level": 4,
          "text": "Examples",
          "id": "examples-7"
        },
        {
          "level": 3,
          "text": "Auth",
          "id": "auth"
        },
        {
          "level": 4,
          "text": "Examples",
          "id": "examples-8"
        },
        {
          "level": 3,
          "text": "Events",
          "id": "events"
        },
        {
          "level": 4,
          "text": "Examples",
          "id": "examples-9"
        }
      ],
      "category": "Develop",
      "scrapedAt": 1768685276866
    },
    {
      "path": "/docs/server/",
      "title": "Server",
      "url": "https://opencode.ai/docs/server/",
      "content": "# Server\n\nInteract with opencode server over HTTP.\n\nThe opencode serve command runs a headless HTTP server that exposes an OpenAPI endpoint that an opencode client can use.\n\n### Usage\n\n```\nopencode serve [--port <number>] [--hostname <string>] [--cors <origin>]\n```\n\n#### Options\n\n--cors can be passed multiple times:\n\n```\nopencode serve --cors http://localhost:5173 --cors https://app.example.com\n```\n\n### Authentication\n\nSet OPENCODE_SERVER_PASSWORD to protect the server with HTTP basic auth. The username defaults to opencode, or set OPENCODE_SERVER_USERNAME to override it. This applies to both opencode serve and opencode web.\n\n```\nOPENCODE_SERVER_PASSWORD=your-password opencode serve\n```\n\n### How it works\n\nWhen you run opencode it starts a TUI and a server. Where the TUI is the\nclient that talks to the server. The server exposes an OpenAPI 3.1 spec\nendpoint. This endpoint is also used to generate an SDK.\n\nTip\n\nUse the opencode server to interact with opencode programmatically.\n\nThis architecture lets opencode support multiple clients and allows you to interact with opencode programmatically.\n\nYou can run opencode serve to start a standalone server. If you have the\nopencode TUI running, opencode serve will start a new server.\n\n#### Connect to an existing server\n\nWhen you start the TUI it randomly assigns a port and hostname. You can instead pass in the --hostname and --port flags. Then use this to connect to its server.\n\nThe /tui endpoint can be used to drive the TUI through the server. For example, you can prefill or run a prompt. This setup is used by the OpenCode IDE plugins.\n\n## Spec\n\nThe server publishes an OpenAPI 3.1 spec that can be viewed at:\n\n```\nhttp://<hostname>:<port>/doc\n```\n\nFor example, http://localhost:4096/doc. Use the spec to generate clients or inspect request and response types. Or view it in a Swagger explorer.\n\n## APIs\n\nThe opencode server exposes the following APIs.\n\n### Global\n\n### Project\n\n[Project[]](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) \n### Path & VCS\n\n[VcsInfo](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) \n### Instance\n\n### Config\n\n[Provider[]](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) \n### Provider\n\n[ProviderAuthMethod[]](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) [ProviderAuthAuthorization](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) \n### Sessions\n\n[Session[]](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) [SessionStatus](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) [Todo[]](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) [FileDiff[]](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) \n### Messages\n\n[Part[]](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) \n### Commands\n\n[Command[]](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) \n### Files\n\n[Symbol[]](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) [FileNode[]](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) [FileContent](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) [File[]](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) \n#### /find/file query parameters\n\n- query (required) — search string (fuzzy match)\n- type (optional) — limit results to \"file\" or \"directory\"\n- directory (optional) — override the project root for the search\n- limit (optional) — max results (1–200)\n- dirs (optional) — legacy flag (\"false\" returns only files)\n\n### Tools (Experimental)\n\n[ToolIDs](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) [ToolList](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) \n### LSP, Formatters & MCP\n\n[LSPStatus[]](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) [FormatterStatus[]](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) [MCPStatus](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) \n### Agents\n\n[Agent[]](https://github.com/anomalyco/opencode/blob/dev/packages/sdk/js/src/gen/types.gen.ts) \n### Logging\n\n### TUI\n\n### Auth\n\n### Events\n\n### Docs\n\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/server.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "Server",
          "id": "_top"
        },
        {
          "level": 3,
          "text": "Usage",
          "id": "usage"
        },
        {
          "level": 4,
          "text": "Options",
          "id": "options"
        },
        {
          "level": 3,
          "text": "Authentication",
          "id": "authentication"
        },
        {
          "level": 3,
          "text": "How it works",
          "id": "how-it-works"
        },
        {
          "level": 4,
          "text": "Connect to an existing server",
          "id": "connect-to-an-existing-server"
        },
        {
          "level": 2,
          "text": "Spec",
          "id": "spec"
        },
        {
          "level": 2,
          "text": "APIs",
          "id": "apis"
        },
        {
          "level": 3,
          "text": "Global",
          "id": "global"
        },
        {
          "level": 3,
          "text": "Project",
          "id": "project"
        },
        {
          "level": 3,
          "text": "Path & VCS",
          "id": "path--vcs"
        },
        {
          "level": 3,
          "text": "Instance",
          "id": "instance"
        },
        {
          "level": 3,
          "text": "Config",
          "id": "config"
        },
        {
          "level": 3,
          "text": "Provider",
          "id": "provider"
        },
        {
          "level": 3,
          "text": "Sessions",
          "id": "sessions"
        },
        {
          "level": 3,
          "text": "Messages",
          "id": "messages"
        },
        {
          "level": 3,
          "text": "Commands",
          "id": "commands"
        },
        {
          "level": 3,
          "text": "Files",
          "id": "files"
        },
        {
          "level": 4,
          "text": "/find/file query parameters",
          "id": "findfile-query-parameters"
        },
        {
          "level": 3,
          "text": "Tools (Experimental)",
          "id": "tools-experimental"
        },
        {
          "level": 3,
          "text": "LSP, Formatters & MCP",
          "id": "lsp-formatters--mcp"
        },
        {
          "level": 3,
          "text": "Agents",
          "id": "agents"
        },
        {
          "level": 3,
          "text": "Logging",
          "id": "logging"
        },
        {
          "level": 3,
          "text": "TUI",
          "id": "tui"
        },
        {
          "level": 3,
          "text": "Auth",
          "id": "auth"
        },
        {
          "level": 3,
          "text": "Events",
          "id": "events"
        },
        {
          "level": 3,
          "text": "Docs",
          "id": "docs"
        }
      ],
      "category": "Develop",
      "scrapedAt": 1768685277217
    },
    {
      "path": "/docs/plugins/",
      "title": "Plugins",
      "url": "https://opencode.ai/docs/plugins/",
      "content": "# Plugins\n\nWrite your own plugins to extend OpenCode.\n\nPlugins allow you to extend OpenCode by hooking into various events and customizing behavior. You can create plugins to add new features, integrate with external services, or modify OpenCode’s default behavior.\n\nFor examples, check out the plugins created by the community.\n\n## Use a plugin\n\nThere are two ways to load plugins.\n\n### From local files\n\nPlace JavaScript or TypeScript files in the plugin directory.\n\n- .opencode/plugin/ - Project-level plugins\n- ~/.config/opencode/plugin/ - Global plugins\nFiles in these directories are automatically loaded at startup.\n\n### From npm\n\nSpecify npm packages in your config file.\n\n```\n{  \"$schema\": \"https://opencode.ai/config.json\",  \"plugin\": [\"opencode-helicone-session\", \"opencode-wakatime\", \"@my-org/custom-plugin\"]}\n```\n\nBoth regular and scoped npm packages are supported.\n\nBrowse available plugins in the ecosystem.\n\n### How plugins are installed\n\nnpm plugins are installed automatically using Bun at startup. Packages and their dependencies are cached in ~/.cache/opencode/node_modules/.\n\nLocal plugins are loaded directly from the plugin directory. To use external packages, you must create a package.json within your config directory (see Dependencies), or publish the plugin to npm and add it to your config.\n\n### Load order\n\nPlugins are loaded from all sources and all hooks run in sequence. The load order is:\n\n- Global config (~/.config/opencode/opencode.json)\n- Project config (opencode.json)\n- Global plugin directory (~/.config/opencode/plugin/)\n- Project plugin directory (.opencode/plugin/)\nDuplicate npm packages with the same name and version are loaded once. However, a local plugin and an npm plugin with similar names are both loaded separately.\n\n## Create a plugin\n\nA plugin is a JavaScript/TypeScript module that exports one or more plugin\nfunctions. Each function receives a context object and returns a hooks object.\n\n### Dependencies\n\nLocal plugins and custom tools can use external npm packages. Add a package.json to your config directory with the dependencies you need.\n\n```\n{  \"dependencies\": {    \"shescape\": \"^2.1.0\"  }}\n```\n\nOpenCode runs bun install at startup to install these. Your plugins and tools can then import them.\n\n```\nimport { escape } from \"shescape\"\nexport const MyPlugin = async (ctx) => {  return {    \"tool.execute.before\": async (input, output) => {      if (input.tool === \"bash\") {        output.args.command = escape(output.args.command)      }    },  }}\n```\n\n### Basic structure\n\n```\nexport const MyPlugin = async ({ project, client, $, directory, worktree }) => {  console.log(\"Plugin initialized!\")\n  return {    // Hook implementations go here  }}\n```\n\nThe plugin function receives:\n\n- project: The current project information.\n- directory: The current working directory.\n- worktree: The git worktree path.\n- client: An opencode SDK client for interacting with the AI.\n- $: Bun’s shell API for executing commands.\n\n### TypeScript support\n\nFor TypeScript plugins, you can import types from the plugin package:\n\n```\nimport type { Plugin } from \"@opencode-ai/plugin\"\nexport const MyPlugin: Plugin = async ({ project, client, $, directory, worktree }) => {  return {    // Type-safe hook implementations  }}\n```\n\n### Events\n\nPlugins can subscribe to events as seen below in the Examples section. Here is a list of the different events available.\n\n#### Command Events\n\n- command.executed\n\n#### File Events\n\n- file.edited\n- file.watcher.updated\n\n#### Installation Events\n\n- installation.updated\n\n#### LSP Events\n\n- lsp.client.diagnostics\n- lsp.updated\n\n#### Message Events\n\n- message.part.removed\n- message.part.updated\n- message.removed\n- message.updated\n\n#### Permission Events\n\n- permission.replied\n- permission.updated\n\n#### Server Events\n\n- server.connected\n\n#### Session Events\n\n- session.created\n- session.compacted\n- session.deleted\n- session.diff\n- session.error\n- session.idle\n- session.status\n- session.updated\n\n#### Todo Events\n\n- todo.updated\n\n#### Tool Events\n\n- tool.execute.after\n- tool.execute.before\n\n#### TUI Events\n\n- tui.prompt.append\n- tui.command.execute\n- tui.toast.show\n\n## Examples\n\nHere are some examples of plugins you can use to extend opencode.\n\n### Send notifications\n\nSend notifications when certain events occur:\n\n```\nexport const NotificationPlugin = async ({ project, client, $, directory, worktree }) => {  return {    event: async ({ event }) => {      // Send notification on session completion      if (event.type === \"session.idle\") {        await $`osascript -e 'display notification \"Session completed!\" with title \"opencode\"'`      }    },  }}\n```\n\nWe are using osascript to run AppleScript on macOS. Here we are using it to send notifications.\n\nNote\n\nIf you’re using the OpenCode desktop app, it can send system notifications automatically when a response is ready or when a session errors.\n\n### .env protection\n\nPrevent opencode from reading .env files:\n\n```\nexport const EnvProtection = async ({ project, client, $, directory, worktree }) => {  return {    \"tool.execute.before\": async (input, output) => {      if (input.tool === \"read\" && output.args.filePath.includes(\".env\")) {        throw new Error(\"Do not read .env files\")      }    },  }}\n```\n\n### Custom tools\n\nPlugins can also add custom tools to opencode:\n\n```\nimport { type Plugin, tool } from \"@opencode-ai/plugin\"\nexport const CustomToolsPlugin: Plugin = async (ctx) => {  return {    tool: {      mytool: tool({        description: \"This is a custom tool\",        args: {          foo: tool.schema.string(),        },        async execute(args, ctx) {          return `Hello ${args.foo}!`        },      }),    },  }}\n```\n\nThe tool helper creates a custom tool that opencode can call. It takes a Zod schema function and returns a tool definition with:\n\n- description: What the tool does\n- args: Zod schema for the tool’s arguments\n- execute: Function that runs when the tool is called\nYour custom tools will be available to opencode alongside built-in tools.\n\n### Logging\n\nUse client.app.log() instead of console.log for structured logging:\n\n```\nexport const MyPlugin = async ({ client }) => {  await client.app.log({    service: \"my-plugin\",    level: \"info\",    message: \"Plugin initialized\",    extra: { foo: \"bar\" },  })}\n```\n\nLevels: debug, info, warn, error. See SDK documentation for details.\n\n### Compaction hooks\n\nCustomize the context included when a session is compacted:\n\n```\nimport type { Plugin } from \"@opencode-ai/plugin\"\nexport const CompactionPlugin: Plugin = async (ctx) => {  return {    \"experimental.session.compacting\": async (input, output) => {      // Inject additional context into the compaction prompt      output.context.push(`## Custom Context\nInclude any state that should persist across compaction:- Current task status- Important decisions made- Files being actively worked on`)    },  }}\n```\n\nThe experimental.session.compacting hook fires before the LLM generates a continuation summary. Use it to inject domain-specific context that the default compaction prompt would miss.\n\nYou can also replace the compaction prompt entirely by setting output.prompt:\n\n```\nimport type { Plugin } from \"@opencode-ai/plugin\"\nexport const CustomCompactionPlugin: Plugin = async (ctx) => {  return {    \"experimental.session.compacting\": async (input, output) => {      // Replace the entire compaction prompt      output.prompt = `You are generating a continuation prompt for a multi-agent swarm session.\nSummarize:1. The current task and its status2. Which files are being modified and by whom3. Any blockers or dependencies between agents4. The next steps to complete the work\nFormat as a structured prompt that a new agent can use to resume work.`    },  }}\n```\n\nWhen output.prompt is set, it completely replaces the default compaction prompt. The output.context array is ignored in this case.\n\n[Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/plugins.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "Plugins",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "Use a plugin",
          "id": "use-a-plugin"
        },
        {
          "level": 3,
          "text": "From local files",
          "id": "from-local-files"
        },
        {
          "level": 3,
          "text": "From npm",
          "id": "from-npm"
        },
        {
          "level": 3,
          "text": "How plugins are installed",
          "id": "how-plugins-are-installed"
        },
        {
          "level": 3,
          "text": "Load order",
          "id": "load-order"
        },
        {
          "level": 2,
          "text": "Create a plugin",
          "id": "create-a-plugin"
        },
        {
          "level": 3,
          "text": "Dependencies",
          "id": "dependencies"
        },
        {
          "level": 3,
          "text": "Basic structure",
          "id": "basic-structure"
        },
        {
          "level": 3,
          "text": "TypeScript support",
          "id": "typescript-support"
        },
        {
          "level": 3,
          "text": "Events",
          "id": "events"
        },
        {
          "level": 4,
          "text": "Command Events",
          "id": "command-events"
        },
        {
          "level": 4,
          "text": "File Events",
          "id": "file-events"
        },
        {
          "level": 4,
          "text": "Installation Events",
          "id": "installation-events"
        },
        {
          "level": 4,
          "text": "LSP Events",
          "id": "lsp-events"
        },
        {
          "level": 4,
          "text": "Message Events",
          "id": "message-events"
        },
        {
          "level": 4,
          "text": "Permission Events",
          "id": "permission-events"
        },
        {
          "level": 4,
          "text": "Server Events",
          "id": "server-events"
        },
        {
          "level": 4,
          "text": "Session Events",
          "id": "session-events"
        },
        {
          "level": 4,
          "text": "Todo Events",
          "id": "todo-events"
        },
        {
          "level": 4,
          "text": "Tool Events",
          "id": "tool-events"
        },
        {
          "level": 4,
          "text": "TUI Events",
          "id": "tui-events"
        },
        {
          "level": 2,
          "text": "Examples",
          "id": "examples"
        },
        {
          "level": 3,
          "text": "Send notifications",
          "id": "send-notifications"
        },
        {
          "level": 3,
          "text": ".env protection",
          "id": "env-protection"
        },
        {
          "level": 3,
          "text": "Custom tools",
          "id": "custom-tools"
        },
        {
          "level": 3,
          "text": "Logging",
          "id": "logging"
        },
        {
          "level": 3,
          "text": "Compaction hooks",
          "id": "compaction-hooks"
        }
      ],
      "category": "Develop",
      "scrapedAt": 1768685277570
    },
    {
      "path": "/docs/ecosystem/",
      "title": "Ecosystem",
      "url": "https://opencode.ai/docs/ecosystem/",
      "content": "# Ecosystem\n\nProjects and integrations built with OpenCode.\n\nA collection of community projects built on OpenCode.\n\nNote\n\nWant to add your OpenCode related project to this list? Submit a PR.\n\nYou can also check out awesome-opencode and opencode.cafe, a community that aggregates the ecosystem and community.\n\n## Plugins\n\n[opencode-helicone-session](https://github.com/H2Shami/opencode-helicone-session) [opencode-type-inject](https://github.com/nick-vi/opencode-type-inject) [opencode-openai-codex-auth](https://github.com/numman-ali/opencode-openai-codex-auth) [opencode-gemini-auth](https://github.com/jenslys/opencode-gemini-auth) [opencode-antigravity-auth](https://github.com/NoeFabris/opencode-antigravity-auth) [opencode-devcontainers](https://github.com/athal7/opencode-devcontainers) [opencode-google-antigravity-auth](https://github.com/shekohex/opencode-google-antigravity-auth) [opencode-dynamic-context-pruning](https://github.com/Tarquinen/opencode-dynamic-context-pruning) [opencode-websearch-cited](https://github.com/ghoulr/opencode-websearch-cited.git) [opencode-pty](https://github.com/shekohex/opencode-pty.git) [opencode-shell-strategy](https://github.com/JRedeker/opencode-shell-strategy) [opencode-wakatime](https://github.com/angristan/opencode-wakatime) [opencode-md-table-formatter](https://github.com/franlol/opencode-md-table-formatter/tree/main) [opencode-morph-fast-apply](https://github.com/JRedeker/opencode-morph-fast-apply) [oh-my-opencode](https://github.com/code-yeongyu/oh-my-opencode) [opencode-notificator](https://github.com/panta82/opencode-notificator) [opencode-notifier](https://github.com/mohak34/opencode-notifier) [opencode-zellij-namer](https://github.com/24601/opencode-zellij-namer) [opencode-skillful](https://github.com/zenobi-us/opencode-skillful) [opencode-supermemory](https://github.com/supermemoryai/opencode-supermemory) [@plannotator/opencode](https://github.com/backnotprop/plannotator/tree/main/apps/opencode-plugin) [@openspoon/subtask2](https://github.com/spoons-and-mirrors/subtask2) [opencode-scheduler](https://github.com/different-ai/opencode-scheduler) [micode](https://github.com/vtemian/micode) [octto](https://github.com/vtemian/octto) \n## Projects\n\n[kimaki](https://github.com/remorses/kimaki) [opencode.nvim](https://github.com/NickvanDyke/opencode.nvim) [portal](https://github.com/hosenur/portal) [opencode plugin template](https://github.com/zenobi-us/opencode-plugin-template/) [ai-sdk-provider-opencode-sdk](https://github.com/ben-vargas/ai-sdk-provider-opencode-sdk) [OpenChamber](https://github.com/btriapitsyn/openchamber) [OpenCode-Obsidian](https://github.com/mtymek/opencode-obsidian) \n## Agents\n\n[Agentic](https://github.com/Cluster444/agentic) [opencode-agents](https://github.com/darrenhinde/opencode-agents) [Edit this page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/ecosystem.mdx) [Find a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new) [Join our Discord community](https://opencode.ai/discord) © Anomaly\n\nJan 16, 2026",
      "headings": [
        {
          "level": 2,
          "text": "On this page",
          "id": "starlight__on-this-page"
        },
        {
          "level": 1,
          "text": "Ecosystem",
          "id": "_top"
        },
        {
          "level": 2,
          "text": "Plugins",
          "id": "plugins"
        },
        {
          "level": 2,
          "text": "Projects",
          "id": "projects"
        },
        {
          "level": 2,
          "text": "Agents",
          "id": "agents"
        }
      ],
      "category": "Develop",
      "scrapedAt": 1768685277933
    }
  ],
  "version": "1.0.0",
  "updatedAt": 1768685278234,
  "baseUrl": "https://opencode.ai/docs"
}